{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Navigating Ethical Challenges in Generative AI-Enhanced Research: The ETHICAL Framework for Responsible Generative AI Use", "authors": "Douglas Eacersall, Lynette Pretorius, Ivan Smirnov, Erika Spray, Sam Illingworth, Ritesh Chugh, Sonja Strydom, Dianne Stratton-Maher, Jonathan Simmons, Isaac Jennings, Rian Roux, Ruth Kamrowski, Abigail Downie, Chee Ling Thong, Katharine A. Howell", "subjects": "Subjects:\nComputers and Society (cs.CY); Artificial Intelligence (cs.AI)", "abstract": "The rapid adoption of generative artificial intelligence (GenAI) in research presents both opportunities and ethical challenges that should be carefully navigated. Although GenAI tools can enhance research efficiency through automation of tasks such as literature review and data analysis, their use raises concerns about aspects such as data accuracy, privacy, bias, and research integrity. This paper develops the ETHICAL framework, which is a practical guide for responsible GenAI use in research. Employing a constructivist case study examining multiple GenAI tools in real research contexts, the framework consists of seven key principles: Examine policies and guidelines, Think about social impacts, Harness understanding of the technology, Indicate use, Critically engage with outputs, Access secure versions, and Look at user agreements. Applying these principles will enable researchers to uphold research integrity while leveraging GenAI benefits. The framework addresses a critical gap between awareness of ethical issues and practical action steps, providing researchers with concrete guidance for ethical GenAI integration. This work has implications for research practice, institutional policy development, and the broader academic community while adapting to an AI-enhanced research landscape. The ETHICAL framework can serve as a foundation for developing AI literacy in academic settings and promoting responsible innovation in research methodologies."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Cyber-Physical Security Vulnerabilities Identification and Classification in Smart Manufacturing - A Defense-in-Depth Driven Framework and Taxonomy", "authors": "Md Habibor Rahman (1), Mohammed Shafae (2) ((1) University of Massachusetts Dartmouth, (2) The University of Arizona)", "subjects": "Subjects:\nCryptography and Security (cs.CR)", "abstract": "The increasing cybersecurity threats to critical manufacturing infrastructure necessitate proactive strategies for vulnerability identification, classification, and assessment. Traditional approaches, which define vulnerabilities as weaknesses in computational logic or information systems, often overlook the physical and cyber-physical dimensions critical to manufacturing systems, comprising intertwined cyber, physical, and human elements. As a result, existing solutions fall short in addressing the complex, domain-specific vulnerabilities of manufacturing environments. To bridge this gap, this work redefines vulnerabilities in the manufacturing context by introducing a novel characterization based on the duality between vulnerabilities and defenses. Vulnerabilities are conceptualized as exploitable gaps within various defense layers, enabling a structured investigation of manufacturing systems. This paper presents a manufacturing-specific cyber-physical defense-in-depth model, highlighting how security-aware personnel, post-production inspection systems, and process monitoring approaches can complement traditional cyber defenses to enhance system resilience. Leveraging this model, we systematically identify and classify vulnerabilities across the manufacturing cyberspace, human element, post-production inspection systems, production process monitoring, and organizational policies and procedures. This comprehensive classification introduces the first taxonomy of cyber-physical vulnerabilities in smart manufacturing systems, providing practitioners with a structured framework for addressing vulnerabilities at both the system and process levels. Finally, the effectiveness of the proposed model and framework is demonstrated through an illustrative smart manufacturing system and its corresponding threat model."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Social-LLaVA: Enhancing Robot Navigation through Human-Language Reasoning in Social Spaces", "authors": "Amirreza Payandeh, Daeun Song, Mohammad Nazeri, Jing Liang, Praneel Mukherjee, Amir Hossain Raj, Yangzhe Kong, Dinesh Manocha, Xuesu Xiao", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC); Robotics (cs.RO)", "abstract": "Most existing social robot navigation techniques either leverage hand-crafted rules or human demonstrations to connect robot perception to socially compliant actions. However, there remains a significant gap in effectively translating perception into socially compliant actions, much like how human reasoning naturally occurs in dynamic environments. Considering the recent success of Vision-Language Models (VLMs), we propose using language to bridge the gap in human-like reasoning between perception and socially aware robot actions. We create a vision-language dataset, Social robot Navigation via Explainable Interactions (SNEI), featuring 40K human-annotated Visual Question Answers (VQAs) based on 2K human-robot social interactions in unstructured, crowded public spaces, spanning perception, prediction, chain-of-thought reasoning, action, and explanation. We fine-tune a VLM, Social-LLaVA, using SNEI to demonstrate the practical application of our dataset. Social-LLaVA outperforms state-of-the-art models like GPT-4V and Gemini, based on the average of fifteen different human-judge scores across 50 VQA. Deployed onboard a mobile robot, Social-LLaVA enables human-like reasoning, marking a promising step toward socially compliant robot navigation in dynamic public spaces through language reasoning."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Cyber Shadows: Neutralizing Security Threats with AI and Targeted Policy Measures", "authors": "Marc Schmitt, Pantelis Koutroumpis", "subjects": "Subjects:\nCryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computers and Society (cs.CY); General Economics (econ.GN)", "abstract": "The digital age, driven by the AI revolution, brings significant opportunities but also conceals security threats, which we refer to as cyber shadows. These threats pose risks at individual, organizational, and societal levels. This paper examines the systemic impact of these cyber threats and proposes a comprehensive cybersecurity strategy that integrates AI-driven solutions, such as Intrusion Detection Systems (IDS), with targeted policy interventions. By combining technological and regulatory measures, we create a multilevel defense capable of addressing both direct threats and indirect negative externalities. We emphasize that the synergy between AI-driven solutions and policy interventions is essential for neutralizing cyber threats and mitigating their negative impact on the digital economy. Finally, we underscore the need for continuous adaptation of these strategies, especially in response to the rapid advancement of autonomous AI-driven attacks, to ensure the creation of secure and resilient digital ecosystems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Intelligent Anti-Money Laundering Solution Based upon Novel Community Detection in Massive Transaction Networks on Spark", "authors": "Xurui Li, Xiang Cao, Xuetao Qiu, Jintao Zhao, Jianbin Zheng", "subjects": "Subjects:\nSocial and Information Networks (cs.SI); Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "abstract": "Criminals are using every means available to launder the profits from their illegal activities into ostensibly legitimate assets. Meanwhile, most commercial anti-money laundering systems are still rule-based, which cannot adapt to the ever-changing tricks. Although some machine learning methods have been proposed, they are mainly focused on the perspective of abnormal behavior for single accounts. Considering money laundering activities are often involved in gang criminals, these methods are still not intelligent enough to crack down on criminal gangs all-sidedly. In this paper, a systematic solution is presented to find suspicious money laundering gangs. A temporal-directed Louvain algorithm has been proposed to detect communities according to relevant anti-money laundering patterns. All processes are implemented and optimized on Spark platform. This solution can greatly improve the efficiency of anti-money laundering work for financial regulation agencies."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Unveiling Behavioral Differences in Bilingual Information Operations: A Network-Based Approach", "authors": "Bowen Yi", "subjects": "Subjects:\nSocial and Information Networks (cs.SI)", "abstract": "Twitter has become a pivotal platform for conducting information operations (IOs), particularly during high-stakes political events. In this study, we analyze over a million tweets about the 2024 U.S. presidential election to explore an under-studied area: the behavioral differences of IO drivers from English- and Spanish-speaking communities. Using similarity graphs constructed from behavioral patterns, we identify IO drivers in both languages and evaluate the clustering quality of these graphs in an unsupervised setting. Our analysis demonstrates how different network dismantling strategies, such as node pruning and edge filtering, can impact clustering quality and the identification of coordinated IO drivers. We also reveal significant differences in the topics and political indicators between English and Spanish IO drivers. Additionally, we investigate bilingual users who post in both languages, systematically uncovering their distinct roles and behaviors compared to monolingual users. These findings underscore the importance of robust, culturally and linguistically adaptable IO detection methods to mitigate the risks of influence campaigns on social media. Our code and data are available on GitHub: this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Emergence of the Traffic Autonomous Zone (TAZ) for Telecommunication Operations from Spatial Heterogeneity in Cellular Networks", "authors": "Liyan Xu, Jintong Tang, Hezhishi Jiang, Hongbin Yu, Yihang Li, Qian Huang, Yinsheng Zhou, Jun Zhang, Yu Liu", "subjects": "Subjects:\nSocial and Information Networks (cs.SI)", "abstract": "In the field of telecommunications, various operations are driven by different physical quantities. Each has its own patterns in time and space, but all show some clustered structures in their spatial distribution. This reflects a unified rule of human mobility, suggesting the consistency among different telecommunication regionalization objectives. With this in mind, regionalization can be used to identify these patterns and can be applied to improve management efficiency in the context of \"autonomous networks\". This article introduces the \"Traffic Autonomous Zone (TAZ)\" concept. This approach aims to create a reasonable unified regionalization scheme by identifying spatial clusters. It is not just a practical way to partition cities based on telecommunications needs, but it also captures self-organization structure of cities in essence. We present examples of this regionalization method using real data. Compared to the popular Louvain community detection method, our approach is on the Pareto frontier, allowing for a balance among various metrics in telecommunications."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Enhancing Data Integrity through Provenance Tracking in Semantic Web Frameworks", "authors": "Nilesh Jain", "subjects": "Subjects:\nCryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "abstract": "This paper explores the integration of provenance tracking systems within the context of Semantic Web technologies to enhance data integrity in diverse operational environments. SURROUND Australia Pty Ltd demonstrates innovative applica-tions of the PROV Data Model (PROV-DM) and its Semantic Web variant, PROV-O, to systematically record and manage provenance information across multiple data processing domains. By employing RDF and Knowledge Graphs, SURROUND ad-dresses the critical challenges of shared entity identification and provenance granularity. The paper highlights the company's architecture for capturing comprehensive provenance data, en-abling robust validation, traceability, and knowledge inference. Through the examination of two projects, we illustrate how provenance mechanisms not only improve data reliability but also facilitate seamless integration across heterogeneous systems. Our findings underscore the importance of sophisticated provenance solutions in maintaining data integrity, serving as a reference for industry peers and academics engaged in provenance research and implementation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Synthetic Data and Health Privacy", "authors": "Gw\u00e9nol\u00e9 Abgrall, Xavier Monnet, Anmol Arora", "subjects": "Subjects:\nCryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "abstract": "This Viewpoint discusses generative artificial intelligence and safeguarding privacy by using synthetic data as a substitute for private health data."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Distributed Identity for Zero Trust and Segmented Access Control: A Novel Approach to Securing Network Infrastructure", "authors": "Sina Ahmadi", "subjects": "Subjects:\nCryptography and Security (cs.CR); Computers and Society (cs.CY)", "abstract": "\"Distributed Identity\" refers to the transition from centralized identity systems using Decentralized Identifiers (DID) and Verifiable Credentials (VC) for secure and privacy-preserving authentications. With distributed identity, control of identity data is returned to the user, making credential-based attacks impossible due to the lack of a single point of failure. This study assesses the security improvements achieved when distributed identity is employed with the ZTA principle, particularly concerning lateral movements within segmented networks. It also considers areas such as the implementation specifications of the framework, the advantages and disadvantages of the method to organizations, and the issues of compatibility and generalizability. Furthermore, the study highlights privacy and regulatory compliance, including the General Data Protection Regulation (GDPR) and California Consumer Data Privacy Act (CCPA), analyzing potential solutions to these problems. The study implies that adopting distributed identities can enhance overall security postures by an order of magnitude, providing contextual and least-privilege authorization and user privacy. The research recommends refining technical standards, expanding the use of distributed identity in practice, and discussing its applications for the contemporary digital security landscape."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Adaptive Cybersecurity: Dynamically Retrainable Firewalls for Real-Time Network Protection", "authors": "Sina Ahmadi", "subjects": "Subjects:\nCryptography and Security (cs.CR); Computers and Society (cs.CY)", "abstract": "The growing complexity of cyber attacks has necessitated the evolution of firewall technologies from static models to adaptive, machine learning-driven systems. This research introduces \"Dynamically Retrainable Firewalls\", which respond to emerging threats in real-time. Unlike traditional firewalls that rely on static rules to inspect traffic, these advanced systems leverage machine learning algorithms to analyze network traffic pattern dynamically and identify threats. The study explores architectures such as micro-services and distributed systems for real-time adaptability, data sources for model retraining, and dynamic threat identification through reinforcement and continual learning. It also discusses strategies to improve performance, reduce latency, optimize resource utilization, and address integration issues with present- day concepts such as Zero Trust and mixed environments. By critically assessing the literature, analyzing case studies, and elucidating areas of future research, this work suggests dynamically retrainable firewalls as a more robust form of network security. Additionally, it considers emerging trends such as advancements in AI and quantum computing, ethical issues, and other regulatory questions surrounding future AI systems. These findings provide valuable information on the future state of adaptive cyber security, focusing on the need for proactive and adaptive measures that counter cyber threats that continue to evolve."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Physics-Informed Machine Learning for Microscale Drying of Plant-Based Foods: A Systematic Review of Computational Models and Experimental Insights", "authors": "C. P. Batuwatta-Gamage (1), H. Jeong (1), HCP Karunasena (1 and 3), M. A. Karim (1), C.M. Rathnayaka (1 and 2), Y.T. Gu (1) ((1) Queensland University of Technology (QUT), Australia, (2) University of the Sunshine Coast (UniSC), Australia., (3) University of Ruhuna, Sri Lanka)", "subjects": "Subjects:\nMachine Learning (cs.LG); Biological Physics (physics.bio-ph); Computational Physics (physics.comp-ph)", "abstract": "This review examines the current state of research on microscale cellular changes during the drying of plant-based food materials (PBFM), with particular emphasis on computational modelling approaches. The review addresses the critical need for advanced computational methods in microscale investigations. We systematically analyse experimental studies in PBFM drying, highlighting their contributions and limitations in capturing cellular-level phenomena, including challenges in data acquisition and measurement accuracy under varying drying conditions. The evolution of computational models for microstructural investigations is thoroughly examined, from traditional numerical methods to contemporary state-of-the-art approaches, with specific focus on their ability to handle the complex, nonlinear properties of plant cellular materials. Special attention is given to the emergence of data-driven models and their limitations in predicting microscale cellular behaviour during PBFM drying, particularly addressing challenges in dataset acquisition and model generalization. The review provides an in-depth analysis of Physics-Informed Machine Learning (PIML) frameworks, examining their theoretical foundations, current applications in related fields, and unique advantages in combining physical principles with neural network architectures. Through this comprehensive assessment, we identify critical gaps in existing methodologies, evaluate the trade-offs between different modelling approaches, and provide insights into future research directions for improving our understanding of cellular-level transformations during PBFM drying processes. The review concludes with recommendations for integrating experimental and computational approaches to advance the field of food preservation technology."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          DomainDemo: a dataset of domain-sharing activities among different demographic groups on Twitter", "authors": "Kai-Cheng Yang, Pranav Goel, Alexi Quintana-Math\u00e9, Luke Horgan, Stefan D. McCabe, Nir Grinberg, Kenneth Joseph, David Lazer", "subjects": "Subjects:\nSocial and Information Networks (cs.SI); Computers and Society (cs.CY)", "abstract": "Social media play a pivotal role in disseminating web content, particularly during elections, yet our understanding of the association between demographic factors and political discourse online remains limited. Here, we introduce a unique dataset, DomainDemo, linking domains shared on Twitter (X) with the demographic characteristics of associated users, including age, gender, race, political affiliation, and geolocation, from 2011 to 2022. This new resource was derived from a panel of over 1.5 million Twitter users matched against their U.S. voter registration records, facilitating a better understanding of a decade of information flows on one of the most prominent social media platforms and trends in political and public discourse among registered U.S. voters from different sociodemographic groups. By aggregating user demographic information onto the domains, we derive five metrics that provide critical insights into over 129,000 websites. In particular, the localness and partisan audience metrics quantify the domains' geographical reach and ideological orientation, respectively. These metrics show substantial agreement with existing classifications, suggesting the effectiveness and reliability of DomainDemo's approach."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Do generative video models learn physical principles from watching videos?", "authors": "Saman Motamed, Laura Culp, Kevin Swersky, Priyank Jaini, Robert Geirhos", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Graphics (cs.GR); Machine Learning (cs.LG)", "abstract": "AI video generation is undergoing a revolution, with quality and realism advancing rapidly. These advances have led to a passionate scientific debate: Do video models learn ``world models'' that discover laws of physics -- or, alternatively, are they merely sophisticated pixel predictors that achieve visual realism without understanding the physical principles of reality? We address this question by developing Physics-IQ, a comprehensive benchmark dataset that can only be solved by acquiring a deep understanding of various physical principles, like fluid dynamics, optics, solid mechanics, magnetism and thermodynamics. We find that across a range of current models (Sora, Runway, Pika, Lumiere, Stable Video Diffusion, and VideoPoet), physical understanding is severely limited, and unrelated to visual realism. At the same time, some test cases can already be successfully solved. This indicates that acquiring certain physical principles from observation alone may be possible, but significant challenges remain. While we expect rapid advances ahead, our work demonstrates that visual realism does not imply physical understanding. Our project page is at this https URL; code at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Playing Devil's Advocate: Unmasking Toxicity and Vulnerabilities in Large Vision-Language Models", "authors": "Abdulkadir Erol, Trilok Padhi, Agnik Saha, Ugur Kursuncu, Mehmet Emin Aktas", "subjects": "Subjects:\nCryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "abstract": "The rapid advancement of Large Vision-Language Models (LVLMs) has enhanced capabilities offering potential applications from content creation to productivity enhancement. Despite their innovative potential, LVLMs exhibit vulnerabilities, especially in generating potentially toxic or unsafe responses. Malicious actors can exploit these vulnerabilities to propagate toxic content in an automated (or semi-) manner, leveraging the susceptibility of LVLMs to deception via strategically crafted prompts without fine-tuning or compute-intensive procedures. Despite the red-teaming efforts and inherent potential risks associated with the LVLMs, exploring vulnerabilities of LVLMs remains nascent and yet to be fully addressed in a systematic manner. This study systematically examines the vulnerabilities of open-source LVLMs, including LLaVA, InstructBLIP, Fuyu, and Qwen, using adversarial prompt strategies that simulate real-world social manipulation tactics informed by social theories. Our findings show that (i) toxicity and insulting are the most prevalent behaviors, with the mean rates of 16.13% and 9.75%, respectively; (ii) Qwen-VL-Chat, LLaVA-v1.6-Vicuna-7b, and InstructBLIP-Vicuna-7b are the most vulnerable models, exhibiting toxic response rates of 21.50%, 18.30% and 17.90%, and insulting responses of 13.40%, 11.70% and 10.10%, respectively; (iii) prompting strategies incorporating dark humor and multimodal toxic prompt completion significantly elevated these vulnerabilities. Despite being fine-tuned for safety, these models still generate content with varying degrees of toxicity when prompted with adversarial inputs, highlighting the urgent need for enhanced safety mechanisms and robust guardrails in LVLM development."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Pseudolabel guided pixels contrast for domain adaptive semantic segmentation", "authors": "Jianzi Xiang, Cailu Wan, Zhu Cao", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "Semantic segmentation is essential for comprehending images, but the process necessitates a substantial amount of detailed annotations at the pixel level. Acquiring such annotations can be costly in the real-world. Unsupervised domain adaptation (UDA) for semantic segmentation is a technique that uses virtual data with labels to train a model and adapts it to real data without labels. Some recent works use contrastive learning, which is a powerful method for self-supervised learning, to help with this technique. However, these works do not take into account the diversity of features within each class when using contrastive learning, which leads to errors in class prediction. We analyze the limitations of these works and propose a novel framework called Pseudo-label Guided Pixel Contrast (PGPC), which overcomes the disadvantages of previous methods. We also investigate how to use more information from target images without adding noise from pseudo-labels. We test our method on two standard UDA benchmarks and show that it outperforms existing methods. Specifically, we achieve relative improvements of 5.1% mIoU and 4.6% mIoU on the Grand Theft Auto V (GTA5) to Cityscapes and SYNTHIA to Cityscapes tasks based on DAFormer, respectively. Furthermore, our approach can enhance the performance of other UDA approaches without increasing model complexity. Code is available at this https URL"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Generative Visual Commonsense Answering and Explaining with Generative Scene Graph Constructing", "authors": "Fan Yuan, Xiaoyuan Fang, Rong Quan, Jing Li, Wei Bi, Xiaogang Xu, Piji Li", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL)", "abstract": "Visual Commonsense Reasoning, which is regarded as one challenging task to pursue advanced visual scene comprehension, has been used to diagnose the reasoning ability of AI systems. However, reliable reasoning requires a good grasp of the scene's details. Existing work fails to effectively exploit the real-world object relationship information present within the scene, and instead overly relies on knowledge from training memory. Based on these observations, we propose a novel scene-graph-enhanced visual commonsense reasoning generation method named \\textit{\\textbf{G2}}, which first utilizes the image patches and LLMs to construct a location-free scene graph, and then answer and explain based on the scene graph's information. We also propose automatic scene graph filtering and selection strategies to absorb valuable scene graph information during training. Extensive experiments are conducted on the tasks and datasets of scene graph constructing and visual commonsense answering and explaining, respectively. Experimental results and ablation analysis demonstrate the effectiveness of our proposed framework."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          CookingDiffusion: Cooking Procedural Image Generation with Stable Diffusion", "authors": "Yuan Wang, Bin Xhu, Yanbin Hao, Chong-Wah Ngo, Yi Tan, Xiang Wang", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR); Machine Learning (cs.LG)", "abstract": "Recent advancements in text-to-image generation models have excelled in creating diverse and realistic images. This success extends to food imagery, where various conditional inputs like cooking styles, ingredients, and recipes are utilized. However, a yet-unexplored challenge is generating a sequence of procedural images based on cooking steps from a recipe. This could enhance the cooking experience with visual guidance and possibly lead to an intelligent cooking simulation system. To fill this gap, we introduce a novel task called \\textbf{cooking procedural image generation}. This task is inherently demanding, as it strives to create photo-realistic images that align with cooking steps while preserving sequential consistency. To collectively tackle these challenges, we present \\textbf{CookingDiffusion}, a novel approach that leverages Stable Diffusion and three innovative Memory Nets to model procedural prompts. These prompts encompass text prompts (representing cooking steps), image prompts (corresponding to cooking images), and multi-modal prompts (mixing cooking steps and images), ensuring the consistent generation of cooking procedural images. To validate the effectiveness of our approach, we preprocess the YouCookII dataset, establishing a new benchmark. Our experimental results demonstrate that our model excels at generating high-quality cooking procedural images with remarkable consistency across sequential cooking steps, as measured by both the FID and the proposed Average Procedure Consistency metrics. Furthermore, CookingDiffusion demonstrates the ability to manipulate ingredients and cooking methods in a recipe. We will make our code, models, and dataset publicly accessible."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          TCMM: Token Constraint and Multi-Scale Memory Bank of Contrastive Learning for Unsupervised Person Re-identification", "authors": "Zheng-An Zhu, Hsin-Che Chien, Chen-Kuo Chiang", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "This paper proposes the ViT Token Constraint and Multi-scale Memory bank (TCMM) method to address the patch noises and feature inconsistency in unsupervised person re-identification works. Many excellent methods use ViT features to obtain pseudo labels and clustering prototypes, then train the model with contrastive learning. However, ViT processes images by performing patch embedding, which inevitably introduces noise in patches and may compromise the performance of the re-identification model. On the other hand, previous memory bank based contrastive methods may lead data inconsistency due to the limitation of batch size. Furthermore, existing pseudo label methods often discard outlier samples that are difficult to cluster. It sacrifices the potential value of outlier samples, leading to limited model diversity and robustness. This paper introduces the ViT Token Constraint to mitigate the damage caused by patch noises to the ViT architecture. The proposed Multi-scale Memory enhances the exploration of outlier samples and maintains feature consistency. Experimental results demonstrate that our system achieves state-of-the-art performance on common benchmarks. The project is available at \\href{this https URL}{this https URL}."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Spatio-Temporal Foundation Models: Vision, Challenges, and Opportunities", "authors": "Adam Goodge, Wee Siong Ng, Bryan Hooi, See Kiong Ng", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET)", "abstract": "Foundation models have revolutionized artificial intelligence, setting new benchmarks in performance and enabling transformative capabilities across a wide range of vision and language tasks. However, despite the prevalence of spatio-temporal data in critical domains such as transportation, public health, and environmental monitoring, spatio-temporal foundation models (STFMs) have not yet achieved comparable success. In this paper, we articulate a vision for the future of STFMs, outlining their essential characteristics and the generalization capabilities necessary for broad applicability. We critically assess the current state of research, identifying gaps relative to these ideal traits, and highlight key challenges that impede their progress. Finally, we explore potential opportunities and directions to advance research towards the aim of effective and broadly applicable STFMs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Anthropomorphic Features for On-Line Signatures", "authors": "Moises Diaz, Miguel A. Ferrer, Jose J. Quintana", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "Many features have been proposed in on-line signature verification. Generally, these features rely on the position of the on-line signature samples and their dynamic properties, as recorded by a tablet. This paper proposes a novel feature space to describe efficiently on-line signatures. Since producing a signature requires a skeletal arm system and its associated muscles, the new feature space is based on characterizing the movement of the shoulder, the elbow and the wrist joints when signing. As this motion is not directly obtained from a digital tablet, the new features are calculated by means of a virtual skeletal arm (VSA) model, which simulates the architecture of a real arm and forearm. Specifically, the VSA motion is described by its 3D joint position and its joint angles. These anthropomorphic features are worked out from both pen position and orientation through the VSA forward and direct kinematic model. The anthropomorphic features' robustness is proved by achieving state-of-the-art performance with several verifiers and multiple benchmarks on third party signature databases, which were collected with different devices and in different languages and scripts."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Generating Realistic Synthetic Head Rotation Data for Extended Reality using Deep Learning", "authors": "Jakob Struye, Filip Lemic, Jeroen Famaey", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Extended Reality is a revolutionary method of delivering multimedia content to users. A large contributor to its popularity is the sense of immersion and interactivity enabled by having real-world motion reflected in the virtual experience accurately and immediately. This user motion, mainly caused by head rotations, induces several technical challenges. For instance, which content is generated and transmitted depends heavily on where the user is looking. Seamless systems, taking user motion into account proactively, will therefore require accurate predictions of upcoming rotations. Training and evaluating such predictors requires vast amounts of orientational input data, which is expensive to gather, as it requires human test subjects. A more feasible approach is to gather a modest dataset through test subjects, and then extend it to a more sizeable set using synthetic data generation methods. In this work, we present a head rotation time series generator based on TimeGAN, an extension of the well-known Generative Adversarial Network, designed specifically for generating time series. This approach is able to extend a dataset of head rotations with new samples closely matching the distribution of the measured time series."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Polyp detection in colonoscopy images using YOLOv11", "authors": "Alok Ranjan Sahoo, Satya Sangram Sahoo, Pavan Chakraborty", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Colorectal cancer (CRC) is one of the most commonly diagnosed cancers all over the world. It starts as a polyp in the inner lining of the colon. To prevent CRC, early polyp detection is required. Colonosopy is used for the inspection of the colon. Generally, the images taken by the camera placed at the tip of the endoscope are analyzed by the experts manually. Various traditional machine learning models have been used with the rise of machine learning. Recently, deep learning models have shown more effectiveness in polyp detection due to their superiority in generalizing and learning small features. These deep learning models for object detection can be segregated into two different types: single-stage and two-stage. Generally, two stage models have higher accuracy than single stage ones but the single stage models have low inference time. Hence, single stage models are easy to use for quick object detection. YOLO is one of the singlestage models used successfully for polyp detection. It has drawn the attention of researchers because of its lower inference time. The researchers have used Different versions of YOLO so far, and with each newer version, the accuracy of the model is increasing. This paper aims to see the effectiveness of the recently released YOLOv11 to detect polyp. We analyzed the performance for all five models of YOLOv11 (YOLO11n, YOLO11s, YOLO11m, YOLO11l, YOLO11x) with Kvasir dataset for the training and testing. Two different versions of the dataset were used. The first consisted of the original dataset, and the other was created using augmentation techniques. The performance of all the models with these two versions of the dataset have been analysed."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SHYI: Action Support for Contrastive Learning in High-Fidelity Text-to-Image Generation", "authors": "Tianxiang Xia, Lin Xiao, Yannick Montorfani, Francesco Pavia, Enis Simsar, Thomas Hofmann", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "In this project, we address the issue of infidelity in text-to-image generation, particularly for actions involving multiple objects. For this we build on top of the CONFORM framework which uses Contrastive Learning to improve the accuracy of the generated image for multiple objects. However the depiction of actions which involves multiple different object has still large room for improvement. To improve, we employ semantically hypergraphic contrastive adjacency learning, a comprehension of enhanced contrastive structure and \"contrast but link\" technique. We further amend Stable Diffusion's understanding of actions by InteractDiffusion. As evaluation metrics we use image-text similarity CLIP and TIFA. In addition, we conducted a user study. Our method shows promising results even with verbs that Stable Diffusion understands mediocrely. We then provide future directions by analyzing the results. Our codebase can be found on polybox under the link: this https URL"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Decompose-ToM: Enhancing Theory of Mind Reasoning in Large Language Models through Simulation and Task Decomposition", "authors": "Sneheel Sarangi, Maha Elgarf, Hanan Salam", "subjects": "Subjects:\nComputation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "Theory of Mind (ToM) is the ability to understand and reflect on the mental states of others. Although this capability is crucial for human interaction, testing on Large Language Models (LLMs) reveals that they possess only a rudimentary understanding of it. Although the most capable closed-source LLMs have come close to human performance on some ToM tasks, they still perform poorly on complex variations of the task that involve more structured reasoning. In this work, we utilize the concept of \"pretend-play\", or ``Simulation Theory'' from cognitive psychology to propose ``Decompose-ToM'': an LLM-based inference algorithm that improves model performance on complex ToM tasks. We recursively simulate user perspectives and decompose the ToM task into a simpler set of functions: subject identification, question-reframing, world model updation, and knowledge availability. We test the algorithm on higher-order ToM tasks and a task testing for ToM capabilities in a conversational setting, demonstrating that our approach shows significant improvement across models compared to baseline methods while requiring minimal prompt tuning across tasks and no additional model training."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Average-Reward Reinforcement Learning with Entropy Regularization", "authors": "Jacob Adamczyk, Volodymyr Makarenko, Stas Tiomkin, Rahul V. Kulkarni", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "The average-reward formulation of reinforcement learning (RL) has drawn increased interest in recent years due to its ability to solve temporally-extended problems without discounting. Independently, RL algorithms have benefited from entropy-regularization: an approach used to make the optimal policy stochastic, thereby more robust to noise. Despite the distinct benefits of the two approaches, the combination of entropy regularization with an average-reward objective is not well-studied in the literature and there has been limited development of algorithms for this setting. To address this gap in the field, we develop algorithms for solving entropy-regularized average-reward RL problems with function approximation. We experimentally validate our method, comparing it with existing algorithms on standard benchmarks for RL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Inferring Transition Dynamics from Value Functions", "authors": "Jacob Adamczyk", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "In reinforcement learning, the value function is typically trained to solve the Bellman equation, which connects the current value to future values. This temporal dependency hints that the value function may contain implicit information about the environment's transition dynamics. By rearranging the Bellman equation, we show that a converged value function encodes a model of the underlying dynamics of the environment. We build on this insight to propose a simple method for inferring dynamics models directly from the value function, potentially mitigating the need for explicit model learning. Furthermore, we explore the challenges of next-state identifiability, discussing conditions under which the inferred dynamics model is well-defined. Our work provides a theoretical foundation for leveraging value functions in dynamics modeling and opens a new avenue for bridging model-free and model-based reinforcement learning."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Salient Information Preserving Adversarial Training Improves Clean and Robust Accuracy", "authors": "Timothy Redgrave, Adam Czajka", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "In this work we introduce Salient Information Preserving Adversarial Training (SIP-AT), an intuitive method for relieving the robustness-accuracy trade-off incurred by traditional adversarial training. SIP-AT uses salient image regions to guide the adversarial training process in such a way that fragile features deemed meaningful by an annotator remain unperturbed during training, allowing models to learn highly predictive non-robust features without sacrificing overall robustness. This technique is compatible with both human-based and automatically generated salience estimates, allowing SIP-AT to be used as a part of human-driven model development without forcing SIP-AT to be reliant upon additional human data. We perform experiments across multiple datasets and architectures and demonstrate that SIP-AT is able to boost the clean accuracy of models while maintaining a high degree of robustness against attacks at multiple epsilon levels. We complement our central experiments with an observational study measuring the rate at which human subjects successfully identify perturbed images. This study helps build a more intuitive understanding of adversarial attack strength and demonstrates the heightened importance of low-epsilon robustness. Our results demonstrate the efficacy of SIP-AT and provide valuable insight into the risks posed by adversarial samples of various strengths."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A simpler QPTAS for scheduling jobs with precedence constraints", "authors": "Syamantak Das, Andreas Wiese", "subjects": "Subjects:\nData Structures and Algorithms (cs.DS)", "abstract": "We study the classical scheduling problem of minimizing the makespan of a set of unit size jobs with precedence constraints on parallel identical machines. Research on the problem dates back to the landmark paper by Graham from 1966 who showed that the simple List Scheduling algorithm is a $(2-\\frac{1}{m})$-approximation. Interestingly, it is open whether the problem is NP-hard if $m=3$ which is one of the few remaining open problems in the seminal book by Garey and Johnson. Recently, quite some progress has been made for the setting that $m$ is a constant. In a break-through paper, Levey and Rothvoss presented a $(1+\\epsilon)$-approximation with a running time of $n^{(\\log n)^{O((m^{2}/\\epsilon^{2})\\log\\log n)}}$[STOC 2016, SICOMP 2019] and this running time was improved to quasi-polynomial by Garg[ICALP 2018] and to even $n^{O_{m,\\epsilon}(\\log^{3}\\log n)}$ by Li[SODA 2021]. These results use techniques like LP-hierarchies, conditioning on certain well-selected jobs, and abstractions like (partial) dyadic systems and virtually valid schedules. In this paper, we present a QPTAS for the problem which is arguably simpler than the previous algorithms. We just guess the positions of certain jobs in the optimal solution, recurse on a set of guessed subintervals, and fill in the remaining jobs with greedy routines. We believe that also our analysis is more accessible, in particular since we do not use (LP-)hierarchies or abstractions of the problem like the ones above, but we guess properties of the optimal solution directly."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SteLLA: A Structured Grading System Using LLMs with RAG", "authors": "Hefei Qiu, Brian White, Ashley Ding, Reinaldo Costa, Ali Hachem, Wei Ding, Ping Chen", "subjects": "Subjects:\nComputation and Language (cs.CL); Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "abstract": "Large Language Models (LLMs) have shown strong general capabilities in many applications. However, how to make them reliable tools for some specific tasks such as automated short answer grading (ASAG) remains a challenge. We present SteLLA (Structured Grading System Using LLMs with RAG) in which a) Retrieval Augmented Generation (RAG) approach is used to empower LLMs specifically on the ASAG task by extracting structured information from the highly relevant and reliable external knowledge based on the instructor-provided reference answer and rubric, b) an LLM performs a structured and question-answering-based evaluation of student answers to provide analytical grades and feedback. A real-world dataset that contains students' answers in an exam was collected from a college-level Biology course. Experiments show that our proposed system can achieve substantial agreement with the human grader while providing break-down grades and feedback on all the knowledge points examined in the problem. A qualitative and error analysis of the feedback generated by GPT4 shows that GPT4 is good at capturing facts while may be prone to inferring too much implication from the given text in the grading task which provides insights into the usage of LLMs in the ASAG system."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Drama Llama: An LLM-Powered Storylets Framework for Authorable Responsiveness in Interactive Narrative", "authors": "Yuqian Sun, Phoebe J. Wang, John Joon Young Chung, Melissa Roemmele, Taewook Kim, Max Kreminski", "subjects": "Subjects:\nHuman-Computer Interaction (cs.HC)", "abstract": "In this paper, we present Drama Llama, an LLM-powered storylets framework that supports the authoring of responsive, open-ended interactive stories. DL combines the structural benefits of storylet-based systems with the generative capabilities of large language models, enabling authors to create responsive interactive narratives while maintaining narrative control. Rather than crafting complex logical preconditions in a general-purpose or domain-specific programming language, authors define triggers in natural language that fire at appropriate moments in the story. Through a preliminary authoring study with six content authors, we present initial evidence that DL can generate coherent and meaningful narratives with believable character interactions. This work suggests directions for hybrid approaches that enhance authorial control while supporting emergent narrative generation through LLMs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Tracking the Takes and Trajectories of English-Language News Narratives across Trustworthy and Worrisome Websites", "authors": "Hans W. A. Hanley, Emily Okabe, Zakir Durumeric", "subjects": "Subjects:\nSocial and Information Networks (cs.SI); Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)", "abstract": "Understanding how misleading and outright false information enters news ecosystems remains a difficult challenge that requires tracking how narratives spread across thousands of fringe and mainstream news websites. To do this, we introduce a system that utilizes encoder-based large language models and zero-shot stance detection to scalably identify and track news narratives and their attitudes across over 4,000 factually unreliable, mixed-reliability, and factually reliable English-language news websites. Running our system over an 18 month period, we track the spread of 146K news stories. Using network-based interference via the NETINF algorithm, we show that the paths of news narratives and the stances of websites toward particular entities can be used to uncover slanted propaganda networks (e.g., anti-vaccine and anti-Ukraine) and to identify the most influential websites in spreading these attitudes in the broader news ecosystem. We hope that increased visibility into our distributed news ecosystem can help with the reporting and fact-checking of propaganda and disinformation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Similarity-Quantized Relative Difference Learning for Improved Molecular Activity Prediction", "authors": "Karina Zadorozhny, Kangway V. Chuang, Bharath Sathappan, Ewan Wallace, Vishnu Sresht, Colin A. Grambow", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "Accurate prediction of molecular activities is crucial for efficient drug discovery, yet remains challenging due to limited and noisy datasets. We introduce Similarity-Quantized Relative Learning (SQRL), a learning framework that reformulates molecular activity prediction as relative difference learning between structurally similar pairs of compounds. SQRL uses precomputed molecular similarities to enhance training of graph neural networks and other architectures, and significantly improves accuracy and generalization in low-data regimes common in drug discovery. We demonstrate its broad applicability and real-world potential through benchmarking on public datasets as well as proprietary industry data. Our findings demonstrate that leveraging similarity-aware relative differences provides an effective paradigm for molecular activity prediction."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Non-autoregressive Model for Joint STT and TTS", "authors": "Vishal Sunder, Brian Kingsbury, George Saon, Samuel Thomas, Slava Shechtman Hagai Aronowitz, Eric Fosler-Lussier, Luis Lastras", "subjects": "Subjects:\nSound (cs.SD); Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)", "abstract": "In this paper, we take a step towards jointly modeling automatic speech recognition (STT) and speech synthesis (TTS) in a fully non-autoregressive way. We develop a novel multimodal framework capable of handling the speech and text modalities as input either individually or together. The proposed model can also be trained with unpaired speech or text data owing to its multimodal nature. We further propose an iterative refinement strategy to improve the STT and TTS performance of our model such that the partial hypothesis at the output can be fed back to the input of our model, thus iteratively improving both STT and TTS predictions. We show that our joint model can effectively perform both STT and TTS tasks, outperforming the STT-specific baseline in all tasks and performing competitively with the TTS-specific baseline across a wide range of evaluation metrics."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Physical Layer Security in FAS-aided Wireless Powered NOMA Systems", "authors": "Farshad Rostami Ghadi, Masoud Kaveh, Kai-Kit Wong, Diego Martin, Riku Jantti, Zheng Yan", "subjects": "Subjects:\nInformation Theory (cs.IT); Signal Processing (eess.SP)", "abstract": "The rapid evolution of communication technologies and the emergence of sixth-generation (6G) networks have introduced unprecedented opportunities for ultra-reliable, low-latency, and energy-efficient communication. However, the integration of advanced technologies like non-orthogonal multiple access (NOMA) and wireless powered communication networks (WPCNs) brings significant challenges, particularly in terms of energy constraints and security vulnerabilities. Traditional antenna systems and orthogonal multiple access schemes struggle to meet the increasing demands for performance and security in such environments. To address this gap, this paper investigates the impact of emerging fluid antenna systems (FAS) on the performance of physical layer security (PLS) in WPCNs. Specifically, we consider a scenario in which a transmitter, powered by a power beacon via an energy link, transmits confidential messages to legitimate FAS-aided users over information links while an external eavesdropper attempts to decode the transmitted signals. Additionally, users leverage the NOMA scheme, where the far user may also act as an internal eavesdropper. For the proposed model, we first derive the distributions of the equivalent channels at each node and subsequently obtain compact expressions for the secrecy outage probability (SOP) and average secrecy capacity (ASC), using the Gaussian quadrature methods. Our results reveal that incorporating the FAS for NOMA users, instead of the TAS, enhances the performance of the proposed secure WPCN."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Rethinking Post-Training Quantization: Introducing a Statistical Pre-Calibration Approach", "authors": "Alireza Ghaffari, Sharareh Younesian, Boxing Chen, Vahid Partovi Nia, Masoud Asgharian", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "As Large Language Models (LLMs) become increasingly computationally complex, developing efficient deployment strategies, such as quantization, becomes crucial. State-of-the-art Post-training Quantization (PTQ) techniques often rely on calibration processes to maintain the accuracy of these models. However, while these calibration techniques can enhance performance in certain domains, they may not be as effective in others. This paper aims to draw attention to robust statistical approaches that can mitigate such issues. We propose a weight-adaptive PTQ method that can be considered a precursor to calibration-based PTQ methods, guiding the quantization process to preserve the distribution of weights by minimizing the Kullback-Leibler divergence between the quantized weights and the originally trained weights. This minimization ensures that the quantized model retains the Shannon information content of the original model to a great extent, guaranteeing robust and efficient deployment across many tasks. As such, our proposed approach can perform on par with most common calibration-based PTQ methods, establishing a new pre-calibration step for further adjusting the quantized weights with calibration. We show that our pre-calibration results achieve the same accuracy as some existing calibration-based PTQ methods on various LLMs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Generative Medical Image Anonymization Based on Latent Code Projection and Optimization", "authors": "Huiyu Li, Nicholas Ayache, Herv\u00e9 Delingette", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Medical image anonymization aims to protect patient privacy by removing identifying information, while preserving the data utility to solve downstream tasks. In this paper, we address the medical image anonymization problem with a two-stage solution: latent code projection and optimization. In the projection stage, we design a streamlined encoder to project input images into a latent space and propose a co-training scheme to enhance the projection process. In the optimization stage, we refine the latent code using two deep loss functions designed to address the trade-off between identity protection and data utility dedicated to medical images. Through a comprehensive set of qualitative and quantitative experiments, we showcase the effectiveness of our approach on the MIMIC-CXR chest X-ray dataset by generating anonymized synthetic images that can serve as training set for detecting lung pathologies. Source codes are available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Multi-Class Traffic Assignment using Multi-View Heterogeneous Graph Attention Networks", "authors": "Tong Liu, Hadi Meidani", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "Solving traffic assignment problem for large networks is computationally challenging when conventional optimization-based methods are used. In our research, we develop an innovative surrogate model for a traffic assignment when multi-class vehicles are involved. We do so by employing heterogeneous graph neural networks which use a multiple-view graph attention mechanism tailored to different vehicle classes, along with additional links connecting origin-destination pairs. We also integrate the node-based flow conservation law into the loss function. As a result, our model adheres to flow conservation while delivering highly accurate predictions for link flows and utilization ratios. Through numerical experiments conducted on urban transportation networks, we demonstrate that our model surpasses traditional neural network approaches in convergence speed and predictive accuracy in both user equilibrium and system optimal versions of traffic assignment."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Stream-HLS: Towards Automatic Dataflow Acceleration", "authors": "Suhail Basalama, Jason Cong", "subjects": "Subjects:\nHardware Architecture (cs.AR)", "abstract": "High-level synthesis (HLS) has enabled the rapid development of custom hardware circuits for many software applications. However, developing high-performance hardware circuits using HLS is still a non-trivial task requiring expertise in hardware design. Further, the hardware design space, especially for multi-kernel applications, grows exponentially. Therefore, several HLS automation and abstraction frameworks have been proposed recently, but many issues remain unresolved. These issues include: 1) relying mainly on hardware directives (pragmas) to apply hardware optimizations without exploring loop scheduling opportunities. 2) targeting single-kernel applications only. 3) lacking automatic and/or global design space exploration. 4) missing critical hardware optimizations, such as graph-level pipelining for multi-kernel applications. To address these challenges, we propose a novel methodology and framework on top of the popular multi-level intermediate representation (MLIR) infrastructure called Stream-HLS. Our framework takes a C/C++ or PyTorch software code and automatically generates an optimized dataflow architecture along with host code for field-programmable gate arrays (FPGAs). To achieve this, we developed an accurate analytical performance model for global scheduling and optimization of dataflow architectures. Stream-HLS is evaluated using various standard HLS benchmarks and real-world benchmarks from transformer models, convolution neural networks, and multilayer perceptrons. Stream-HLS designs outperform the designs of prior state-of-the-art automation frameworks and manually-optimized designs of abstraction frameworks by up to $79.43\\times$ and $10.62\\times$ geometric means respectively. Finally, the Stream-HLS framework is modularized, extensible, and open-sourced at \\url{this https URL} (\\url{this https URL})."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Adaptive boundary element methods for regularized combined field integral equations", "authors": "Th\u00e9ophile Chaumont-Frelet, Gregor Gantner", "subjects": "Subjects:\nNumerical Analysis (math.NA)", "abstract": "While the exterior Helmholtz problem with Dirichlet boundary conditions is always well-posed, the associated standard boundary integral equations are not if the squared wavenumber agrees with an eigenvalue of the interior Dirichlet problem. Combined field integral equations are not affected by this spurious resonances but are essentially restricted to sufficiently smooth boundaries. For general Lipschitz domains, the latter integral equations are applicable through suitable regularization. Under fairly general assumptions on the regularizing operator, we propose {\\sl a posterirori} computable error estimators for corresponding Galerkin boundary element methods of arbitrary polynomial degree. We show that adaptive mesh-refining algorithms steered by these local estimators converge at optimal algebraic rate with respect to the number of underlying boundary mesh elements. In particular, we consider mixed formulations involving the inverse Laplace--Beltrami as regularizing operator. Numerical examples highlight that in the vicinity of spurious resonances the proposed adaptive algorithm is significantly more performant when applied to the regularized combined field equation rather than the standard one."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Intelligent Backhaul Link Selection for Traffic Offloading in B5G Networks", "authors": "Ant\u00f3nio J. Morgado, Firooz B. Saghezchi, Pablo Fondo-Ferreiro, Felipe Gil-Casti\u00f1eira, Jonathan Rodriguez", "subjects": "Subjects:\nNetworking and Internet Architecture (cs.NI)", "abstract": "Fifth Generation (5G) mobile networks considers an expansive set of heterogeneous services with stringent Quality of Service (QoS) requirements, and traffic demand with inherent spatial-temporal distribution, which places the backhaul network deployment under potential strain. In this paper, we propose to harness network slicing, Integrated Access and Backhaul (IAB) technology coupled with satellite connectivity to build a dynamic wireless backhaul network that can provide additional backhaul capacity to the base stations on demand when the wired backhaul link is temporarily out of capacity. To construct the network design, Deep Reinforcement Learning (DRL) models are used to select, for each network slice of the congested base station, an appropriate backhaul link from the pool of available IAB and satellite links that meets the QoS requirements (i.e., throughput and latency) of the slice. Simulation results show that around 20 episodes are sufficient to train a Double Deep Q-Network (DDQN) agent, with one fully-connected hidden layer and Rectified Linear Unit (ReLU) activation function, that adjusts the topology of the backhaul network."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          5G Network Slicing as a Service Enabler for theAutomotive Sector", "authors": "David Candal-Ventureira, Jos\u00e9 Manuel R\u00faa-Est\u00e9vez, Pablo Fondo-Ferreiro, Felipe Gil-Casti\u00f1eira, Antonio Fern\u00e1ndez-Barciela, Francisco Javier Gonz\u00e1lez-Casta\u00f1o, Emilio Di\u00e9guez-Pazo, Luis Fern\u00e1ndez-Ferreira", "subjects": "Subjects:\nNetworking and Internet Architecture (cs.NI)", "abstract": "Network slicing, a key technology introduced in 5G standards, enables mobile networks to simultaneously support a wide range ofheterogeneous use cases with diverse quality of service (QoS) requirements. This work discusses the potential benefits of networkslicing for the automotive sector, encompassing manufacturing processes and vehicular communications. The review of the stateof the art reveals a clear gap regarding the application of network slicing from the perspective of industrial verticals such asautomotive use cases and their specific requirements. Departing from this observation, we first identify limitations of previouscellular technologies and open challenges for supporting the data services required. Then we describe network slicing as an enablerto face these challenges. We present an analysis of the cost equilibrium for network slicing to be effective for car manufacturers,and tests in real 5G networks that demonstrate the performance improvement in OTA updates coexisting with other services."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Augmenting Human-Annotated Training Data with Large Language Model Generation and Distillation in Open-Response Assessment", "authors": "Conrad Borchers, Danielle R. Thomas, Jionghao Lin, Ralph Abboud, Kenneth R. Koedinger", "subjects": "Subjects:\nComputation and Language (cs.CL); Computers and Society (cs.CY); Machine Learning (cs.LG)", "abstract": "Large Language Models (LLMs) like GPT-4o can help automate text classification tasks at low cost and scale. However, there are major concerns about the validity and reliability of LLM outputs. By contrast, human coding is generally more reliable but expensive to procure at scale. In this study, we propose a hybrid solution to leverage the strengths of both. We combine human-coded data and synthetic LLM-produced data to fine-tune a classical machine learning classifier, distilling both into a smaller BERT model. We evaluate our method on a human-coded test set as a validity measure for LLM output quality. In three experiments, we systematically vary LLM-generated samples' size, variety, and consistency, informed by best practices in LLM tuning. Our findings indicate that augmenting datasets with synthetic samples improves classifier performance, with optimal results achieved at an 80% synthetic to 20% human-coded data ratio. Lower temperature settings of 0.3, corresponding to less variability in LLM generations, produced more stable improvements but also limited model learning from augmented samples. In contrast, higher temperature settings (0.7 and above) introduced greater variability in performance estimates and, at times, lower performance. Hence, LLMs may produce more uniform output that classifiers overfit to earlier or produce more diverse output that runs the risk of deteriorating model performance through information irrelevant to the prediction task. Filtering out inconsistent synthetic samples did not enhance performance. We conclude that integrating human and LLM-generated data to improve text classification models in assessment offers a scalable solution that leverages both the accuracy of human coding and the variety of LLM outputs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Multilingual LLMs Struggle to Link Orthography and Semantics in Bilingual Word Processing", "authors": "Eshaan Tanwar, Gayatri Oke, Tanmoy Chakraborty", "subjects": "Subjects:\nComputation and Language (cs.CL)", "abstract": "Bilingual lexical processing is shaped by the complex interplay of phonological, orthographic, and semantic features of two languages within an integrated mental lexicon. In humans, this is evident in the ease with which cognate words - words similar in both orthographic form and meaning (e.g., blind, meaning \"sightless\" in both English and German) - are processed, compared to the challenges posed by interlingual homographs, which share orthographic form but differ in meaning (e.g., gift, meaning \"present\" in English but \"poison\" in German). We investigate how multilingual Large Language Models (LLMs) handle such phenomena, focusing on English-Spanish, English-French, and English-German cognates, non-cognate, and interlingual homographs. Specifically, we evaluate their ability to disambiguate meanings and make semantic judgments, both when these word types are presented in isolation or within sentence contexts. Our findings reveal that while certain LLMs demonstrate strong performance in recognizing cognates and non-cognates in isolation, they exhibit significant difficulty in disambiguating interlingual homographs, often performing below random baselines. This suggests LLMs tend to rely heavily on orthographic similarities rather than semantic understanding when interpreting interlingual homographs. Further, we find LLMs exhibit difficulty in retrieving word meanings, with performance in isolative disambiguation tasks having no correlation with semantic understanding. Finally, we study how the LLM processes interlingual homographs in incongruent sentences. We find models to opt for different strategies in understanding English and non-English homographs, highlighting a lack of a unified approach to handling cross-lingual ambiguities."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Deep Self-Supervised Disturbance Mapping with the OPERA Sentinel-1 Radiometric Terrain Corrected SAR Backscatter Product", "authors": "Harris Hardiman-Mostow, Charles Marshak, Alexander L. Handwerger", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Image and Video Processing (eess.IV)", "abstract": "Mapping land surface disturbances supports disaster response, resource and ecosystem management, and climate adaptation efforts. Synthetic aperture radar (SAR) is an invaluable tool for disturbance mapping, providing consistent time-series images of the ground regardless of weather or illumination conditions. Despite SAR's potential for disturbance mapping, processing SAR data to an analysis-ready format requires expertise and significant compute resources, particularly for large-scale global analysis. In October 2023, NASA's Observational Products for End-Users from Remote Sensing Analysis (OPERA) project released the near-global Radiometric Terrain Corrected SAR backscatter from Sentinel-1 (RTC-S1) dataset, providing publicly available, analysis-ready SAR imagery. In this work, we utilize this new dataset to systematically analyze land surface disturbances. As labeling SAR data is often prohibitively time-consuming, we train a self-supervised vision transformer - which requires no labels to train - on OPERA RTC-S1 data to estimate a per-pixel distribution from the set of baseline imagery and assess disturbances when there is significant deviation from the modeled distribution. To test our model's capability and generality, we evaluate three different natural disasters - which represent high-intensity, abrupt disturbances - from three different regions of the world. Across events, our approach yields high quality delineations: F1 scores exceeding 0.6 and Areas Under the Precision-Recall Curve exceeding 0.65, consistently outperforming existing SAR disturbance methods. Our findings suggest that a self-supervised vision transformer is well-suited for global disturbance mapping and can be a valuable tool for operational, near-global disturbance monitoring, particularly when labeled data does not exist."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Benchmarking Robustness of Contrastive Learning Models for Medical Image-Report Retrieval", "authors": "Demetrio Deanda, Yuktha Priya Masupalli, Jeong Yang, Young Lee, Zechun Cao, Gongbo Liang", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Information Retrieval (cs.IR); Machine Learning (cs.LG)", "abstract": "Medical images and reports offer invaluable insights into patient health. The heterogeneity and complexity of these data hinder effective analysis. To bridge this gap, we investigate contrastive learning models for cross-domain retrieval, which associates medical images with their corresponding clinical reports. This study benchmarks the robustness of four state-of-the-art contrastive learning models: CLIP, CXR-RePaiR, MedCLIP, and CXR-CLIP. We introduce an occlusion retrieval task to evaluate model performance under varying levels of image corruption. Our findings reveal that all evaluated models are highly sensitive to out-of-distribution data, as evidenced by the proportional decrease in performance with increasing occlusion levels. While MedCLIP exhibits slightly more robustness, its overall performance remains significantly behind CXR-CLIP and CXR-RePaiR. CLIP, trained on a general-purpose dataset, struggles with medical image-report retrieval, highlighting the importance of domain-specific training data. The evaluation of this work suggests that more effort needs to be spent on improving the robustness of these models. By addressing these limitations, we can develop more reliable cross-domain retrieval models for medical applications."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          HAFix: History-Augmented Large Language Models for Bug Fixing", "authors": "Yu Shi, Abdul Ali Bangash, Emad Fallahzadeh, Bram Adams, Ahmed E. Hassan", "subjects": "Subjects:\nSoftware Engineering (cs.SE)", "abstract": "Recent studies have explored the performance of Large Language Models (LLMs) on various Software Engineering (SE) tasks, such as code generation and bug fixing. However, these approaches typically rely on the context data from the current snapshot of the project, overlooking the potential of rich historical data from real-world software repositories. Additionally, the impact of prompt styles on LLM performance within a historical context remains underexplored. To address these gaps, we propose HAFix, which stands for History-Augmented LLMs on Bug Fixing, a novel approach that leverages individual historical heuristics associated with bugs and aggregates the results of these heuristics (HAFix-Agg) to enhance LLMs' bug-fixing capabilities. To empirically evaluate HAFix, we employ Code Llama on a dataset of 51 single-line bugs, sourced from 11 open-source projects, by mining the historical context data of bugs and operationalizing this context in the form of seven heuristics. Our evaluation demonstrates that historical heuristics significantly enhance bug-fixing performance. For example, the FLN-all heuristic achieves a 10% improvement in performance compared to a non-historical baseline inspired by GitHub Copilot. Furthermore, HAFix-Agg fixes 45% more bugs than the baseline, outperforming FLN-all and demonstrating the best performance overall. Moreover, within the context of historical heuristics, we identify the Instruction style prompt as the most effective template for LLMs in bug fixing. Finally, we provide a pragmatic trade-off analysis of bug-fixing performance, cost, and time efficiency, offering valuable insights for the practical deployment of our approach in real-world scenarios."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Agentic Retrieval-Augmented Generation: A Survey on Agentic RAG", "authors": "Aditi Singh, Abul Ehtesham, Saket Kumar, Tala Talaei Khoei", "subjects": "Subjects:\nArtificial Intelligence (cs.AI); Computation and Language (cs.CL); Information Retrieval (cs.IR)", "abstract": "Large Language Models (LLMs) have revolutionized artificial intelligence (AI) by enabling human like text generation and natural language understanding. However, their reliance on static training data limits their ability to respond to dynamic, real time queries, resulting in outdated or inaccurate outputs. Retrieval Augmented Generation (RAG) has emerged as a solution, enhancing LLMs by integrating real time data retrieval to provide contextually relevant and up-to-date responses. Despite its promise, traditional RAG systems are constrained by static workflows and lack the adaptability required for multistep reasoning and complex task management. Agentic Retrieval-Augmented Generation (Agentic RAG) transcends these limitations by embedding autonomous AI agents into the RAG pipeline. These agents leverage agentic design patterns reflection, planning, tool use, and multiagent collaboration to dynamically manage retrieval strategies, iteratively refine contextual understanding, and adapt workflows to meet complex task requirements. This integration enables Agentic RAG systems to deliver unparalleled flexibility, scalability, and context awareness across diverse applications. This survey provides a comprehensive exploration of Agentic RAG, beginning with its foundational principles and the evolution of RAG paradigms. It presents a detailed taxonomy of Agentic RAG architectures, highlights key applications in industries such as healthcare, finance, and education, and examines practical implementation strategies. Additionally, it addresses challenges in scaling these systems, ensuring ethical decision making, and optimizing performance for real-world applications, while providing detailed insights into frameworks and tools for implementing Agentic RAG"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Gradient Descent Converges Linearly to Flatter Minima than Gradient Flow in Shallow Linear Networks", "authors": "Pierfrancesco Beneventano, Blake Woodworth", "subjects": "Subjects:\nMachine Learning (cs.LG); Optimization and Control (math.OC); Machine Learning (stat.ML)", "abstract": "We study the gradient descent (GD) dynamics of a depth-2 linear neural network with a single input and output. We show that GD converges at an explicit linear rate to a global minimum of the training loss, even with a large stepsize--about $2/\\textrm{sharpness}$. It still converges for even larger stepsizes, but may do so very slowly. We also characterize the solution to which GD converges, which has lower norm and sharpness than the gradient flow solution. Our analysis reveals a trade off between the speed of convergence and the magnitude of implicit regularization. This sheds light on the benefits of training at the ``Edge of Stability'', which induces additional regularization by delaying convergence and may have implications for training more complex models."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Few-Shot Adaptation of Training-Free Foundation Model for 3D Medical Image Segmentation", "authors": "Xingxin He, Yifan Hu, Zhaoye Zhou, Mohamed Jarraya, Fang Liu", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Vision foundation models have achieved remarkable progress across various image analysis tasks. In the image segmentation task, foundation models like the Segment Anything Model (SAM) enable generalizable zero-shot segmentation through user-provided prompts. However, SAM primarily trained on natural images, lacks the domain-specific expertise of medical imaging. This limitation poses challenges when applying SAM to medical image segmentation, including the need for extensive fine-tuning on specialized medical datasets and a dependency on manual prompts, which are both labor-intensive and require intervention from medical experts. This work introduces the Few-shot Adaptation of Training-frEe SAM (FATE-SAM), a novel method designed to adapt the advanced Segment Anything Model 2 (SAM2) for 3D medical image segmentation. FATE-SAM reassembles pre-trained modules of SAM2 to enable few-shot adaptation, leveraging a small number of support examples to capture anatomical knowledge and perform prompt-free segmentation, without requiring model fine-tuning. To handle the volumetric nature of medical images, we incorporate a Volumetric Consistency mechanism that enhances spatial coherence across 3D slices. We evaluate FATE-SAM on multiple medical imaging datasets and compare it with supervised learning methods, zero-shot SAM approaches, and fine-tuned medical SAM methods. Results show that FATE-SAM delivers robust and accurate segmentation while eliminating the need for large annotated datasets and expert intervention. FATE-SAM provides a practical, efficient solution for medical image segmentation, making it more accessible for clinical applications."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Reducing real-time complexity via sub-control Lyapunov functions: from theory to experiments", "authors": "Huu-Thinh Do, Franco Blanchini, Stefano Miani, Ionela Prodan", "subjects": "Subjects:\nSystems and Control (eess.SY); Optimization and Control (math.OC)", "abstract": "The techniques to design control Lyapunov functions (CLF), along with a proper stabilizing feedback, possibly in the presence of constraints, often provide control laws that are too complex for proper implementation online, especially when an optimization problem is involved. In this work, we show how to acquire an alternative, computationally attractive feedback. Given a nominal CLF and a nominal state feedback, we say that a different positive definite function is a Sub-control Lyapunov function (SCLF) if its Lyapunov derivative is negative-definite and bounded above by the Lyapunov derivative of the nominal function with the nominal control. It turns out that if we consider a family of basis functions, then a SCLF can be computed by linear programming, with an infinite number of constraints. The idea is that although the offline computational burden to achieve the new controller and solve the linear program is considerable, the online computational burden is drastically reduced. Comprehensive simulations and experiments on drone control are conducted to demonstrate the effectiveness of the study."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Rule-Based Graph Programs Matching the Time Complexity of Imperative Algorithms", "authors": "Ziad Ismaili Alaoui, Detlef Plump", "subjects": "Subjects:\nProgramming Languages (cs.PL); Performance (cs.PF)", "abstract": "We report on a recent breakthrough in rule-based graph programming, which allows us to match the time complexity of some fundamental imperative graph algorithms. In general, achieving the complexity of graph algorithms in conventional languages using graph transformation rules is challenging due to the cost of graph matching. Previous work demonstrated that with rooted rules, certain algorithms can be implemented in the graph programming language GP 2 such that their runtime matches the time complexity of imperative implementations. However, this required input graphs to have a bounded node degree and (for some algorithms) to be connected. In this paper, we overcome these limitations by enhancing the graph data structure generated by the GP 2 compiler and exploiting the new structure in programs. We present three case studies: the first program checks whether input graphs are connected, the second program checks whether input graphs are acyclic, and the third program solves the single-source shortest-paths problem for graphs with integer edge-weights. The first two programs run in linear time on (possibly disconnected) input graphs with arbitrary node degrees. The third program runs in time O(nm) on arbitrary input graphs, matching the time complexity of imperative implementations of the Bellman-Ford algorithm. For each program, we formally prove its correctness and time complexity, and provide runtime experiments on various graph classes."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Towards Federated Multi-Armed Bandit Learning for Content Dissemination using Swarm of UAVs", "authors": "Amit Kumar Bhuyan, Hrishikesh Dutta, Subir Biswas", "subjects": "Subjects:\nMachine Learning (cs.LG); Networking and Internet Architecture (cs.NI)", "abstract": "This paper introduces an Unmanned Aerial Vehicle - enabled content management architecture that is suitable for critical content access in communities of users that are communication-isolated during diverse types of disaster scenarios. The proposed architecture leverages a hybrid network of stationary anchor UAVs and mobile Micro-UAVs for ubiquitous content dissemination. The anchor UAVs are equipped with both vertical and lateral communication links, and they serve local users, while the mobile micro-ferrying UAVs extend coverage across communities with increased mobility. The focus is on developing a content dissemination system that dynamically learns optimal caching policies to maximize content availability. The core innovation is an adaptive content dissemination framework based on distributed Federated Multi-Armed Bandit learning. The goal is to optimize UAV content caching decisions based on geo-temporal content popularity and user demand variations. A Selective Caching Algorithm is also introduced to reduce redundant content replication by incorporating inter-UAV information sharing. This method strategically preserves the uniqueness in user preferences while amalgamating the intelligence across a distributed learning system. This approach improves the learning algorithm's ability to adapt to diverse user preferences. Functional verification and performance evaluation confirm the proposed architecture's utility across different network sizes, UAV swarms, and content popularity patterns."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Towards Multilingual LLM Evaluation for Baltic and Nordic languages: A study on Lithuanian History", "authors": "Yevhen Kostiuk, Oxana Vitman, \u0141ukasz Gaga\u0142a, Artur Kiulian", "subjects": "Subjects:\nComputation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "In this work, we evaluated Lithuanian and general history knowledge of multilingual Large Language Models (LLMs) on a multiple-choice question-answering task. The models were tested on a dataset of Lithuanian national and general history questions translated into Baltic, Nordic, and other languages (English, Ukrainian, Arabic) to assess the knowledge sharing from culturally and historically connected groups. We evaluated GPT-4o, LLaMa3.1 8b and 70b, QWEN2.5 7b and 72b, Mistral Nemo 12b, LLaMa3 8b, Mistral 7b, LLaMa3.2 3b, and Nordic fine-tuned models (GPT-SW3 and LLaMa3 8b). Our results show that GPT-4o consistently outperformed all other models across language groups, with slightly better results for Baltic and Nordic languages. Larger open-source models like QWEN2.5 72b and LLaMa3.1 70b performed well but showed weaker alignment with Baltic languages. Smaller models (Mistral Nemo 12b, LLaMa3.2 3b, QWEN 7B, LLaMa3.1 8B, and LLaMa3 8b) demonstrated gaps with LT-related alignment with Baltic languages while performing better on Nordic and other languages. The Nordic fine-tuned models did not surpass multilingual models, indicating that shared cultural or historical context alone does not guarantee better performance."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          VCRScore: Image captioning metric based on V\\&L Transformers, CLIP, and precision-recall", "authors": "Guillermo Ruiz, Tania Ram\u00edrez, Daniela Moctezuma", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL)", "abstract": "Image captioning has become an essential Vision & Language research task. It is about predicting the most accurate caption given a specific image or video. The research community has achieved impressive results by continuously proposing new models and approaches to improve the overall model's performance. Nevertheless, despite increasing proposals, the performance metrics used to measure their advances have remained practically untouched through the years. A probe of that, nowadays metrics like BLEU, METEOR, CIDEr, and ROUGE are still very used, aside from more sophisticated metrics such as BertScore and ClipScore. Hence, it is essential to adjust how are measure the advances, limitations, and scopes of the new image captioning proposals, as well as to adapt new metrics to these new advanced image captioning approaches. This work proposes a new evaluation metric for the image captioning problem. To do that, first, it was generated a human-labeled dataset to assess to which degree the captions correlate with the image's content. Taking these human scores as ground truth, we propose a new metric, and compare it with several well-known metrics, from classical to newer ones. Outperformed results were also found, and interesting insights were presented and discussed."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Evaluating GenAI for Simplifying Texts for Education: Improving Accuracy and Consistency for Enhanced Readability", "authors": "Stephanie L. Day, Jacapo Cirica, Steven R. Clapp, Veronika Penkova, Amy E. Giroux, Abbey Banta, Catherine Bordeau, Poojitha Mutteneni, Ben D. Sawyer", "subjects": "Subjects:\nComputation and Language (cs.CL)", "abstract": "Generative artificial intelligence (GenAI) holds great promise as a tool to support personalized learning. Teachers need tools to efficiently and effectively enhance content readability of educational texts so that they are matched to individual students reading levels, while retaining key details. Large Language Models (LLMs) show potential to fill this need, but previous research notes multiple shortcomings in current approaches. In this study, we introduced a generalized approach and metrics for the systematic evaluation of the accuracy and consistency in which LLMs, prompting techniques, and a novel multi-agent architecture to simplify sixty informational reading passages, reducing each from the twelfth grade level down to the eighth, sixth, and fourth grade levels. We calculated the degree to which each LLM and prompting technique accurately achieved the targeted grade level for each passage, percentage change in word count, and consistency in maintaining keywords and key phrases (semantic similarity). One-sample t-tests and multiple regression models revealed significant differences in the best performing LLM and prompt technique for each of the four metrics. Both LLMs and prompting techniques demonstrated variable utility in grade level accuracy and consistency of keywords and key phrases when attempting to level content down to the fourth grade reading level. These results demonstrate the promise of the application of LLMs for efficient and precise automated text simplification, the shortcomings of current models and prompting methods in attaining an ideal balance across various evaluation criteria, and a generalizable method to evaluate future systems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          AutoLoop: Fast Visual SLAM Fine-tuning through Agentic Curriculum Learning", "authors": "Assaf Lahiany, Oren Gal", "subjects": "Subjects:\nRobotics (cs.RO); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Current visual SLAM systems face significant challenges in balancing computational efficiency with robust loop closure handling. Traditional approaches require careful manual tuning and incur substantial computational overhead, while learning-based methods either lack explicit loop closure capabilities or implement them through computationally expensive methods. We present AutoLoop, a novel approach that combines automated curriculum learning with efficient fine-tuning for visual SLAM systems. Our method employs a DDPG (Deep Deterministic Policy Gradient) agent to dynamically adjust loop closure weights during training, eliminating the need for manual hyperparameter search while significantly reducing the required training steps. The approach pre-computes potential loop closure pairs offline and leverages them through an agent-guided curriculum, allowing the model to adapt efficiently to new scenarios. Experiments conducted on TartanAir for training and validated across multiple benchmarks including KITTI, EuRoC, ICL-NUIM and TUM RGB-D demonstrate that AutoLoop achieves comparable or superior performance while reducing training time by an order of magnitude compared to traditional approaches. AutoLoop provides a practical solution for rapid adaptation of visual SLAM systems, automating the weight tuning process that traditionally requires multiple manual iterations. Our results show that this automated curriculum strategy not only accelerates training but also maintains or improves the model's performance across diverse environmental conditions."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Vessel Bifurcation Landmark Pair Dataset for Abdominal CT Deformable Image Registration (DIR) Validation", "authors": "Edward R Criscuolo, Yao Hao, Zhendong Zhang, Trevor McKeown, Deshan Yang", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Medical Physics (physics.med-ph)", "abstract": "Deformable image registration (DIR) is an enabling technology in many diagnostic and therapeutic tasks. Despite this, DIR algorithms have limited clinical use, largely due to a lack of benchmark datasets for quality assurance during development. To support future algorithm development, here we introduce our first-of-its-kind abdominal CT DIR benchmark dataset, comprising large numbers of highly accurate landmark pairs on matching blood vessel bifurcations. Abdominal CT image pairs of 30 patients were acquired from several public repositories as well as the authors' institution with IRB approval. The two CTs of each pair were originally acquired for the same patient on different days. An image processing workflow was developed and applied to each image pair: 1) Abdominal organs were segmented with a deep learning model, and image intensity within organ masks was overwritten. 2) Matching image patches were manually identified between two CTs of each image pair 3) Vessel bifurcation landmarks were labeled on one image of each image patch pair. 4) Image patches were deformably registered, and landmarks were projected onto the second image. 5) Landmark pair locations were refined manually or with an automated process. This workflow resulted in 1895 total landmark pairs, or 63 per case on average. Estimates of the landmark pair accuracy using digital phantoms were 0.7+/-1.2mm. The data is published in Zenodo at this https URL. Instructions for use can be found at this https URL. This dataset is a first-of-its-kind for abdominal DIR validation. The number, accuracy, and distribution of landmark pairs will allow for robust validation of DIR algorithms with precision beyond what is currently available."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Towards Understanding Extrapolation: a Causal Lens", "authors": "Lingjing Kong, Guangyi Chen, Petar Stojanov, Haoxuan Li, Eric P. Xing, Kun Zhang", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)", "abstract": "Canonical work handling distribution shifts typically necessitates an entire target distribution that lands inside the training distribution. However, practical scenarios often involve only a handful of target samples, potentially lying outside the training support, which requires the capability of extrapolation. In this work, we aim to provide a theoretical understanding of when extrapolation is possible and offer principled methods to achieve it without requiring an on-support target distribution. To this end, we formulate the extrapolation problem with a latent-variable model that embodies the minimal change principle in causal mechanisms. Under this formulation, we cast the extrapolation problem into a latent-variable identification problem. We provide realistic conditions on shift properties and the estimation objectives that lead to identification even when only one off-support target sample is available, tackling the most challenging scenarios. Our theory reveals the intricate interplay between the underlying manifold's smoothness and the shift properties. We showcase how our theoretical results inform the design of practical adaptation algorithms. Through experiments on both synthetic and real-world data, we validate our theoretical findings and their practical implications."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          The Veln(ia)s is in the Details: Evaluating LLM Judgment on Latvian and Lithuanian Short Answer Matching", "authors": "Yevhen Kostiuk, Oxana Vitman, \u0141ukasz Gaga\u0142a, Artur Kiulian", "subjects": "Subjects:\nComputation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "In this work, we address the challenge of evaluating large language models (LLMs) on the short answer matching task for Latvian and Lithuanian languages. We introduce novel datasets consisting of 502 Latvian and 690 Lithuanian question-answer pairs. For each question-answer pair, we generated matched and non-matched answers using a set of alteration rules specifically designed to introduce small but meaningful changes in the text. These generated answers serve as test cases to assess the ability of LLMs to detect subtle differences in matching of the original answers. A subset of the datasets was manually verified for quality and accuracy. Our results show that while larger LLMs, such as QWEN2.5 72b and LLaMa3.1 70b, demonstrate near-perfect performance in distinguishing matched and non-matched answers, smaller models show more variance. For instance, LLaMa3.1 8b and EuroLLM 9b benefited from few-shot examples, while Mistral Nemo 12b underperformed on detection of subtle text alteration, particularly in Lithuanian, even with additional examples. QWEN2.5 7b and Mistral 7b were able to obtain a strong and comparable performance to the larger 70b models in zero and few shot experiments. Moreover, the performance of Mistral 7b was weaker in few shot experiments."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Breaking Barriers or Building Dependency? Exploring Team-LLM Collaboration in AI-infused Classroom Debate", "authors": "Zihan Zhang, Black Sun, Pengcheng An", "subjects": "Subjects:\nHuman-Computer Interaction (cs.HC)", "abstract": "Classroom debates are a unique form of collaborative learning characterized by fast-paced, high-intensity interactions that foster critical thinking and teamwork. Despite the recognized importance of debates, the role of AI tools, particularly LLM-based systems, in supporting this dynamic learning environment has been under-explored in HCI. This study addresses this opportunity by investigating the integration of LLM-based AI into real-time classroom debates. Over four weeks, 22 students in a Design History course participated in three rounds of debates with support from ChatGPT. The findings reveal how learners prompted the AI to offer insights, collaboratively processed its outputs, and divided labor in team-AI interactions. The study also surfaces key advantages of AI usage, reducing social anxiety, breaking communication barriers, and providing scaffolding for novices, alongside risks, such as information overload and cognitive dependency, which could limit learners' autonomy. We thereby discuss a set of nuanced implications for future HCI exploration."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Attention is All You Need Until You Need Retention", "authors": "M. Murat Yaslioglu", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "This work introduces a novel Retention Layer mechanism for Transformer based architectures, addressing their inherent lack of intrinsic retention capabilities. Unlike human cognition, which can encode and dynamically recall symbolic templates, Generative Pretrained Transformers rely solely on fixed pretrained weights and ephemeral context windows, limiting their adaptability. The proposed Retention Layer incorporates a persistent memory module capable of real time data population, dynamic recall, and guided output generation. This enhancement allows models to store, update, and reuse observed patterns across sessions, enabling incremental learning and bridging the gap between static pretraining and dynamic, context sensitive adaptation. The Retention Layer design parallels social learning processes, encompassing attention, retention, reproduction, and motivation stages. Technically, it integrates a memory attention mechanism and episodic buffers to manage memory scalability, mitigate overfitting, and ensure efficient recall. Applications span adaptive personal assistants, real time fraud detection, autonomous robotics, content moderation, and healthcare diagnostics. In each domain, the retention mechanism enables systems to learn incrementally, personalize outputs, and respond to evolving real world challenges effectively. By emulating key aspects of human learning, this retention enhanced architecture fosters a more fluid and responsive AI paradigm, paving the way for dynamic, session aware models that extend the capabilities of traditional Transformers into domains requiring continual adaptation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Embodied Scene Understanding for Vision Language Models via MetaVQA", "authors": "Weizhen Wang, Chenda Duan, Zhenghao Peng, Yuxin Liu, Bolei Zhou", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)", "abstract": "Vision Language Models (VLMs) demonstrate significant potential as embodied AI agents for various mobility applications. However, a standardized, closed-loop benchmark for evaluating their spatial reasoning and sequential decision-making capabilities is lacking. To address this, we present MetaVQA: a comprehensive benchmark designed to assess and enhance VLMs' understanding of spatial relationships and scene dynamics through Visual Question Answering (VQA) and closed-loop simulations. MetaVQA leverages Set-of-Mark prompting and top-down view ground-truth annotations from nuScenes and Waymo datasets to automatically generate extensive question-answer pairs based on diverse real-world traffic scenarios, ensuring object-centric and context-rich instructions. Our experiments show that fine-tuning VLMs with the MetaVQA dataset significantly improves their spatial reasoning and embodied scene comprehension in safety-critical simulations, evident not only in improved VQA accuracies but also in emerging safety-aware driving maneuvers. In addition, the learning demonstrates strong transferability from simulation to real-world observation. Code and data will be publicly available at this https URL ."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Short-time Variational Mode Decomposition", "authors": "Hao Jia, Pengfei Cao, Tong Liang, Cesar F. Caiafa, Zhe Sun, Yasuhiro Kushihashi, Grau A, Bolea Y, Feng Duan, Jordi Sole-Casals", "subjects": "Subjects:\nInformation Theory (cs.IT)", "abstract": "Variational mode decomposition (VMD) and its extensions like Multivariate VMD (MVMD) decompose signals into ensembles of band-limited modes with narrow central frequencies. These methods utilize Fourier transformations to shift signals between time and frequency domains. However, since Fourier transformations span the entire time-domain signal, they are suboptimal for non-stationary time series. We introduce Short-Time Variational Mode Decomposition (STVMD), an innovative extension of the VMD algorithm that incorporates the Short-Time Fourier transform (STFT) to minimize the impact of local disturbances. STVMD segments signals into short time windows, converting these segments into the frequency domain. It then formulates a variational optimization problem to extract band-limited modes representing the windowed data. The optimization aims to minimize the sum of the bandwidths of these modes across the windowed data, extending the cost functions used in VMD and MVMD. Solutions are derived using the alternating direction method of multipliers, ensuring the extraction of modes with narrow bandwidths. STVMD is divided into dynamic and non-dynamic types, depending on whether the central frequencies vary with time. Our experiments show that non-dynamic STVMD is comparable to VMD with properly sized time windows, while dynamic STVMD better accommodates non-stationary signals, evidenced by reduced mode function errors and tracking of dynamic central frequencies. This effectiveness is validated by steady-state visual-evoked potentials in electroencephalogram signals."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Enhancing Graph Representation Learning with Localized Topological Features", "authors": "Zuoyu Yan, Qi Zhao, Ze Ye, Tengfei Ma, Liangcai Gao, Zhi Tang, Yusu Wang, Chao Chen", "subjects": "Subjects:\nMachine Learning (cs.LG); Social and Information Networks (cs.SI)", "abstract": "Representation learning on graphs is a fundamental problem that can be crucial in various tasks. Graph neural networks, the dominant approach for graph representation learning, are limited in their representation power. Therefore, it can be beneficial to explicitly extract and incorporate high-order topological and geometric information into these models. In this paper, we propose a principled approach to extract the rich connectivity information of graphs based on the theory of persistent homology. Our method utilizes the topological features to enhance the representation learning of graph neural networks and achieve state-of-the-art performance on various node classification and link prediction benchmarks. We also explore the option of end-to-end learning of the topological features, i.e., treating topological computation as a differentiable operator during learning. Our theoretical analysis and empirical study provide insights and potential guidelines for employing topological features in graph learning tasks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Numerical approximation of Caputo-type advection-diffusion equations via Sylvester equations", "authors": "Francisco de la Hoz, Peru Muniain", "subjects": "Subjects:\nNumerical Analysis (math.NA)", "abstract": "In this paper, we approximate numerically the solution of Caputo-type advection-diffusion equations of the form $D_t^{\\alpha} u(t,x) = a_1(x)u_{xx}(t,x) + a_2(x)u_x(t,x) + a_3u(t,x) + a_4(t,x)$, where $D_t^{\\alpha} u$ denotes the Caputo fractional derivative of order $\\alpha\\in(0,1)$ of $u$ with respect to $t$, $t\\in[0, t_f]$ and the spatial domain can be the whole real line or a closed interval. First, we propose a method of order $3 - \\alpha$ to approximate Caputo fractional derivatives, explain how to implement an FFT-based fast convolution to reduce the computational cost, and express the numerical approximation in terms of an operational matrix. Then, we transform a given Caputo-type advection-diffusion equation into a Sylvester equation of the form $\\mathbf A\\mathbf U + \\mathbf U \\mathbf B = \\mathbf C$, and special care is given to the treatment of the boundary conditions, when the spatial domain is a closed interval. Finally, we perform several numerical experiments that illustrate the adequacy of our approach. The implementation has been done in Matlab, and we share and explain in detail the majority of the actual codes that we have used."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Blockchain-Enabled Approach to Cross-Border Compliance and Trust", "authors": "Vikram Kulothungan", "subjects": "Subjects:\nArtificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Computers and Society (cs.CY); Software Engineering (cs.SE)", "abstract": "As artificial intelligence (AI) systems become increasingly integral to critical infrastructure and global operations, the need for a unified, trustworthy governance framework is more urgent that ever. This paper proposes a novel approach to AI governance, utilizing blockchain and distributed ledger technologies (DLT) to establish a decentralized, globally recognized framework that ensures security, privacy, and trustworthiness of AI systems across borders. The paper presents specific implementation scenarios within the financial sector, outlines a phased deployment timeline over the next decade, and addresses potential challenges with solutions grounded in current research. By synthesizing advancements in blockchain, AI ethics, and cybersecurity, this paper offers a comprehensive roadmap for a decentralized AI governance framework capable of adapting to the complex and evolving landscape of global AI regulation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Guiding Retrieval using LLM-based Listwise Rankers", "authors": "Mandeep Rathee, Sean MacAvaney, Avishek Anand", "subjects": "Subjects:\nInformation Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "abstract": "Large Language Models (LLMs) have shown strong promise as rerankers, especially in ``listwise'' settings where an LLM is prompted to rerank several search results at once. However, this ``cascading'' retrieve-and-rerank approach is limited by the bounded recall problem: relevant documents not retrieved initially are permanently excluded from the final ranking. Adaptive retrieval techniques address this problem, but do not work with listwise rerankers because they assume a document's score is computed independently from other documents. In this paper, we propose an adaptation of an existing adaptive retrieval method that supports the listwise setting and helps guide the retrieval process itself (thereby overcoming the bounded recall problem for LLM rerankers). Specifically, our proposed algorithm merges results both from the initial ranking and feedback documents provided by the most relevant documents seen up to that point. Through extensive experiments across diverse LLM rerankers, first stage retrievers, and feedback sources, we demonstrate that our method can improve nDCG@10 by up to 13.23% and recall by 28.02%--all while keeping the total number of LLM inferences constant and overheads due to the adaptive process minimal. The work opens the door to leveraging LLM-based search in settings where the initial pool of results is limited, e.g., by legacy systems, or by the cost of deploying a semantic first-stage."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Patch-aware Vector Quantized Codebook Learning for Unsupervised Visual Defect Detection", "authors": "Qisen Cheng, Shuhui Qu, Janghwan Lee", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Unsupervised visual defect detection is critical in industrial applications, requiring a representation space that captures normal data features while detecting deviations. Achieving a balance between expressiveness and compactness is challenging; an overly expressive space risks inefficiency and mode collapse, impairing detection accuracy. We propose a novel approach using an enhanced VQ-VAE framework optimized for unsupervised defect detection. Our model introduces a patch-aware dynamic code assignment scheme, enabling context-sensitive code allocation to optimize spatial representation. This strategy enhances normal-defect distinction and improves detection accuracy during inference. Experiments on MVTecAD, BTAD, and MTSD datasets show our method achieves state-of-the-art performance."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Testing Noise Assumptions of Learning Algorithms", "authors": "Surbhi Goel, Adam R. Klivans, Konstantinos Stavropoulos, Arsen Vasilyan", "subjects": "Subjects:\nMachine Learning (cs.LG); Data Structures and Algorithms (cs.DS)", "abstract": "We pose a fundamental question in computational learning theory: can we efficiently test whether a training set satisfies the assumptions of a given noise model? This question has remained unaddressed despite decades of research on learning in the presence of noise. In this work, we show that this task is tractable and present the first efficient algorithm to test various noise assumptions on the training data. To model this question, we extend the recently proposed testable learning framework of Rubinfeld and Vasilyan (2023) and require a learner to run an associated test that satisfies the following two conditions: (1) whenever the test accepts, the learner outputs a classifier along with a certificate of optimality, and (2) the test must pass for any dataset drawn according to a specified modeling assumption on both the marginal distribution and the noise model. We then consider the problem of learning halfspaces over Gaussian marginals with Massart noise (where each label can be flipped with probability less than $1/2$ depending on the input features), and give a fully-polynomial time testable learning algorithm. We also show a separation between the classical setting of learning in the presence of structured noise and testable learning. In fact, for the simple case of random classification noise (where each label is flipped with fixed probability $\\eta = 1/2$), we show that testable learning requires super-polynomial time while classical learning is trivial."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Detecting Vulnerabilities in Encrypted Software Code while Ensuring Code Privacy", "authors": "Jorge Martins, David Dantas, Rafael Ramires, Bernardo Ferreira, Ib\u00e9ria Medeiros", "subjects": "Subjects:\nSoftware Engineering (cs.SE); Cryptography and Security (cs.CR)", "abstract": "Software vulnerabilities continue to be the main cause of occurrence for cyber attacks. In an attempt to reduce them and improve software quality, software code analysis has emerged as a service offered by companies specialising in software testing. However, this service requires software companies to provide access to their software's code, which raises concerns about code privacy and intellectual property theft. This paper presents a novel approach to Software Quality and Privacy, in which testing companies can perform code analysis tasks on encrypted software code provided by software companies while code privacy is preserved. The approach combines Static Code Analysis and Searchable Symmetric Encryption in order to process the source code and build an encrypted inverted index that represents its data and control flows. The index is then used to discover vulnerabilities by carrying out static analysis tasks in a confidential way. With this approach, this paper also defines a new research field -- Confidential Code Analysis --, from which other types of code analysis tasks and approaches can be derived. We implemented the approach in a new tool called CoCoA and evaluated it experimentally with synthetic and real PHP web applications. The results show that the tool has similar precision as standard (non-confidential) static analysis tools and a modest average performance overhead of 42.7%."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Grounding Text-To-Image Diffusion Models For Controlled High-Quality Image Generation", "authors": "Ahmad S\u00fcleyman, G\u00f6ksel Biricik", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Large-scale text-to-image (T2I) diffusion models have demonstrated an outstanding performance in synthesizing diverse high-quality visuals from natural language text captions. Multiple layout-to-image models have been developed to control the generation process by utilizing a broad array of layouts such as segmentation maps, edges, and human keypoints. In this work, we present ObjectDiffusion, a model that takes inspirations from the top cutting-edge image generative frameworks to seamlessly condition T2I models with new bounding boxes capabilities. Specifically, we make substantial modifications to the network architecture introduced in ContorlNet to integrate it with the condition processing and injection techniques proposed in GLIGEN. ObjectDiffusion is initialized with pretraining parameters to leverage the generation knowledge obtained from training on large-scale datasets. We fine-tune ObjectDiffusion on the COCO2017 training dataset and evaluate it on the COCO2017 validation dataset. Our model achieves an AP$_{50}$ of 46.6, an AR of 44.5, and a FID of 19.8 outperforming the current SOTA model trained on open-source datasets in all of the three metrics. ObjectDiffusion demonstrates a distinctive capability in synthesizing diverse, high-quality, high-fidelity images that seamlessly conform to the semantic and spatial control layout. Evaluated in qualitative and quantitative tests, ObjectDiffusion exhibits remarkable grounding abilities on closed-set and open-set settings across a wide variety of contexts. The qualitative assessment verifies the ability of ObjectDiffusion to generate multiple objects of different sizes and locations."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Combining Movement Primitives with Contraction Theory", "authors": "Moses C. Nah, Johannes Lachner, Neville Hogan, Jean-Jacques Slotine", "subjects": "Subjects:\nRobotics (cs.RO)", "abstract": "This paper presents a modular framework for motion planning using movement primitives. Central to the approach is Contraction Theory, a modular stability tool for nonlinear dynamical systems. The approach extends prior methods by achieving parallel and sequential combinations of both discrete and rhythmic movements, while enabling independent modulation of each movement. This modular framework enables a divide-and-conquer strategy to simplify the programming of complex robot motion planning. Simulation examples illustrate the flexibility and versatility of the framework, highlighting its potential to address diverse challenges in robot motion planning."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A random free-boundary diffusive logistic model: Analysis, computing and simulation", "authors": "M.-C. Casab\u00e1n, R. Company, V.N. Egorova, L. J\u00f3dar", "subjects": "Subjects:\nNumerical Analysis (math.NA)", "abstract": "A free boundary diffusive logistic model finds application in many different fields from biological invasion to wildfire propagation. However, many of these processes show a random nature and contain uncertainties in the parameters. In this paper we extend the diffusive logistic model with unknown moving front to the random scenario by assuming that the involved parameters have a finite degree of randomness. The resulting mathematical model becomes a random free boundary partial differential problem and it is addressed numerically combining the finite difference method with two approaches for the treatment of the moving front. Firstly, we propose a front-fixing transformation, reshaping the original random free boundary domain into a fixed deterministic one. A second approach is using the front-tracking method to capture the evolution of the moving front adapted to the random framework. Statistical moments of the approximating solution stochastic process and the stochastic moving boundary solution are calculated by the Monte Carlo technique. Qualitative numerical analysis establishes the stability and positivity conditions. Numerical examples are provided to compare both approaches, study the spreading-vanishing dichotomy, prove qualitative properties of the schemes and show the numerical convergence."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Towards Semantics Lifting for Scientific Computing: A Case Study on FFT", "authors": "Naifeng Zhang, Sanil Rao, Mike Franusich, Franz Franchetti", "subjects": "Subjects:\nProgramming Languages (cs.PL); Symbolic Computation (cs.SC)", "abstract": "The rise of automated code generation tools, such as large language models (LLMs), has introduced new challenges in ensuring the correctness and efficiency of scientific software, particularly in complex kernels, where numerical stability, domain-specific optimizations, and precise floating-point arithmetic are critical. We propose a stepwise semantics lifting approach using an extended SPIRAL framework with symbolic execution and theorem proving to statically derive high-level code semantics from LLM-generated kernels. This method establishes a structured path for verifying the source code's correctness via a step-by-step lifting procedure to high-level specification. We conducted preliminary tests on the feasibility of this approach by successfully lifting GPT-generated fast Fourier transform code to high-level specifications."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Unified Few-shot Crack Segmentation and its Precise 3D Automatic Measurement in Concrete Structures", "authors": "Pengru Deng, Jiapeng Yao, Chun Li, Su Wang, Xinrun Li, Varun Ojha, Xuhui He, Takashi Matsumoto", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)", "abstract": "Visual-Spatial Systems has become increasingly essential in concrete crack inspection. However, existing methods often lacks adaptability to diverse scenarios, exhibits limited robustness in image-based approaches, and struggles with curved or complex geometries. To address these limitations, an innovative framework for two-dimensional (2D) crack detection, three-dimensional (3D) reconstruction, and 3D automatic crack measurement was proposed by integrating computer vision technologies and multi-modal Simultaneous localization and mapping (SLAM) in this study. Firstly, building on a base DeepLabv3+ segmentation model, and incorporating specific refinements utilizing foundation model Segment Anything Model (SAM), we developed a crack segmentation method with strong generalization across unfamiliar scenarios, enabling the generation of precise 2D crack masks. To enhance the accuracy and robustness of 3D reconstruction, Light Detection and Ranging (LiDAR) point clouds were utilized together with image data and segmentation masks. By leveraging both image- and LiDAR-SLAM, we developed a multi-frame and multi-modal fusion framework that produces dense, colorized point clouds, effectively capturing crack semantics at a 3D real-world scale. Furthermore, the crack geometric attributions were measured automatically and directly within 3D dense point cloud space, surpassing the limitations of conventional 2D image-based measurements. This advancement makes the method suitable for structural components with curved and complex 3D geometries. Experimental results across various concrete structures highlight the significant improvements and unique advantages of the proposed method, demonstrating its effectiveness, accuracy, and robustness in real-world applications."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          3D Printed Maps and Icons for Inclusion: Testing in the Wild by People who are Blind or have Low Vision", "authors": "Leona Holloway, Kim Marriott, Matthew Butler, Samuel Reinders", "subjects": "Subjects:\nHuman-Computer Interaction (cs.HC)", "abstract": "The difficulty and consequent fear of travel is one of the most disabling consequences of blindness and severe vision impairment, affecting confidence and quality of life. Traditional tactile graphics are vital in the Orientation and Mobility training process, however 3D printing may have the capacity to enable production of more meaningful and inclusive maps. This study explored the use of 3D printed maps on site at a public event to examine their suitability and to identify guidelines for the design of future 3D maps. An iterative design process was used in the production of the 3D maps, with feedback from visitors who are blind or have low vision informing the recommendations for their design and use. For example, it was found that many representational 3D icons could be recognised by touch without the need for a key and that such a map helped form mental models of the event space. Complex maps, however, require time to explore and should be made available before an event or at the entrance in a comfortable position. The maps were found to support the orientation and mobility process, and importantly to also promote a positive message about inclusion and accessibility."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Surgical Visual Understanding (SurgVU) Dataset", "authors": "Aneeq Zia, Max Berniker, Rogerio Nespolo, Conor Perreault, Ziheng Wang, Benjamin Mueller, Ryan Schmidt, Kiran Bhattacharyya, Xi Liu, Anthony Jarc", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Owing to recent advances in machine learning and the ability to harvest large amounts of data during robotic-assisted surgeries, surgical data science is ripe for foundational work. We present a large dataset of surgical videos and their accompanying labels for this purpose. We describe how the data was collected and some of its unique attributes. Multiple example problems are outlined. Although the dataset was curated for a particular set of scientific challenges (in an accompanying paper), it is general enough to be used for a broad range machine learning questions. Our hope is that this dataset exposes the larger machine learning community to the challenging problems within surgical data science, and becomes a touchstone for future research. The videos are available at this https URL, the labels at this https URL, and a validation set for tool detection problem at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Personalized Parsons Puzzles as Scaffolding Enhance Practice Engagement Over Just Showing LLM-Powered Solutions", "authors": "Xinying Hou, Zihan Wu, Xu Wang, Barbara J. Ericson", "subjects": "Subjects:\nHuman-Computer Interaction (cs.HC); Computers and Society (cs.CY)", "abstract": "As generative AI products could generate code and assist students with programming learning seamlessly, integrating AI into programming education contexts has driven much attention. However, one emerging concern is that students might get answers without learning from the LLM-generated content. In this work, we deployed the LLM-powered personalized Parsons puzzles as scaffolding to write-code practice in a Python learning classroom (PC condition) and conducted an 80-minute randomized between-subjects study. Both conditions received the same practice problems. The only difference was that when requesting help, the control condition showed students a complete solution (CC condition), simulating the most traditional LLM output. Results indicated that students who received personalized Parsons puzzles as scaffolding engaged in practicing significantly longer than those who received complete solutions when struggling."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Fuzzy Integration of Data Lake Tables", "authors": "Aamod Khatiwada, Roee Shraga, Ren\u00e9e J. Miller", "subjects": "Subjects:\nDatabases (cs.DB); Information Retrieval (cs.IR)", "abstract": "Data integration is an important step in any data science pipeline where the objective is to unify the information available in different datasets for comprehensive analysis. Full Disjunction, which is an associative extension of the outer join operator, has been shown to be an effective operator for integrating datasets. It fully preserves and combines the available information. Existing Full Disjunction algorithms only consider the equi-join scenario where only tuples having the same value on joining columns are integrated. This, however, does not realistically represent an open data scenario, where datasets come from diverse sources with inconsistent values (e.g., synonyms, abbreviations, etc.) and with limited metadata. So, joining just on equal values severely limits the ability of Full Disjunction to fully combine datasets. Thus, in this work, we propose an extension of Full Disjunction to also account for \"fuzzy\" matches among tuples. We present a novel data-driven approach to enable the joining of approximate or fuzzy matches within Full Disjunction. Experimentally, we show that fuzzy Full Disjunction does not add significant time overhead over a state-of-the-art Full Disjunction implementation and also that it enhances the integration effectiveness."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          FineMedLM-o1: Enhancing the Medical Reasoning Ability of LLM from Supervised Fine-Tuning to Test-Time Training", "authors": "Hongzhou Yu, Tianhao Cheng, Ying Cheng, Rui Feng", "subjects": "Subjects:\nComputation and Language (cs.CL)", "abstract": "Recent advancements in large language models (LLMs) have shown promise in medical applications such as disease diagnosis and treatment planning. However, most existing medical LLMs struggle with the advanced reasoning required for complex clinical scenarios, such as differential diagnosis or personalized treatment suggestions. We proposed FineMedLM-o1, which leverages high-quality synthetic medical data and long-form reasoning data for Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO), enabling advanced dialogue and deep reasoning capabilities. Additionally, we introduced Test-Time Training (TTT) in the medical domain for the first time, facilitating domain adaptation and ensuring reliable, accurate reasoning. Experimental results demonstrate that FineMedLM-o1 achieves a 23% average performance improvement over prior models on key medical benchmarks. Furthermore, the introduction of TTT provides an additional 14% performance boost, highlighting its effectiveness in enhancing medical reasoning capabilities. To support this process, we also proposed a novel method for synthesizing medical dialogue. Compared to other open-source datasets, our dataset stands out as superior in both quality and complexity. The project and data will be released on GitHub."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Boosting Short Text Classification with Multi-Source Information Exploration and Dual-Level Contrastive Learning", "authors": "Yonghao Liu, Mengyu Li, Wei Pang, Fausto Giunchiglia, Lan Huang, Xiaoyue Feng, Renchu Guan", "subjects": "Subjects:\nComputation and Language (cs.CL)", "abstract": "Short text classification, as a research subtopic in natural language processing, is more challenging due to its semantic sparsity and insufficient labeled samples in practical scenarios. We propose a novel model named MI-DELIGHT for short text classification in this work. Specifically, it first performs multi-source information (i.e., statistical information, linguistic information, and factual information) exploration to alleviate the sparsity issues. Then, the graph learning approach is adopted to learn the representation of short texts, which are presented in graph forms. Moreover, we introduce a dual-level (i.e., instance-level and cluster-level) contrastive learning auxiliary task to effectively capture different-grained contrastive information within massive unlabeled data. Meanwhile, previous models merely perform the main task and auxiliary tasks in parallel, without considering the relationship among tasks. Therefore, we introduce a hierarchical architecture to explicitly model the correlations between tasks. We conduct extensive experiments across various benchmark datasets, demonstrating that MI-DELIGHT significantly surpasses previous competitive models. It even outperforms popular large language models on several datasets."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          EILID: Execution Integrity for Low-end IoT Devices", "authors": "Sashidhar Jakkamsetti, Youngil Kim, Andrew Searles, Gene Tsudik", "subjects": "Subjects:\nCryptography and Security (cs.CR)", "abstract": "Prior research yielded many techniques to mitigate software compromise for low-end Internet of Things (IoT) devices. Some of them detect software modifications via remote attestation and similar services, while others preventatively ensure software (static) integrity. However, achieving run-time (dynamic) security, e.g., control-flow integrity (CFI), remains a challenge. Control-flow attestation (CFA) is one approach that minimizes the burden on devices. However, CFA is not a real-time countermeasure against run-time attacks since it requires communication with a verifying entity. This poses significant risks if safety- or time-critical tasks have memory vulnerabilities. To address this issue, we construct EILID - a hybrid architecture that ensures software execution integrity by actively monitoring control-flow violations on low-end devices. EILID is built atop CASU, a prevention-based (i.e., active) hybrid Root-of-Trust (RoT) that guarantees software immutability. EILID achieves fine-grained backward-edge and function-level forward-edge CFI via semi-automatic code instrumentation and a secure shadow stack."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Adaptive Law-Based Transformation (ALT): A Lightweight Feature Representation for Time Series Classification", "authors": "Marcell T. Kurbucz, Bal\u00e1zs Haj\u00f3s, Bal\u00e1zs P. Halmos, Vince \u00c1. Moln\u00e1r, Antal Jakov\u00e1c", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)", "abstract": "Time series classification (TSC) is fundamental in numerous domains, including finance, healthcare, and environmental monitoring. However, traditional TSC methods often struggle with the inherent complexity and variability of time series data. Building on our previous work with the linear law-based transformation (LLT) - which improved classification accuracy by transforming the feature space based on key data patterns - we introduce adaptive law-based transformation (ALT). ALT enhances LLT by incorporating variable-length shifted time windows, enabling it to capture distinguishing patterns of various lengths and thereby handle complex time series more effectively. By mapping features into a linearly separable space, ALT provides a fast, robust, and transparent solution that achieves state-of-the-art performance with only a few hyperparameters."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Simple Graph Contrastive Learning Framework for Short Text Classification", "authors": "Yonghao Liu, Fausto Giunchiglia, Lan Huang, Ximing Li, Xiaoyue Feng, Renchu Guan", "subjects": "Subjects:\nComputation and Language (cs.CL)", "abstract": "Short text classification has gained significant attention in the information age due to its prevalence and real-world applications. Recent advancements in graph learning combined with contrastive learning have shown promising results in addressing the challenges of semantic sparsity and limited labeled data in short text classification. However, existing models have certain limitations. They rely on explicit data augmentation techniques to generate contrastive views, resulting in semantic corruption and noise. Additionally, these models only focus on learning the intrinsic consistency between the generated views, neglecting valuable discriminative information from other potential views. To address these issues, we propose a Simple graph contrastive learning framework for Short Text Classification (SimSTC). Our approach involves performing graph learning on multiple text-related component graphs to obtain multi-view text embeddings. Subsequently, we directly apply contrastive learning on these embeddings. Notably, our method eliminates the need for data augmentation operations to generate contrastive views while still leveraging the benefits of multi-view contrastive learning. Despite its simplicity, our model achieves outstanding performance, surpassing large language models on various datasets."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Leveraging Scale-aware Representations for improved Concept-Representation Alignment in ViTs", "authors": "Sanchit Sinha, Guangzhi Xiong, Aidong Zhang", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "Vision Transformers (ViTs) are increasingly being adopted in various sensitive vision applications - like medical diagnosis, facial recognition, etc. To improve the interpretability of such models, many approaches attempt to forward-align them with carefully annotated abstract, human-understandable semantic entities - concepts. Concepts provide global rationales to the model predictions and can be quickly understood/intervened on by domain experts. Most current research focuses on designing model-agnostic, plug-and-play generic concept-based explainability modules that do not incorporate the inner workings of foundation models (e.g., inductive biases, scale invariance, etc.) during training. To alleviate this issue for ViTs, in this paper, we propose a novel Concept Representation Alignment Module (CRAM) which learns both scale and position-aware representations from multi-scale feature pyramids and patch representations respectively. CRAM further aligns these representations with concept annotations through an attention matrix. The proposed CRAM module improves the predictive performance of ViT architectures and also provides accurate and robust concept explanations as demonstrated on five datasets - including three widely used benchmarks (CUB, Pascal APY, Concept-MNIST) and 2 real-world datasets (AWA2, KITS)."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Foundations of Large Language Models", "authors": "Tong Xiao, Jingbo Zhu", "subjects": "Subjects:\nComputation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "This is a book about large language models. As indicated by the title, it primarily focuses on foundational concepts rather than comprehensive coverage of all cutting-edge technologies. The book is structured into four main chapters, each exploring a key area: pre-training, generative models, prompting techniques, and alignment methods. It is intended for college students, professionals, and practitioners in natural language processing and related fields, and can serve as a reference for anyone interested in large language models."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Provenance Guided Rollback Suggestions", "authors": "David Zhao, Pavle Subotic, Mukund Raghothaman, Bernhard Scholz", "subjects": "Subjects:\nLogic in Computer Science (cs.LO); Programming Languages (cs.PL)", "abstract": "Advances in incremental Datalog evaluation strategies have made Datalog popular among use cases with constantly evolving inputs such as static analysis in continuous integration and deployment pipelines. As a result, new logic programming debugging techniques are needed to support these emerging use cases. This paper introduces an incremental debugging technique for Datalog, which determines the failing changes for a \\emph{rollback} in an incremental setup. Our debugging technique leverages a novel incremental provenance method. We have implemented our technique using an incremental version of the Souffl\u00e9 Datalog engine and evaluated its effectiveness on the DaCapo Java program benchmarks analyzed by the Doop static analysis library. Compared to state-of-the-art techniques, we can localize faults and suggest rollbacks with an overall speedup of over 26.9$\\times$ while providing higher quality results."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Tessellated Linear Model for Age Prediction from Voice", "authors": "Dareen Alharthi, Mahsa Zamani, Bhiksha Raj, Rita Singh", "subjects": "Subjects:\nMachine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)", "abstract": "Voice biometric tasks, such as age estimation require modeling the often complex relationship between voice features and the biometric variable. While deep learning models can handle such complexity, they typically require large amounts of accurately labeled data to perform well. Such data are often scarce for biometric tasks such as voice-based age prediction. On the other hand, simpler models like linear regression can work with smaller datasets but often fail to generalize to the underlying non-linear patterns present in the data. In this paper we propose the Tessellated Linear Model (TLM), a piecewise linear approach that combines the simplicity of linear models with the capacity of non-linear functions. TLM tessellates the feature space into convex regions and fits a linear model within each region. We optimize the tessellation and the linear models using a hierarchical greedy partitioning. We evaluated TLM on the TIMIT dataset on the task of age prediction from voice, where it outperformed state-of-the-art deep learning models."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Redefining Affordance via Computational Rationality", "authors": "Yi-Chi Liao, Christian Holz", "subjects": "Subjects:\nHuman-Computer Interaction (cs.HC)", "abstract": "Affordances, a foundational concept in human-computer interaction and design, have traditionally been explained by direct-perception theories, which assume that individuals perceive action possibilities directly from the environment. However, these theories fall short of explaining how affordances are perceived, learned, refined, or misperceived, and how users choose between multiple affordances in dynamic contexts. This paper introduces a novel affordance theory grounded in Computational Rationality, positing that humans construct internal representations of the world based on bounded sensory inputs. Within these internal models, affordances are inferred through two core mechanisms: feature recognition and hypothetical motion trajectories. Our theory redefines affordance perception as a decision-making process, driven by two components: confidence (the perceived likelihood of successfully executing an action) and predicted utility (the expected value of the outcome). By balancing these factors, individuals make informed decisions about which actions to take. Our theory frames affordances perception as dynamic, continuously learned, and refined through reinforcement and feedback. We validate the theory via thought experiments and demonstrate its applicability across diverse types of affordances (e.g., physical, digital, social). Beyond clarifying and generalizing the understanding of affordances across contexts, our theory serves as a foundation for improving design communication and guiding the development of more adaptive and intuitive systems that evolve with user capabilities."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          The Spread of Virtual Gifting in Live Streaming: The Case of Twitch", "authors": "Ji Eun Kim, Seura Ha, Sangmi Kim, Libby Hemphill", "subjects": "Subjects:\nComputers and Society (cs.CY); Human-Computer Interaction (cs.HC)", "abstract": "This paper examines how gifting spreads among viewers on Twitch, one of the largest live streaming platforms worldwide. Twitch users can give gift subscriptions to other viewers in the chat room, with the majority of gifters opting for community gifting, which is gifting to randomly selected viewers. We identify the random nature of gift-receiving in our data as a natural experiment setting. We investigate whether gift recipients pay it forward, considering various gift types that may either promote or deter the spread of gifting. Our findings reveal that Twitch viewers who receive gift subscriptions are generally more likely to pay it forward than non-recipients, and the positive impact of gift-receiving becomes stronger when the recipient is the sole beneficiary of the giver's gifting behavior. However, we found that gifts from frequent gifters discourage recipients from paying it forward, and gifts from anonymous gifters do not influence the likelihood of viewers becoming future gifters. This research contributes to the existing literature on the spread of online prosocial behavior by providing robust evidence and suggests practical strategies for promoting online gifting."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Exploring the Capabilities of Vision-Language Models to Detect Visual Bugs in HTML5 <canvas> Applications", "authors": "Finlay Macklon, Cor-Paul Bezemer", "subjects": "Subjects:\nSoftware Engineering (cs.SE)", "abstract": "The HyperText Markup Language 5 (HTML5) <canvas> is useful for creating visual-centric web applications. However, unlike traditional web applications, HTML5 <canvas> applications render objects onto the <canvas> bitmap without representing them in the Document Object Model (DOM). Mismatches between the expected and actual visual output of the <canvas> bitmap are termed visual bugs. Due to the visual-centric nature of <canvas> applications, visual bugs are important to detect because such bugs can render a <canvas> application useless. As we showed in prior work, Asset-Based graphics can provide the ground truth for a visual test oracle. However, many <canvas> applications procedurally generate their graphics. In this paper, we investigate how to detect visual bugs in <canvas> applications that use Procedural graphics as well. In particular, we explore the potential of Vision-Language Models (VLMs) to automatically detect visual bugs. Instead of defining an exact visual test oracle, information about the application's expected functionality (the context) can be provided with the screenshot as input to the VLM. To evaluate this approach, we constructed a dataset containing 80 bug-injected screenshots across four visual bug types (Layout, Rendering, Appearance, and State) plus 20 bug-free screenshots from 20 <canvas> applications. We ran experiments with a state-of-the-art VLM using several combinations of text and image context to describe each application's expected functionality. Our results show that by providing the application README(s), a description of visual bug types, and a bug-free screenshot as context, VLMs can be leveraged to detect visual bugs with up to 100% per-application accuracy."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Split Fine-Tuning for Large Language Models in Wireless Networks", "authors": "Songge Zhang, Guoliang Cheng, Xinyu Huang, Zuguang Li, Wen Wu, Lingyang Song, Xuemin Shen", "subjects": "Subjects:\nDistributed, Parallel, and Cluster Computing (cs.DC)", "abstract": "Fine-tuning is the process of adapting the pre-trained large language models (LLMs) for downstream tasks. Due to substantial parameters, fine-tuning LLMs on mobile devices demands considerable memory resources, and suffers from high communication overhead and long fine-tuning delay. In this paper, we propose an efficient LLM fine-tuning scheme in wireless networks, named Split Fine-Tuning (SFT), which can accommodate LLM fine-tuning on mobile devices. Specifically, an LLM is split into a server-side part on the edge server and a device-side part on the mobile device to satisfy the device-side memory constraint. All devices share a server-side model and perform parallel fine-tuning to reduce fine-tuning delay. In addition, to reduce significant communication overhead incurred by data exchange between devices and the edge server, we propose a data compression scheme by jointly leveraging sparsification, stochastic quantization, and lossless encoding methods. Furthermore, we formulate a fine-tuning delay minimization problem under accuracy and memory constraints, taking device heterogeneity and channel dynamics into account. To solve the problem, the nonlinear mixed-integer problem is decoupled into two subproblems in different timescales. The two-timescale resource management algorithm is proposed to jointly optimize the compression rate and transformer block allocation in the large timescale using the augmented Lagrangian method, and determine spectrum resource allocation in the small timescale via sequential quadratic programming. Extensive simulation results demonstrate that the proposed scheme can reduce the fine-tuning delay by up to 80.2% and communication overhead by 93.6% compared to state-of-the-art benchmarks, while satisfying device-side memory and model accuracy constraints."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Mono-Forward: Backpropagation-Free Algorithm for Efficient Neural Network Training Harnessing Local Errors", "authors": "James Gong, Bruce Li, Waleed Abdulla", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "Backpropagation is the standard method for achieving state-of-the-art accuracy in neural network training, but it often imposes high memory costs and lacks biological plausibility. In this paper, we introduce the Mono-Forward algorithm, a purely local layerwise learning method inspired by Hinton's Forward-Forward framework. Unlike backpropagation, Mono-Forward optimizes each layer solely with locally available information, eliminating the reliance on global error signals. We evaluated Mono-Forward on multi-layer perceptrons and convolutional neural networks across multiple benchmarks, including MNIST, Fashion-MNIST, CIFAR-10, and CIFAR-100. The test results show that Mono-Forward consistently matches or surpasses the accuracy of backpropagation across all tasks, with significantly reduced and more even memory usage, better parallelizability, and a comparable convergence rate."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          AI-based Identity Fraud Detection: A Systematic Review", "authors": "Chuo Jun Zhang, Asif Q. Gill, Bo Liu, Memoona J. Anwar", "subjects": "Subjects:\nArtificial Intelligence (cs.AI)", "abstract": "With the rapid development of digital services, a large volume of personally identifiable information (PII) is stored online and is subject to cyberattacks such as Identity fraud. Most recently, the use of Artificial Intelligence (AI) enabled deep fake technologies has significantly increased the complexity of identity fraud. Fraudsters may use these technologies to create highly sophisticated counterfeit personal identification documents, photos and videos. These advancements in the identity fraud landscape pose challenges for identity fraud detection and society at large. There is a pressing need to review and understand identity fraud detection methods, their limitations and potential solutions. This research aims to address this important need by using the well-known systematic literature review method. This paper reviewed a selected set of 43 papers across 4 major academic literature databases. In particular, the review results highlight the two types of identity fraud prevention and detection methods, in-depth and open challenges. The results were also consolidated into a taxonomy of AI-based identity fraud detection and prevention methods including key insights and trends. Overall, this paper provides a foundational knowledge base to researchers and practitioners for further research and development in this important area of digital identity fraud."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Task Vectors in In-Context Learning: Emergence, Formation, and Benefit", "authors": "Liu Yang, Ziqian Lin, Kangwook Lee, Dimitris Papailiopoulos, Robert Nowak", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "In-context learning is a remarkable capability of transformers, referring to their ability to adapt to specific tasks based on a short history or context. Previous research has found that task-specific information is locally encoded within models, though their emergence and functionality remain unclear due to opaque pre-training processes. In this work, we investigate the formation of task vectors in a controlled setting, using models trained from scratch on synthetic datasets. Our findings confirm that task vectors naturally emerge under certain conditions, but the tasks may be relatively weakly and/or non-locally encoded within the model. To promote strong task vectors encoded at a prescribed location within the model, we propose an auxiliary training mechanism based on a task vector prompting loss (TVP-loss). This method eliminates the need to search for task-correlated encodings within the trained model and demonstrably improves robustness and generalization."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Holistic Optimization Framework for FPGA Accelerators", "authors": "St\u00e9phane Pouget, Michael Lo, Louis-No\u00ebl Pouchet, Jason Cong", "subjects": "Subjects:\nHardware Architecture (cs.AR)", "abstract": "Customized accelerators have transformed modern computing by enhancing energy efficiency and performance through specialization. Field Programmable Gate Arrays play a pivotal role in this domain due to their flexibility and high-performance potential. High-Level Synthesis and source-to-source compilers simplify hardware design by converting high-level code into hardware descriptions enriched with directives. However, achieving high Quality of Results in FPGA designs remains challenging, requiring complex transformations, strategic directive use, and efficient data management. While existing approaches like Design Space Exploration (DSE) and source-to-source compilers have made strides in improving performance, they often address isolated aspects of the design process. This paper introduces Prometheus, a holistic framework that integrates task fusion, tiling, loop permutation, computation-communication overlap, and concurrent task execution into a unified design space. Leveraging Non-Linear Problem methodologies, Prometheus explores this space to find solutions under resource constraints, enabling bitstream generation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Practical Spoofing Attacks on Galileo Open Service Navigation Message Authentication", "authors": "Haiyang Wang, Yuanyu Zhang, Xinghui Zhu, Ji He, Shuangtrui Zhao, Yulong Shen, Xiaohong Jiang", "subjects": "Subjects:\nCryptography and Security (cs.CR)", "abstract": "This paper examines the Galileo Open Service Navigation Message Authentication (OSNMA) and, for the first time, discovers two critical vulnerabilities, namely artificially-manipulated time synchronization (ATS) and interruptible message authentication (IMA). ATS allows attackers falsify a receiver's signals and/or local reference time (LRT) while still fulfilling the time synchronization (TS) requirement. IMA allows temporary interruption of the navigation data authentication process due to the reception of a broken message (probably caused by spoofing attacks) and restores the authentication later. By exploiting the ATS vulnerability, we propose a TS-comply replay (TSR) attack with two variants (real-time and non-real-time), where attackers replay signals to a victim receiver while strictly complying with the TS rule. We further propose a TS-comply forgery (TSF) attack, where attackers first use a previously-disclosed key to forge a message based on the OSNMA protocol, then tamper with the vitcim receiver's LRT correspondingly to comply with the TS rule and finally transmit the forged message to the receiver. Finally, we propose a concatenating replay (CR) attack based on the IMA vulnerability, where attackers concatenate replayed signals to the victim receiver's signals in a way that still enables correct verification of the navigation data in the replayed signals. To validate the effectiveness of the proposed attacks, we conduct real-world experiments with a commercial Galileo receiver manufactured by Septentrio, two software-defined radio (SDR) devices, open-source Galileo-SDR-SIM and OSNMAlib software. The results showed that all the attacks can successfully pass the OSNMA scheme and the TSF attack can spoof receivers to arbitrary locations."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Acc-SpMM: Accelerating General-purpose Sparse Matrix-Matrix Multiplication with GPU Tensor Cores", "authors": "Haisha Zhao, San Li, Jiaheng Wang, Chunbao Zhou, Jue Wang, Zhikuang Xin, Shunde Li, Zhiqiang Liang, Zhijie Pan, Fang Liu, Yan Zeng, Yangang Wang, Xuebin Chi", "subjects": "Subjects:\nDistributed, Parallel, and Cluster Computing (cs.DC)", "abstract": "General-purpose Sparse Matrix-Matrix Multiplication (SpMM) is a fundamental kernel in scientific computing and deep learning. The emergence of new matrix computation units such as Tensor Cores (TCs) brings more opportunities for SpMM acceleration. However, in order to fully unleash the power of hardware performance, systematic optimization is required. In this paper, we propose Acc-SpMM, a high-performance SpMM library on TCs, with multiple optimizations, including data-affinity-based reordering, memory efficient compressed format, high-throughput pipeline, and adaptive sparsity-aware load balancing. In contrast to the state-of-the-art SpMM kernels on various NVIDIA GPU architectures with a diverse range of benchmark matrices, Acc-SpMM achieves significant performance improvements, on average 2.52x (up to 5.11x) speedup on RTX 4090, on average 1.91x (up to 4.68x) speedup on A800, and on average 1.58x (up to 3.60x) speedup on H100 over cuSPARSE."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          PATCHEDSERVE: A Patch Management Framework for SLO-Optimized Hybrid Resolution Diffusion Serving", "authors": "Desen Sun, Zepeng Zhao, Yuke Wang", "subjects": "Subjects:\nDistributed, Parallel, and Cluster Computing (cs.DC)", "abstract": "The Text-to-Image (T2I) diffusion model is one of the most popular models in the world. However, serving diffusion models at the entire image level faces several problems, especially when there are multiple candidate resolutions. First, image based serving system prevents requests with different resolutions from batching together. On the other hand, requests with hybrid resolutions also indicate diverse locality features, which makes it hard to apply the same cache policy to all of them. To this end, we propose PATCHEDSERVE, A Patch Management Framework for SLO-Optimized Hybrid Resolution Diffusion Serving that provides a patch-level management strategy to gather hybrid resolution requests into batches. Specifically, PATCHEDSERVE incorporates a novel patch-based processing workflow, significantly enhancing throughput for hybrid resolution inputs. Furthermore, PATCHEDSERVE designs a patch-level cache reuse policy to fully exploit the redundancy in diffusion. In addition, PATCHEDSERVE features an SLO-aware scheduling algorithm with lightweight online latency prediction, achieving higher SLO satisfaction rates. We show that PATCHEDSERVE can achieve 30.1 % higher SLO satisfaction compared to SOTA diffusion serving system while not hurt the image quality."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Clone-Robust AI Alignment", "authors": "Ariel D. Procaccia, Benjamin Schiffer, Shirley Zhang", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT)", "abstract": "A key challenge in training Large Language Models (LLMs) is properly aligning them with human preferences. Reinforcement Learning with Human Feedback (RLHF) uses pairwise comparisons from human annotators to train reward functions and has emerged as a popular alignment method. However, input datasets in RLHF are not necessarily balanced in the types of questions and answers that are included. Therefore, we want RLHF algorithms to perform well even when the set of alternatives is not uniformly distributed. Drawing on insights from social choice theory, we introduce robustness to approximate clones, a desirable property of RLHF algorithms which requires that adding near-duplicate alternatives does not significantly change the learned reward function. We first demonstrate that the standard RLHF algorithm based on regularized maximum likelihood estimation (MLE) fails to satisfy this property. We then propose the weighted MLE, a new RLHF algorithm that modifies the standard regularized MLE by weighting alternatives based on their similarity to other alternatives. This new algorithm guarantees robustness to approximate clones while preserving desirable theoretical properties."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Block Designs and K-Geodetic Graphs: A Survey", "authors": "Carlos E. Frasser", "subjects": "Subjects:\nDiscrete Mathematics (cs.DM); Combinatorics (math.CO)", "abstract": "K-geodetic graphs (K capital) are defined as graphs in which each pair of nonadjacent vertices has at most K paths of minimum length between them. A K-geodetic graph is geodetic if K=1, bigeodetic if K=2 and trigeodetic if K=3. K-geodetic graphs are applied effectively to the solution of several practical problems in distinct areas of computer science, hence the importance of their study. Four problems are central to the study of K-geodetic graphs, namely, characterization, construction, enumeration and classification. The problems of finding the general classification of K-geodetic graphs for each of their classes K=1,2,3 are open. The present paper is a survey dedicated to the construction of K-geodetic graphs for K=1,2,3 using balanced incomplete block designs (BIBDs). To this purpose, we use block designs as combinatorial structures defined in terms of completely predetermined parameters, which is essential for the easy construction of the K-geodetic graphs described in this survey."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Delayed Fusion: Integrating Large Language Models into First-Pass Decoding in End-to-end Speech Recognition", "authors": "Takaaki Hori, Martin Kocour, Adnan Haider, Erik McDermott, Xiaodan Zhuang", "subjects": "Subjects:\nComputation and Language (cs.CL); Sound (cs.SD); Audio and Speech Processing (eess.AS)", "abstract": "This paper presents an efficient decoding approach for end-to-end automatic speech recognition (E2E-ASR) with large language models (LLMs). Although shallow fusion is the most common approach to incorporate language models into E2E-ASR decoding, we face two practical problems with LLMs. (1) LLM inference is computationally costly. (2) There may be a vocabulary mismatch between the ASR model and the LLM. To resolve this mismatch, we need to retrain the ASR model and/or the LLM, which is at best time-consuming and in many cases not feasible. We propose \"delayed fusion,\" which applies LLM scores to ASR hypotheses with a delay during decoding and enables easier use of pre-trained LLMs in ASR tasks. This method can reduce not only the number of hypotheses scored by the LLM but also the number of LLM inference calls. It also allows re-tokenizion of ASR hypotheses during decoding if ASR and LLM employ different tokenizations. We demonstrate that delayed fusion provides improved decoding speed and accuracy compared to shallow fusion and N-best rescoring using the LibriHeavy ASR corpus and three public LLMs, OpenLLaMA 3B & 7B and Mistral 7B."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          OpticFusion: Multi-Modal Neural Implicit 3D Reconstruction of Microstructures by Fusing White Light Interferometry and Optical Microscopy", "authors": "Shuo Chen, Yijin Li, Guofeng Zhang", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Applied Physics (physics.app-ph); Instrumentation and Detectors (physics.ins-det); Optics (physics.optics)", "abstract": "White Light Interferometry (WLI) is a precise optical tool for measuring the 3D topography of microstructures. However, conventional WLI cannot capture the natural color of a sample's surface, which is essential for many microscale research applications that require both 3D geometry and color information. Previous methods have attempted to overcome this limitation by modifying WLI hardware and analysis software, but these solutions are often costly. In this work, we address this challenge from a computer vision multi-modal reconstruction perspective for the first time. We introduce OpticFusion, a novel approach that uses an additional digital optical microscope (OM) to achieve 3D reconstruction with natural color textures using multi-view WLI and OM images. Our method employs a two-step data association process to obtain the poses of WLI and OM data. By leveraging the neural implicit representation, we fuse multi-modal data and apply color decomposition technology to extract the sample's natural color. Tested on our multi-modal dataset of various microscale samples, OpticFusion achieves detailed 3D reconstructions with color textures. Our method provides an effective tool for practical applications across numerous microscale research fields. The source code and our real-world dataset are available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Perspective Transition of Large Language Models for Solving Subjective Tasks", "authors": "Xiaolong Wang, Yuanchi Zhang, Ziyue Wang, Yuzhuang Xu, Fuwen Luo, Yile Wang, Peng Li, Yang Liu", "subjects": "Subjects:\nComputation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "Large language models (LLMs) have revolutionized the field of natural language processing, enabling remarkable progress in various tasks. Different from objective tasks such as commonsense reasoning and arithmetic question-answering, the performance of LLMs on subjective tasks is still limited, where the perspective on the specific problem plays crucial roles for better interpreting the context and giving proper response. For example, in certain scenarios, LLMs may perform better when answering from an expert role perspective, potentially eliciting their relevant domain knowledge. In contrast, in some scenarios, LLMs may provide more accurate responses when answering from a third-person standpoint, enabling a more comprehensive understanding of the problem and potentially mitigating inherent biases. In this paper, we propose Reasoning through Perspective Transition (RPT), a method based on in-context learning that enables LLMs to dynamically select among direct, role, and third-person perspectives for the best way to solve corresponding subjective problem. Through extensive experiments on totally 12 subjective tasks by using both closed-source and open-source LLMs including GPT-4, GPT-3.5, Llama-3, and Qwen-2, our method outperforms widely used single fixed perspective based methods such as chain-of-thought prompting and expert prompting, highlights the intricate ways that LLMs can adapt their perspectives to provide nuanced and contextually appropriate responses for different problems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Are Open-Vocabulary Models Ready for Detection of MEP Elements on Construction Sites", "authors": "Abdalwhab Abdalwhab, Ali Imran, Sina Heydarian, Ivanka Iordanova, David St-Onge", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)", "abstract": "The construction industry has long explored robotics and computer vision, yet their deployment on construction sites remains very limited. These technologies have the potential to revolutionize traditional workflows by enhancing accuracy, efficiency, and safety in construction management. Ground robots equipped with advanced vision systems could automate tasks such as monitoring mechanical, electrical, and plumbing (MEP) systems. The present research evaluates the applicability of open-vocabulary vision-language models compared to fine-tuned, lightweight, closed-set object detectors for detecting MEP components using a mobile ground robotic platform. A dataset collected with cameras mounted on a ground robot was manually annotated and analyzed to compare model performance. The results demonstrate that, despite the versatility of vision-language models, fine-tuned lightweight models still largely outperform them in specialized environments and for domain-specific tasks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Knowledge Distillation for Image Restoration : Simultaneous Learning from Degraded and Clean Images", "authors": "Yongheng Zhang, Danfeng Yan", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)", "abstract": "Model compression through knowledge distillation has seen extensive application in classification and segmentation tasks. However, its potential in image-to-image translation, particularly in image restoration, remains underexplored. To address this gap, we propose a Simultaneous Learning Knowledge Distillation (SLKD) framework tailored for model compression in image restoration tasks. SLKD employs a dual-teacher, single-student architecture with two distinct learning strategies: Degradation Removal Learning (DRL) and Image Reconstruction Learning (IRL), simultaneously. In DRL, the student encoder learns from Teacher A to focus on removing degradation factors, guided by a novel BRISQUE extractor. In IRL, the student decoder learns from Teacher B to reconstruct clean images, with the assistance of a proposed PIQE extractor. These strategies enable the student to learn from degraded and clean images simultaneously, ensuring high-quality compression of image restoration models. Experimental results across five datasets and three tasks demonstrate that SLKD achieves substantial reductions in FLOPs and parameters, exceeding 80\\%, while maintaining strong image restoration performance."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          ThinTact:Thin Vision-Based Tactile Sensor by Lensless Imaging", "authors": "Jing Xu, Weihang Chen, Hongyu Qian, Dan Wu, Rui Chen", "subjects": "Subjects:\nRobotics (cs.RO)", "abstract": "Vision-based tactile sensors have drawn increasing interest in the robotics community. However, traditional lens-based designs impose minimum thickness constraints on these sensors, limiting their applicability in space-restricted settings. In this paper, we propose ThinTact, a novel lensless vision-based tactile sensor with a sensing field of over 200 mm2 and a thickness of less than 10 this http URL utilizes the mask-based lensless imaging technique to map the contact information to CMOS signals. To ensure real-time tactile sensing, we propose a real-time lensless reconstruction algorithm that leverages a frequency-spatial-domain joint filter based on discrete cosine transform (DCT). This algorithm achieves computation significantly faster than existing optimization-based methods. Additionally, to improve the sensing quality, we develop a mask optimization method based on the generic algorithm and the corresponding system matrix calibration this http URL evaluate the performance of our proposed lensless reconstruction and tactile sensing through qualitative and quantitative experiments. Furthermore, we demonstrate ThinTact's practical applicability in diverse applications, including texture recognition and contact-rich object manipulation. The paper will appear in the IEEE Transactions on Robotics: this https URL. Video: this https URL"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Large Language Model is Secretly a Protein Sequence Optimizer", "authors": "Yinkai Wang, Jiaxing He, Yuanqi Du, Xiaohui Chen, Jianan Canal Li, Li-Ping Liu, Xiaolin Xu, Soha Hassoun", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI); Quantitative Methods (q-bio.QM)", "abstract": "We consider the protein sequence engineering problem, which aims to find protein sequences with high fitness levels, starting from a given wild-type sequence. Directed evolution has been a dominating paradigm in this field which has an iterative process to generate variants and select via experimental feedback. We demonstrate large language models (LLMs), despite being trained on massive texts, are secretly protein sequence optimizers. With a directed evolutionary method, LLM can perform protein engineering through Pareto and experiment-budget constrained optimization, demonstrating success on both synthetic and experimental fitness landscapes."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          MagnetDB: A Longitudinal Torrent Discovery Dataset with IMDb-Matched Movies and TV Shows", "authors": "Scott Seidenberger, Noah Pursell, Anindya Maiti", "subjects": "Subjects:\nComputers and Society (cs.CY); Multimedia (cs.MM); Networking and Internet Architecture (cs.NI); Social and Information Networks (cs.SI)", "abstract": "BitTorrent remains a prominent channel for illicit distribution of copyrighted material, yet the supply side of such content remains understudied. We introduce MagnetDB, a longitudinal dataset of torrents discovered through the BitTorrent DHT between 2018 and 2024, containing more than 28.6 million torrents and metadata of more than 950 million files. While our primary focus is on enabling research based on the supply of pirated movies and TV shows, the dataset also encompasses other legitimate and illegitimate torrents. By applying IMDb-matching and annotation to movie and TV show torrents, MagnetDB facilitates detailed analyses of pirated content evolution in the BitTorrent network. Researchers can leverage MagnetDB to examine distribution trends, subcultural practices, and the gift economy within piracy ecosystems. Through its scale and temporal scope, MagnetDB presents a unique opportunity for investigating the broader dynamics of BitTorrent and advancing empirical knowledge on digital piracy."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Bias for Action: Video Implicit Neural Representations with Bias Modulation", "authors": "Alper Kayabasi, Anil Kumar Vadathya, Guha Balakrishnan, Vishwanath Saragadam", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "We propose a new continuous video modeling framework based on implicit neural representations (INRs) called ActINR. At the core of our approach is the observation that INRs can be considered as a learnable dictionary, with the shapes of the basis functions governed by the weights of the INR, and their locations governed by the biases. Given compact non-linear activation functions, we hypothesize that an INR's biases are suitable to capture motion across images, and facilitate compact representations for video sequences. Using these observations, we design ActINR to share INR weights across frames of a video sequence, while using unique biases for each frame. We further model the biases as the output of a separate INR conditioned on time index to promote smoothness. By training the video INR and this bias INR together, we demonstrate unique capabilities, including $10\\times$ video slow motion, $4\\times$ spatial super resolution along with $2\\times$ slow motion, denoising, and video inpainting. ActINR performs remarkably well across numerous video processing tasks (often achieving more than 6dB improvement), setting a new standard for continuous modeling of videos."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Text-guided Synthetic Geometric Augmentation for Zero-shot 3D Understanding", "authors": "Kohei Torimi, Ryosuke Yamada, Daichi Otsuka, Kensho Hara, Yuki M. Asano, Hirokatsu Kataoka, Yoshimitsu Aoki", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Zero-shot recognition models require extensive training data for generalization. However, in zero-shot 3D classification, collecting 3D data and captions is costly and laborintensive, posing a significant barrier compared to 2D vision. Recent advances in generative models have achieved unprecedented realism in synthetic data production, and recent research shows the potential for using generated data as training data. Here, naturally raising the question: Can synthetic 3D data generated by generative models be used as expanding limited 3D datasets? In response, we present a synthetic 3D dataset expansion method, Textguided Geometric Augmentation (TeGA). TeGA is tailored for language-image-3D pretraining, which achieves SoTA in zero-shot 3D classification, and uses a generative textto-3D model to enhance and extend limited 3D datasets. Specifically, we automatically generate text-guided synthetic 3D data and introduce a consistency filtering strategy to discard noisy samples where semantics and geometric shapes do not match with text. In the experiment to double the original dataset size using TeGA, our approach demonstrates improvements over the baselines, achieving zeroshot performance gains of 3.0% on Objaverse-LVIS, 4.6% on ScanObjectNN, and 8.7% on ModelNet40. These results demonstrate that TeGA effectively bridges the 3D data gap, enabling robust zero-shot 3D classification even with limited real training data and paving the way for zero-shot 3D vision application."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Text Semantics to Flexible Design: A Residential Layout Generation Method Based on Stable Diffusion Model", "authors": "Zijin Qiu, Jiepeng Liu, Yi Xia, Hongtuo Qi, Pengkun Liu", "subjects": "Subjects:\nArtificial Intelligence (cs.AI)", "abstract": "Flexibility in the AI-based residential layout design remains a significant challenge, as traditional methods like rule-based heuristics and graph-based generation often lack flexibility and require substantial design knowledge from users. To address these limitations, we propose a cross-modal design approach based on the Stable Diffusion model for generating flexible residential layouts. The method offers multiple input types for learning objectives, allowing users to specify both boundaries and layouts. It incorporates natural language as design constraints and introduces ControlNet to enable stable layout generation through two distinct pathways. We also present a scheme that encapsulates design expertise within a knowledge graph and translates it into natural language, providing an interpretable representation of design knowledge. This comprehensibility and diversity of input options enable professionals and non-professionals to directly express design requirements, enhancing flexibility and controllability. Finally, experiments verify the flexibility of the proposed methods under multimodal constraints better than state-of-the-art models, even when specific semantic information about room areas or connections is incomplete."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SoccerSynth-Detection: A Synthetic Dataset for Soccer Player Detection", "authors": "Haobin Qin, Calvin Yeung, Rikuhei Umemoto, Keisuke Fujii", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "In soccer video analysis, player detection is essential for identifying key events and reconstructing tactical positions. The presence of numerous players and frequent occlusions, combined with copyright restrictions, severely restricts the availability of datasets, leaving limited options such as SoccerNet-Tracking and SportsMOT. These datasets suffer from a lack of diversity, which hinders algorithms from adapting effectively to varied soccer video contexts. To address these challenges, we developed SoccerSynth-Detection, the first synthetic dataset designed for the detection of synthetic soccer players. It includes a broad range of random lighting and textures, as well as simulated camera motion blur. We validated its efficacy using the object detection model (Yolov8n) against real-world datasets (SoccerNet-Tracking and SportsMoT). In transfer tests, it matched the performance of real datasets and significantly outperformed them in images with motion blur; in pre-training tests, it demonstrated its efficacy as a pre-training dataset, significantly enhancing the algorithm's overall performance. Our work demonstrates the potential of synthetic datasets to replace real datasets for algorithm training in the field of soccer video analysis."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Free-Knots Kolmogorov-Arnold Network: On the Analysis of Spline Knots and Advancing Stability", "authors": "Liangwewi Nathan Zheng, Wei Emma Zhang, Lin Yue, Miao Xu, Olaf Maennel, Weitong Chen", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "Kolmogorov-Arnold Neural Networks (KANs) have gained significant attention in the machine learning community. However, their implementation often suffers from poor training stability and heavy trainable parameter. Furthermore, there is limited understanding of the behavior of the learned activation functions derived from B-splines. In this work, we analyze the behavior of KANs through the lens of spline knots and derive the lower and upper bound for the number of knots in B-spline-based KANs. To address existing limitations, we propose a novel Free Knots KAN that enhances the performance of the original KAN while reducing the number of trainable parameters to match the trainable parameter scale of standard Multi-Layer Perceptrons (MLPs). Additionally, we introduce new a training strategy to ensure $C^2$ continuity of the learnable spline, resulting in smoother activation compared to the original KAN and improve the training stability by range expansion. The proposed method is comprehensively evaluated on 8 datasets spanning various domains, including image, text, time series, multimodal, and function approximation tasks. The promising results demonstrates the feasibility of KAN-based network and the effectiveness of proposed method."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SEAL: Entangled White-box Watermarks on Low-Rank Adaptation", "authors": "Giyeong Oh, Seajin Kim, Woohyun Cho, Sangkyu Lee, Jiwan Chung, Dokyung Song, Youngjae Yu", "subjects": "Subjects:\nArtificial Intelligence (cs.AI); Cryptography and Security (cs.CR)", "abstract": "Recently, LoRA and its variants have become the de facto strategy for training and sharing task-specific versions of large pretrained models, thanks to their efficiency and simplicity. However, the issue of copyright protection for LoRA weights, especially through watermark-based techniques, remains underexplored. To address this gap, we propose SEAL (SEcure wAtermarking on LoRA weights), the universal whitebox watermarking for LoRA. SEAL embeds a secret, non-trainable matrix between trainable LoRA weights, serving as a passport to claim ownership. SEAL then entangles the passport with the LoRA weights through training, without extra loss for entanglement, and distributes the finetuned weights after hiding the passport. When applying SEAL, we observed no performance degradation across commonsense reasoning, textual/visual instruction tuning, and text-to-image synthesis tasks. We demonstrate that SEAL is robust against a variety of known attacks: removal, obfuscation, and ambiguity attacks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Graded Courrent PDL", "authors": "Chun-Yu Lin", "subjects": "Subjects:\nLogic in Computer Science (cs.LO)", "abstract": "Propositional Dynamic Logic, PDL, is a modal logic designed to formalize the reasoning about programs. By extending accessibility between states to states and state sets, concurrent propositional dynamic logic CPDL, is introduced to include concurrent programs due to Peleg and Goldblatt. We study a many-valued generalization of CPDL where the satisfiability and the reachability relation between states and state sets are graded over a finite \u0141ukasiewicz chain. Finitely-valued dynamic logic has been shown to be useful in formalizing reasoning about program behaviors under uncertainty. We obtain completeness results for all finitely valued PDL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Interoceptive Robots for Convergent Shared Control in Collaborative Construction Work", "authors": "Xiaoshan Zhou, Carol C. Menassa, Vineet R. Kamat", "subjects": "Subjects:\nRobotics (cs.RO)", "abstract": "Building autonomous mobile robots (AMRs) with optimized efficiency and adaptive capabilities-able to respond to changing task demands and dynamic environments-is a strongly desired goal for advancing construction robotics. Such robots can play a critical role in enabling automation, reducing operational carbon footprints, and supporting modular construction processes. Inspired by the adaptive autonomy of living organisms, we introduce interoception, which centers on the robot's internal state representation, as a foundation for developing self-reflection and conscious learning to enable continual learning and adaptability in robotic agents. In this paper, we factorize internal state variables and mathematical properties as \"cognitive dissonance\" in shared control paradigms, where human interventions occasionally occur. We offer a new perspective on how interoception can help build adaptive motion planning in AMRs by integrating the legacy of heuristic costs from grid/graph-based algorithms with recent advances in neuroscience and reinforcement learning. Declarative and procedural knowledge extracted from human semantic inputs is encoded into a hypergraph model that overlaps with the spatial configuration of onsite layout for path planning. In addition, we design a velocity-replay module using an encoder-decoder architecture with few-shot learning to enable robots to replicate velocity profiles in contextualized scenarios for multi-robot synchronization and handover collaboration. These \"cached\" knowledge representations are demonstrated in simulated environments for multi-robot motion planning and stacking tasks. The insights from this study pave the way toward artificial general intelligence in AMRs, fostering their progression from complexity to competence in construction automation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          LAVCap: LLM-based Audio-Visual Captioning using Optimal Transport", "authors": "Kyeongha Rho, Hyeongkeun Lee, Valentio Iverson, Joon Son Chung", "subjects": "Subjects:\nMultimedia (cs.MM); Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS)", "abstract": "Automated audio captioning is a task that generates textual descriptions for audio content, and recent studies have explored using visual information to enhance captioning quality. However, current methods often fail to effectively fuse audio and visual data, missing important semantic cues from each modality. To address this, we introduce LAVCap, a large language model (LLM)-based audio-visual captioning framework that effectively integrates visual information with audio to improve audio captioning performance. LAVCap employs an optimal transport-based alignment loss to bridge the modality gap between audio and visual features, enabling more effective semantic extraction. Additionally, we propose an optimal transport attention module that enhances audio-visual fusion using an optimal transport assignment map. Combined with the optimal training strategy, experimental results demonstrate that each component of our framework is effective. LAVCap outperforms existing state-of-the-art methods on the AudioCaps dataset, without relying on large datasets or post-processing. Code is available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          To Retrieve or Not to Retrieve? Uncertainty Detection for Dynamic Retrieval Augmented Generation", "authors": "Kaustubh D. Dhole", "subjects": "Subjects:\nComputation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "abstract": "Retrieval-Augmented Generation equips large language models with the capability to retrieve external knowledge, thereby mitigating hallucinations by incorporating information beyond the model's intrinsic abilities. However, most prior works have focused on invoking retrieval deterministically, which makes it unsuitable for tasks such as long-form question answering. Instead, dynamically performing retrieval by invoking it only when the underlying LLM lacks the required knowledge can be more efficient. In this context, we delve deeper into the question, \"To Retrieve or Not to Retrieve?\" by exploring multiple uncertainty detection methods. We evaluate these methods for the task of long-form question answering, employing dynamic retrieval, and present our comparisons. Our findings suggest that uncertainty detection metrics, such as Degree Matrix Jaccard and Eccentricity, can reduce the number of retrieval calls by almost half, with only a slight reduction in question-answering accuracy."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Scheduling Coflows for Minimizing the Maximum Completion Time in Heterogeneous Parallel Networks", "authors": "Chi-Yeh Chen", "subjects": "Subjects:\nData Structures and Algorithms (cs.DS)", "abstract": "Coflow represents a network abstraction that models communication patterns within data centers. The scheduling of coflows is a prevalent issue in large data center environments and is classified as an $\\mathcal{NP}$-hard problem. This paper focuses on the scheduling of coflows in heterogeneous parallel networks, defined by architectures featuring multiple network cores operating concurrently. We introduce two pseudo-polynomial-time algorithms and two polynomial-time approximation algorithms to minimize the maximum completion time (makespan) in heterogeneous parallel networks. We propose a randomized algorithm that offers an expected approximation ratio of 1.5. Building upon this foundation, we provide a deterministic algorithm that utilizes derandomization techniques, which offers a performance guarantee of $1.5 + \\frac{1}{2 \\cdot LB}$, where $LB$ is the lower bound of the makespan for each instance. To address time complexity concerns, we implement an exponential partitioning of time intervals and present a randomized algorithm with an expected approximation ratio of $1.5 + \\epsilon$ in polynomial time where $\\epsilon>0$. Additionally, we develop a deterministic algorithm with a performance guarantee expressed as $\\max\\left\\{1.5+\\epsilon, 1.5+\\frac{1}{2 \\cdot LB}\\right\\}$ within polynomial time. These advancements markedly enhance the best-known approximation ratio of $2+\\epsilon$."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Efficient Few-Shot Medical Image Analysis via Hierarchical Contrastive Vision-Language Learning", "authors": "Harrison Fuller, Fernando Gabriela Garcia, Victor Flores", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL)", "abstract": "Few-shot learning in medical image classification presents a significant challenge due to the limited availability of annotated data and the complex nature of medical imagery. In this work, we propose Adaptive Vision-Language Fine-tuning with Hierarchical Contrastive Alignment (HiCA), a novel framework that leverages the capabilities of Large Vision-Language Models (LVLMs) for medical image analysis. HiCA introduces a two-stage fine-tuning strategy, combining domain-specific pretraining and hierarchical contrastive learning to align visual and textual representations at multiple levels. We evaluate our approach on two benchmark datasets, Chest X-ray and Breast Ultrasound, achieving state-of-the-art performance in both few-shot and zero-shot settings. Further analyses demonstrate the robustness, generalizability, and interpretability of our method, with substantial improvements in performance compared to existing baselines. Our work highlights the potential of hierarchical contrastive strategies in adapting LVLMs to the unique challenges of medical imaging tasks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Physics-informed deep learning for infectious disease forecasting", "authors": "Ying Qian, \u00c9ric Marty, Avranil Basu, Eamon B. O'Dea, Xianqiao Wang, Spencer Fox, Pejman Rohani, John M. Drake, He Li", "subjects": "Subjects:\nMachine Learning (cs.LG); Quantitative Methods (q-bio.QM)", "abstract": "Accurate forecasting of contagious illnesses has become increasingly important to public health policymaking, and better prediction could prevent the loss of millions of lives. To better prepare for future pandemics, it is essential to improve forecasting methods and capabilities. In this work, we propose a new infectious disease forecasting model based on physics-informed neural networks (PINNs), an emerging area of scientific machine learning. The proposed PINN model incorporates dynamical systems representations of disease transmission into the loss function, thereby assimilating epidemiological theory and data using neural networks (NNs). Our approach is designed to prevent model overfitting, which often occurs when training deep learning models with observation data alone. In addition, we employ an additional sub-network to account for mobility, vaccination, and other covariates that influence the transmission rate, a key parameter in the compartment model. To demonstrate the capability of the proposed model, we examine the performance of the model using state-level COVID-19 data in California. Our simulation results show that predictions of PINN model on the number of cases, deaths, and hospitalizations are consistent with existing benchmarks. In particular, the PINN model outperforms the basic NN model and naive baseline forecast. We also show that the performance of the PINN model is comparable to a sophisticated Gaussian infection state space with time dependence (GISST) forecasting model that integrates the compartment model with a data observation model and a regression model for inferring parameters in the compartment model. Nonetheless, the PINN model offers a simpler structure and is easier to implement. Our results show that the proposed forecaster could potentially serve as a new computational tool to enhance the current capacity of infectious disease forecasting."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Creating Virtual Environments with 3D Gaussian Splatting: A Comparative Study", "authors": "Shi Qiu, Binzhu Xie, Qixuan Liu, Pheng-Ann Heng", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR); Human-Computer Interaction (cs.HC)", "abstract": "3D Gaussian Splatting (3DGS) has recently emerged as an innovative and efficient 3D representation technique. While its potential for extended reality (XR) applications is frequently highlighted, its practical effectiveness remains underexplored. In this work, we examine three distinct 3DGS-based approaches for virtual environment (VE) creation, leveraging their unique strengths for efficient and visually compelling scene representation. By conducting a comparable study, we evaluate the feasibility of 3DGS in creating immersive VEs, identify its limitations in XR applications, and discuss future research and development opportunities."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Finding the Trigger: Causal Abductive Reasoning on Video Events", "authors": "Thao Minh Le, Vuong Le, Kien Do, Sunil Gupta, Svetha Venkatesh, Truyen Tran", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "This paper introduces a new problem, Causal Abductive Reasoning on Video Events (CARVE), which involves identifying causal relationships between events in a video and generating hypotheses about causal chains that account for the occurrence of a target event. To facilitate research in this direction, we create two new benchmark datasets with both synthetic and realistic videos, accompanied by trigger-target labels generated through a novel counterfactual synthesis approach. To explore the challenge of solving CARVE, we present a Causal Event Relation Network (CERN) that examines the relationships between video events in temporal and semantic spaces to efficiently determine the root-cause trigger events. Through extensive experiments, we demonstrate the critical roles of event relational representation learning and interaction modeling in solving video causal reasoning challenges. The introduction of the CARVE task, along with the accompanying datasets and the CERN framework, will advance future research on video causal reasoning and significantly facilitate various applications, including video surveillance, root-cause analysis and movie content management."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          RoboReflect: Robotic Reflective Reasoning for Grasping Ambiguous-Condition Objects", "authors": "Zhen Luo, Yixuan Yang, Chang Cai, Yanfu Zhang, Feng Zheng", "subjects": "Subjects:\nRobotics (cs.RO)", "abstract": "As robotic technology rapidly develops, robots are being employed in an increasing number of fields. However, due to the complexity of deployment environments or the prevalence of ambiguous-condition objects, the practical application of robotics still faces many challenges, leading to frequent errors. Traditional methods and some LLM-based approaches, although improved, still require substantial human intervention and struggle with autonomous error correction in complex this http URL this work, we propose RoboReflect, a novel framework leveraging large vision-language models (LVLMs) to enable self-reflection and autonomous error correction in robotic grasping tasks. RoboReflect allows robots to automatically adjust their strategies based on unsuccessful attempts until successful execution is this http URL corrected strategies are saved in a memory for future task this http URL evaluate RoboReflect through extensive testing on eight common objects prone to ambiguous conditions of three this http URL results demonstrate that RoboReflect not only outperforms existing grasp pose estimation methods like AnyGrasp and high-level action planning techniques using GPT-4V but also significantly enhances the robot's ability to adapt and correct errors independently. These findings underscore the critical importance of autonomous selfreflection in robotic systems while effectively addressing the challenges posed by ambiguous environments."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Understanding Mental Health Content on Social Media and Its Effect Towards Suicidal Ideation", "authors": "Mohaiminul Islam Bhuiyan, Nur Shazwani Kamarudin, Nur Hafieza Ismail", "subjects": "Subjects:\nComputers and Society (cs.CY); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "abstract": "This review underscores the critical need for effective strategies to identify and support individuals with suicidal ideation, exploiting technological innovations in ML and DL to further suicide prevention efforts. The study details the application of these technologies in analyzing vast amounts of unstructured social media data to detect linguistic patterns, keywords, phrases, tones, and contextual cues associated with suicidal thoughts. It explores various ML and DL models like SVMs, CNNs, LSTM, neural networks, and their effectiveness in interpreting complex data patterns and emotional nuances within text data. The review discusses the potential of these technologies to serve as a life-saving tool by identifying at-risk individuals through their digital traces. Furthermore, it evaluates the real-world effectiveness, limitations, and ethical considerations of employing these technologies for suicide prevention, stressing the importance of responsible development and usage. The study aims to fill critical knowledge gaps by analyzing recent studies, methodologies, tools, and techniques in this field. It highlights the importance of synthesizing current literature to inform practical tools and suicide prevention efforts, guiding innovation in reliable, ethical systems for early intervention. This research synthesis evaluates the intersection of technology and mental health, advocating for the ethical and responsible application of ML, DL, and NLP to offer life-saving potential worldwide while addressing challenges like generalizability, biases, privacy, and the need for further research to ensure these technologies do not exacerbate existing inequities and harms."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Study of In-Context-Learning-Based Text-to-SQL Errors", "authors": "Jiawei Shen, Chengcheng Wan, Ruoyi Qiao, Jiazhen Zou, Hang Xu, Yuchen Shao, Yueling Zhang, Weikai Miao, Geguang Pu", "subjects": "Subjects:\nComputation and Language (cs.CL); Artificial Intelligence (cs.AI); Software Engineering (cs.SE)", "abstract": "Large language models (LLMs) have been adopted to perform text-to-SQL tasks, utilizing their in-context learning (ICL) capability to translate natural language questions into structured query language (SQL). However, such a technique faces correctness problems and requires efficient repairing solutions. In this paper, we conduct the first comprehensive study of text-to-SQL errors. Our study covers four representative ICL-based techniques, five basic repairing methods, two benchmarks, and two LLM settings. We find that text-to-SQL errors are widespread and summarize 29 error types of 7 categories. We also find that existing repairing attempts have limited correctness improvement at the cost of high computational overhead with many mis-repairs. Based on the findings, we propose MapleRepair, a novel text-to-SQL error detection and repairing framework. The evaluation demonstrates that MapleRepair outperforms existing solutions by repairing 13.8% more queries with neglectable mis-repairs and 67.4% less overhead."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Shape-Based Single Object Classification Using Ensemble Method Classifiers", "authors": "Nur Shazwani Kamarudin, Mokhairi Makhtar, Syadiah Nor Wan Shamsuddin, Syed Abdullah Fadzli", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "abstract": "Nowadays, more and more images are available. Annotation and retrieval of the images pose classification problems, where each class is defined as the group of database images labelled with a common semantic label. Various systems have been proposed for content-based retrieval, as well as for image classification and indexing. In this paper, a hierarchical classification framework has been proposed for bridging the semantic gap effectively and achieving multi-category image classification. A well known pre-processing and post-processing method was used and applied to three problems; image segmentation, object identification and image classification. The method was applied to classify single object images from Amazon and Google datasets. The classification was tested for four different classifiers; BayesNetwork (BN), Random Forest (RF), Bagging and Vote. The estimated classification accuracies ranged from 20% to 99% (using 10-fold cross validation). The Bagging classifier presents the best performance, followed by the Random Forest classifier."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SOP-Agent: Empower General Purpose AI Agent with Domain-Specific SOPs", "authors": "Anbang Ye, Qianran Ma, Jia Chen, Muqi Li, Tong Li, Fujiao Liu, Siqi Mai, Meichen Lu, Haitao Bao, Yang You", "subjects": "Subjects:\nArtificial Intelligence (cs.AI)", "abstract": "Despite significant advancements in general-purpose AI agents, several challenges still hinder their practical application in real-world scenarios. First, the limited planning capabilities of Large Language Models (LLM) restrict AI agents from effectively solving complex tasks that require long-horizon planning. Second, general-purpose AI agents struggle to efficiently utilize domain-specific knowledge and human expertise. In this paper, we introduce the Standard Operational Procedure-guided Agent (SOP-agent), a novel framework for constructing domain-specific agents through pseudocode-style Standard Operational Procedures (SOPs) written in natural language. Formally, we represent a SOP as a decision graph, which is traversed to guide the agent in completing tasks specified by the SOP. We conduct extensive experiments across tasks in multiple domains, including decision-making, search and reasoning, code generation, data cleaning, and grounded customer service. The SOP-agent demonstrates excellent versatility, achieving performance superior to general-purpose agent frameworks and comparable to domain-specific agent systems. Additionally, we introduce the Grounded Customer Service Benchmark, the first benchmark designed to evaluate the grounded decision-making capabilities of AI agents in customer service scenarios based on SOPs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Modeling Language for Scenario Development of Autonomous Driving Systems", "authors": "Toshiaki Aoki, Takashi Tomita, Tatsuji Kawai, Daisuke Kawakami, Nobuo Chida", "subjects": "Subjects:\nSoftware Engineering (cs.SE)", "abstract": "Autonomous driving systems are typically verified based on scenarios. To represent the positions and movements of cars in these scenarios, diagrams that utilize icons are typically employed. However, the interpretation of such diagrams is typically ambiguous, which can lead to misunderstandings among users, making them unsuitable for the development of high-reliability systems. To address this issue, this study introduces a notation called the car position diagram (CPD). The CPD allows for the concise representation of numerous scenarios and is particularly suitable for scenario analysis and design. In addition, we propose a method for converting CPD-based models into propositional logic formulas and enumerating all scenarios using a SAT solver. A tool for scenario enumeration is implemented, and experiments are conducted on both typical car behaviors and international standards. The results demonstrate that the CPD enables the concise description of numerous scenarios, thereby confirming the effectiveness of our scenario analysis method."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Cooperative Decentralized Backdoor Attacks on Vertical Federated Learning", "authors": "Seohyun Lee, Wenzhi Fang, Anindya Bijoy Das, Seyyedali Hosseinalipour, David J. Love, Christopher G. Brinton", "subjects": "Subjects:\nMachine Learning (cs.LG); Cryptography and Security (cs.CR)", "abstract": "Federated learning (FL) is vulnerable to backdoor attacks, where adversaries alter model behavior on target classification labels by embedding triggers into data samples. While these attacks have received considerable attention in horizontal FL, they are less understood for vertical FL (VFL), where devices hold different features of the samples, and only the server holds the labels. In this work, we propose a novel backdoor attack on VFL which (i) does not rely on gradient information from the server and (ii) considers potential collusion among multiple adversaries for sample selection and trigger embedding. Our label inference model augments variational autoencoders with metric learning, which adversaries can train locally. A consensus process over the adversary graph topology determines which datapoints to poison. We further propose methods for trigger splitting across the adversaries, with an intensity-based implantation scheme skewing the server towards the trigger. Our convergence analysis reveals the impact of backdoor perturbations on VFL indicated by a stationarity gap for the trained model, which we verify empirically as well. We conduct experiments comparing our attack with recent backdoor VFL approaches, finding that ours obtains significantly higher success rates for the same main task performance despite not using server information. Additionally, our results verify the impact of collusion on attack performance."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Soft Knowledge Distillation with Multi-Dimensional Cross-Net Attention for Image Restoration Models Compression", "authors": "Yongheng Zhang, Danfeng Yan", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Transformer-based encoder-decoder models have achieved remarkable success in image-to-image transfer tasks, particularly in image restoration. However, their high computational complexity-manifested in elevated FLOPs and parameter counts-limits their application in real-world scenarios. Existing knowledge distillation methods in image restoration typically employ lightweight student models that directly mimic the intermediate features and reconstruction results of the teacher, overlooking the implicit attention relationships between them. To address this, we propose a Soft Knowledge Distillation (SKD) strategy that incorporates a Multi-dimensional Cross-net Attention (MCA) mechanism for compressing image restoration models. This mechanism facilitates interaction between the student and teacher across both channel and spatial dimensions, enabling the student to implicitly learn the attention matrices. Additionally, we employ a Gaussian kernel function to measure the distance between student and teacher features in kernel space, ensuring stable and efficient feature learning. To further enhance the quality of reconstructed images, we replace the commonly used L1 or KL divergence loss with a contrastive learning loss at the image level. Experiments on three tasks-image deraining, deblurring, and denoising-demonstrate that our SKD strategy significantly reduces computational complexity while maintaining strong image restoration capabilities."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Safety-Critical Control for Discrete-time Stochastic Systems with Flexible Safe Bounds using Affine and Quadratic Control Barrier Functions", "authors": "Sotaro Fushimi, Kenta Hoshino, Yuki Nishimura", "subjects": "Subjects:\nSystems and Control (eess.SY)", "abstract": "This paper presents a safe controller synthesis of discrete-time stochastic systems using Control Barrier Functions (CBFs). The proposed condition allows the design of a safe controller synthesis that ensures system safety while avoiding the conservative bounds of safe probabilities. In particular, this study focuses on the design of CBFs that provide flexibility in the choice of functions to obtain tighter bounds on the safe probabilities. Numerical examples demonstrate the effectiveness of the approach."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Algorithm for Semantic Network Generation from Texts of Low Resource Languages Such as Kiswahili", "authors": "Barack Wamkaya Wanjawa, Lawrence Muchemi, Evans Miriti", "subjects": "Subjects:\nComputation and Language (cs.CL)", "abstract": "Processing low-resource languages, such as Kiswahili, using machine learning is difficult due to lack of adequate training data. However, such low-resource languages are still important for human communication and are already in daily use and users need practical machine processing tasks such as summarization, disambiguation and even question answering (QA). One method of processing such languages, while bypassing the need for training data, is the use semantic networks. Some low resource languages, such as Kiswahili, are of the subject-verb-object (SVO) structure, and similarly semantic networks are a triple of subject-predicate-object, hence SVO parts of speech tags can map into a semantic network triple. An algorithm to process raw natural language text and map it into a semantic network is therefore necessary and desirable in structuring low resource languages texts. This algorithm tested on the Kiswahili QA task with upto 78.6% exact match."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          On Learning Informative Trajectory Embeddings for Imitation, Classification and Regression", "authors": "Zichang Ge, Changyu Chen, Arunesh Sinha, Pradeep Varakantham", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "In real-world sequential decision making tasks like autonomous driving, robotics, and healthcare, learning from observed state-action trajectories is critical for tasks like imitation, classification, and clustering. For example, self-driving cars must replicate human driving behaviors, while robots and healthcare systems benefit from modeling decision sequences, whether or not they come from expert data. Existing trajectory encoding methods often focus on specific tasks or rely on reward signals, limiting their ability to generalize across domains and tasks. Inspired by the success of embedding models like CLIP and BERT in static domains, we propose a novel method for embedding state-action trajectories into a latent space that captures the skills and competencies in the dynamic underlying decision-making processes. This method operates without the need for reward labels, enabling better generalization across diverse domains and tasks. Our contributions are threefold: (1) We introduce a trajectory embedding approach that captures multiple abilities from state-action data. (2) The learned embeddings exhibit strong representational power across downstream tasks, including imitation, classification, clustering, and regression. (3) The embeddings demonstrate unique properties, such as controlling agent behaviors in IQ-Learn and an additive structure in the latent space. Experimental results confirm that our method outperforms traditional approaches, offering more flexible and powerful trajectory representations for various applications. Our code is available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Neural Honeytrace: A Robust Plug-and-Play Watermarking Framework against Model Extraction Attacks", "authors": "Yixiao Xu, Binxing Fang, Rui Wang, Yinghai Zhou, Shouling Ji, Yuan Liu, Mohan Li, Zhihong Tian", "subjects": "Subjects:\nCryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "abstract": "Developing high-performance deep learning models is resource-intensive, leading model owners to utilize Machine Learning as a Service (MLaaS) platforms instead of publicly releasing their models. However, malicious users may exploit query interfaces to execute model extraction attacks, reconstructing the target model's functionality locally. While prior research has investigated triggerable watermarking techniques for asserting ownership, existing methods face significant challenges: (1) most approaches require additional training, resulting in high overhead and limited flexibility, and (2) they often fail to account for advanced attackers, leaving them vulnerable to adaptive attacks. In this paper, we propose Neural Honeytrace, a robust plug-and-play watermarking framework against model extraction attacks. We first formulate a watermark transmission model from an information-theoretic perspective, providing an interpretable account of the principles and limitations of existing triggerable watermarking. Guided by the model, we further introduce: (1) a similarity-based training-free watermarking method for plug-and-play and flexible watermarking, and (2) a distribution-based multi-step watermark information transmission strategy for robust watermarking. Comprehensive experiments on four datasets demonstrate that Neural Honeytrace outperforms previous methods in efficiency and resisting adaptive attacks. Neural Honeytrace reduces the average number of samples required for a worst-case t-Test-based copyright claim from $12,000$ to $200$ with zero training cost."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Solving Infinite-Player Games with Player-to-Strategy Networks", "authors": "Carlos Martin, Tuomas Sandholm", "subjects": "Subjects:\nComputer Science and Game Theory (cs.GT)", "abstract": "We present a new approach to solving games with a countably or uncountably infinite number of players. Such games are often used to model multiagent systems with a large number of agents. The latter are frequently encountered in economics, financial markets, crowd dynamics, congestion analysis, epidemiology, and population ecology, among other fields. Our two primary contributions are as follows. First, we present a way to represent strategy profiles for an infinite number of players, which we name a Player-to-Strategy Network (P2SN). Such a network maps players to strategies, and exploits the generalization capabilities of neural networks to learn across an infinite number of inputs (players) simultaneously. Second, we present an algorithm, which we name Shared-Parameter Simultaneous Gradient (SPSG), for training such a network, with the goal of finding an approximate Nash equilibrium. This algorithm generalizes simultaneous gradient ascent and its variants, which are classical equilibrium-seeking dynamics used for multiagent reinforcement learning. We test our approach on infinite-player games and observe its convergence to approximate Nash equilibria. Our method can handle games with infinitely many states, infinitely many players, infinitely many actions (and mixed strategies on them), and discontinuous utility functions."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Identifying Information from Observations with Uncertainty and Novelty", "authors": "Derek S. Prijatelj (1), Timothy J. Ireland (2), Walter J. Scheirer (1) ((1) University of Notre Dame, (2) Independent Researcher)", "subjects": "Subjects:\nMachine Learning (cs.LG); Machine Learning (stat.ML)", "abstract": "A machine learning tasks from observations must encounter and process uncertainty and novelty, especially when it is expected to maintain performance when observing new information and to choose the best fitting hypothesis to the currently observed information. In this context, some key questions arise: what is information, how much information did the observations provide, how much information is required to identify the data-generating process, how many observations remain to get that information, and how does a predictor determine that it has observed novel information? This paper strengthens existing answers to these questions by formalizing the notion of \"identifiable information\" that arises from the language used to express the relationship between distinct states. Model identifiability and sample complexity are defined via computation of an indicator function over a set of hypotheses. Their properties and asymptotic statistics are described for data-generating processes ranging from deterministic processes to ergodic stationary stochastic processes. This connects the notion of identifying information in finite steps with asymptotic statistics and PAC-learning. The indicator function's computation naturally formalizes novel information and its identification from observations with respect to a hypothesis set. We also proved that computable PAC-Bayes learners' sample complexity distribution is determined by its moments in terms of the the prior probability distribution over a fixed finite hypothesis set."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Prompt-CAM: A Simpler Interpretable Transformer for Fine-Grained Analysis", "authors": "Arpita Chowdhury, Dipanjyoti Paul, Zheda Mai, Jianyang Gu, Ziheng Zhang, Kazi Sajeed Mehrab, Elizabeth G. Campolongo, Daniel Rubenstein, Charles V. Stewart, Anuj Karpatne, Tanya Berger-Wolf, Yu Su, Wei-Lun Chao", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "We present a simple usage of pre-trained Vision Transformers (ViTs) for fine-grained analysis, aiming to identify and localize the traits that distinguish visually similar categories, such as different bird species or dog breeds. Pre-trained ViTs such as DINO have shown remarkable capabilities to extract localized, informative features. However, using saliency maps like Grad-CAM can hardly point out the traits: they often locate the whole object by a blurred, coarse heatmap, not traits. We propose a novel approach Prompt Class Attention Map (Prompt-CAM) to the rescue. Prompt-CAM learns class-specific prompts to a pre-trained ViT and uses the corresponding outputs for classification. To classify an image correctly, the true-class prompt must attend to the unique image patches not seen in other classes' images, i.e., traits. As such, the true class's multi-head attention maps reveal traits and their locations. Implementation-wise, Prompt-CAM is almost a free lunch by simply modifying the prediction head of Visual Prompt Tuning (VPT). This makes Prompt-CAM fairly easy to train and apply, sharply contrasting other interpretable methods that design specific models and training processes. It is even simpler than the recently published INterpretable TRansformer (INTR), whose encoder-decoder architecture prevents it from leveraging pre-trained ViTs. Extensive empirical studies on a dozen datasets from various domains (e.g., birds, fishes, insects, fungi, flowers, food, and cars) validate Prompt-CAM superior interpretation capability."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Jodes: Efficient Oblivious Join in the Distributed Setting", "authors": "Yilei Wang, Xiangdong Zeng, Sheng Wang, Feifei Li", "subjects": "Subjects:\nCryptography and Security (cs.CR); Databases (cs.DB); Distributed, Parallel, and Cluster Computing (cs.DC)", "abstract": "Trusted execution environment (TEE) has provided an isolated and secure environment for building cloud-based analytic systems, but it still suffers from access pattern leakages caused by side-channel attacks. To better secure the data, computation inside TEE enclave should be made oblivious, which introduces significant overhead and severely slows down the computation. A natural way to speed up is to build the analytic system with multiple servers in the distributed setting. However, this setting raises a new security concern -- the volumes of the transmissions among these servers can leak sensitive information to a network adversary. Existing works have designed specialized algorithms to address this concern, but their supports for equi-join, one of the most important but non-trivial database operators, are either inefficient, limited, or under a weak security assumption. In this paper, we present Jodes, an efficient oblivious join algorithm in the distributed setting. Jodes prevents the leakage on both the network and enclave sides, supports a general equi-join operation, and provides a high security level protection that only publicizes the input sizes and the output size. Meanwhile, it achieves both communication cost and computation cost asymptotically superior to existing algorithms. To demonstrate the practicality of Jodes, we conduct experiments in the distributed setting comprising 16 servers. Empirical results show that Jodes achieves up to a sixfold performance improvement over state-of-the-art join algorithms."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Robust UAV Path Planning with Obstacle Avoidance for Emergency Rescue", "authors": "Junteng Mao, Ziye Jia, Hanzhi Gu, Chenyu Shi, Haomin Shi, Lijun He, Qihui Wu", "subjects": "Subjects:\nRobotics (cs.RO); Systems and Control (eess.SY)", "abstract": "The unmanned aerial vehicles (UAVs) are efficient tools for diverse tasks such as electronic reconnaissance, agricultural operations and disaster relief. In the complex three-dimensional (3D) environments, the path planning with obstacle avoidance for UAVs is a significant issue for security assurance. In this paper, we construct a comprehensive 3D scenario with obstacles and no-fly zones for dynamic UAV trajectory. Moreover, a novel artificial potential field algorithm coupled with simulated annealing (APF-SA) is proposed to tackle the robust path planning problem. APF-SA modifies the attractive and repulsive potential functions and leverages simulated annealing to escape local minimum and converge to globally optimal solutions. Simulation results demonstrate that the effectiveness of APF-SA, enabling efficient autonomous path planning for UAVs with obstacle avoidance."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SE-BSFV: Online Subspace Learning based Shadow Enhancement and Background Suppression for ViSAR under Complex Background", "authors": "Shangqu Yan, Chenyang Luo, Yaowen Fu, Wenpeng Zhang, Wei Yang, Ruofeng Yu", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Video synthetic aperture radar (ViSAR) has attracted substantial attention in the moving target detection (MTD) field due to its ability to continuously monitor changes in the target area. In ViSAR, the moving targets' shadows will not offset and defocus, which is widely used as a feature for MTD. However, the shadows are difficult to distinguish from the low scattering region in the background, which will cause more missing and false alarms. Therefore, it is worth investigating how to enhance the distinction between the shadows and background. In this study, we proposed the Shadow Enhancement and Background Suppression for ViSAR (SE-BSFV) algorithm. The SE-BSFV algorithm is based on the low-rank representation (LRR) theory and adopts online subspace learning technique to enhance shadows and suppress background for ViSAR images. Firstly, we use a registration algorithm to register the ViSAR images and utilize Gaussian mixture distribution (GMD) to model the ViSAR data. Secondly, the knowledge learned from the previous frames is leveraged to estimate the GMD parameters of the current frame, and the Expectation-maximization (EM) algorithm is used to estimate the subspace parameters. Then, the foreground matrix of the current frame can be obtained. Finally, the alternating direction method of multipliers (ADMM) is used to eliminate strong scattering objects in the foreground matrix to obtain the final results. The experimental results indicate that the SE-BSFV algorithm significantly enhances the shadows' saliency and greatly improves the detection performance while ensuring efficiency compared with several other advanced pre-processing algorithms."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Rational Tuning of LLM Cascades via Probabilistic Modeling", "authors": "Michael J. Zellinger, Matt Thomson", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)", "abstract": "Understanding the reliability of large language models (LLMs) has recently garnered significant attention. Given LLMs' propensity to hallucinate, as well as their high sensitivity to prompt design, it is already challenging to predict the performance of an individual LLM. However, the problem becomes more complex for compound LLM systems such as cascades, where in addition to each model's standalone performance, we must understand how the error rates of different models interact. In this paper, we present a probabilistic model for the joint performance distribution of a sequence of LLMs, which enables a framework for rationally tuning the confidence thresholds of a LLM cascade using continuous optimization. Compared to selecting confidence thresholds using grid search, our parametric Markov-copula model significantly improves runtime scaling with respect to the length of the cascade and the desired resolution of the cost-error curve, turning them from intractable into low-order polynomial. In addition, the optimal thresholds computed using our continuous optimization-based algorithm increasingly outperform those found via grid search as cascade length grows, improving the area under the cost-error curve by 1.9% on average for cascades consisting of at least three models. Overall, our Markov-copula model provides a rational basis for tuning LLM cascade performance and points to the potential of probabilistic methods in analyzing LLM systems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          UVRM: A Scalable 3D Reconstruction Model from Unposed Videos", "authors": "Shiu-hong Kao, Xiao Li, Jinglu Wang, Chi-Keung Tang, Yu-Wing Tai, Yan Lu", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Large Reconstruction Models (LRMs) have recently become a popular method for creating 3D foundational models. Training 3D reconstruction models with 2D visual data traditionally requires prior knowledge of camera poses for the training samples, a process that is both time-consuming and prone to errors. Consequently, 3D reconstruction training has been confined to either synthetic 3D datasets or small-scale datasets with annotated poses. In this study, we investigate the feasibility of 3D reconstruction using unposed video data of various objects. We introduce UVRM, a novel 3D reconstruction model capable of being trained and evaluated on monocular videos without requiring any information about the pose. UVRM uses a transformer network to implicitly aggregate video frames into a pose-invariant latent feature space, which is then decoded into a tri-plane 3D representation. To obviate the need for ground-truth pose annotations during training, UVRM employs a combination of the score distillation sampling (SDS) method and an analysis-by-synthesis approach, progressively synthesizing pseudo novel-views using a pre-trained diffusion model. We qualitatively and quantitatively evaluate UVRM's performance on the G-Objaverse and CO3D datasets without relying on pose information. Extensive experiments show that UVRM is capable of effectively and efficiently reconstructing a wide range of 3D objects from unposed videos."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          ChartInsighter: An Approach for Mitigating Hallucination in Time-series Chart Summary Generation with A Benchmark Dataset", "authors": "Fen Wang, Bomiao Wang, Xueli Shu, Zhen Liu, Zekai Shao, Chao Liu, Siming Chen", "subjects": "Subjects:\nComputation and Language (cs.CL); Human-Computer Interaction (cs.HC)", "abstract": "Effective chart summary can significantly reduce the time and effort decision makers spend interpreting charts, enabling precise and efficient communication of data insights. Previous studies have faced challenges in generating accurate and semantically rich summaries of time-series data charts. In this paper, we identify summary elements and common hallucination types in the generation of time-series chart summaries, which serve as our guidelines for automatic generation. We introduce ChartInsighter, which automatically generates chart summaries of time-series data, effectively reducing hallucinations in chart summary generation. Specifically, we assign multiple agents to generate the initial chart summary and collaborate iteratively, during which they invoke external data analysis modules to extract insights and compile them into a coherent summary. Additionally, we implement a self-consistency test method to validate and correct our summary. We create a high-quality benchmark of charts and summaries, with hallucination types annotated on a sentence-by-sentence basis, facilitating the evaluation of the effectiveness of reducing hallucinations. Our evaluations using our benchmark show that our method surpasses state-of-the-art models, and that our summary hallucination rate is the lowest, which effectively reduces various hallucinations and improves summary quality. The benchmark is available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Making Your Dreams A Reality: Decoding the Dreams into a Coherent Video Story from fMRI Signals", "authors": "Yanwei Fu, Jianxiong Gao, Baofeng Yang, Jianfeng Feng", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "This paper studies the brave new idea for Multimedia community, and proposes a novel framework to convert dreams into coherent video narratives using fMRI data. Essentially, dreams have intrigued humanity for centuries, offering glimpses into our subconscious minds. Recent advancements in brain imaging, particularly functional magnetic resonance imaging (fMRI), have provided new ways to explore the neural basis of dreaming. By combining subjective dream experiences with objective neurophysiological data, we aim to understand the visual aspects of dreams and create complete video narratives. Our process involves three main steps: reconstructing visual perception, decoding dream imagery, and integrating dream stories. Using innovative techniques in fMRI analysis and language modeling, we seek to push the boundaries of dream research and gain deeper insights into visual experiences during sleep. This technical report introduces a novel approach to visually decoding dreams using fMRI signals and weaving dream visuals into narratives using language models. We gather a dataset of dreams along with descriptions to assess the effectiveness of our framework."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          RIS-Aided Fluid Antenna Array-Mounted UAV Networks", "authors": "Li-Hsiang Shen, Yi-Hsuan Chiu", "subjects": "Subjects:\nInformation Theory (cs.IT); Signal Processing (eess.SP)", "abstract": "This paper investigates reconfigurable intelligent surface (RIS)-assisted unmanned aerial vehicle (UAV) downlink networks with fluid antennas (FA), where RIS enables non-line-of-sight (NLoS) transmissions. Moreover, the FA is equipped on the UAV offering dynamic antenna position adjustment, enhancing spatial diversity besides UAV deployment. We aim at total downlink rate maximization while ensuring minimum user rate requirement. We consider joint optimization of active UAV beamforming, passive RIS beamforming, UAV deployment and FA position adjustment. To address the complex problem, we propose beamfomring for RIS/UAV and FA-UAV deployment (BRAUD) scheme by employing alternative optimization, successive convex approximation (SCA) and sequential rank-one constraint relaxation (SROCR) method for the decomposed subproblems. Simulation results demonstrate the effectiveness of RIS-FA-UAV, achieving the highest rate among existing architectures without FA/UAV/RIS deployment and without proper beamforming. Moreover, BRAUD achieves the highest rate among benchmarks of drop-rank method, heuristic optimizations and conventional zero-forcing beamforming as well as random method."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          PAL: Prompting Analytic Learning with Missing Modality for Multi-Modal Class-Incremental Learning", "authors": "Xianghu Yue, Yiming Chen, Xueyi Zhang, Xiaoxue Gao, Mengling Feng, Mingrui Lao, Huiping Zhuang, Haizhou Li", "subjects": "Subjects:\nMachine Learning (cs.LG); Multimedia (cs.MM); Image and Video Processing (eess.IV)", "abstract": "Multi-modal class-incremental learning (MMCIL) seeks to leverage multi-modal data, such as audio-visual and image-text pairs, thereby enabling models to learn continuously across a sequence of tasks while mitigating forgetting. While existing studies primarily focus on the integration and utilization of multi-modal information for MMCIL, a critical challenge remains: the issue of missing modalities during incremental learning phases. This oversight can exacerbate severe forgetting and significantly impair model performance. To bridge this gap, we propose PAL, a novel exemplar-free framework tailored to MMCIL under missing-modality scenarios. Concretely, we devise modality-specific prompts to compensate for missing information, facilitating the model to maintain a holistic representation of the data. On this foundation, we reformulate the MMCIL problem into a Recursive Least-Squares task, delivering an analytical linear solution. Building upon these, PAL not only alleviates the inherent under-fitting limitation in analytic learning but also preserves the holistic representation of missing-modality data, achieving superior performance with less forgetting across various multi-modal incremental scenarios. Extensive experiments demonstrate that PAL significantly outperforms competitive methods across various datasets, including UPMC-Food101 and N24News, showcasing its robustness towards modality absence and its anti-forgetting ability to maintain high incremental accuracy."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Style4Rec: Enhancing Transformer-based E-commerce Recommendation Systems with Style and Shopping Cart Information", "authors": "Berke Ugurlu, Ming-Yi Hong, Che Lin", "subjects": "Subjects:\nInformation Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "abstract": "Understanding users' product preferences is essential to the efficacy of a recommendation system. Precision marketing leverages users' historical data to discern these preferences and recommends products that align with them. However, recent browsing and purchase records might better reflect current purchasing inclinations. Transformer-based recommendation systems have made strides in sequential recommendation tasks, but they often fall short in utilizing product image style information and shopping cart data effectively. In light of this, we propose Style4Rec, a transformer-based e-commerce recommendation system that harnesses style and shopping cart information to enhance existing transformer-based sequential product recommendation systems. Style4Rec represents a significant step forward in personalized e-commerce recommendations, outperforming benchmarks across various evaluation metrics. Style4Rec resulted in notable improvements: HR@5 increased from 0.681 to 0.735, NDCG@5 increased from 0.594 to 0.674, and MRR@5 increased from 0.559 to 0.654. We tested our model using an e-commerce dataset from our partnering company and found that it exceeded established transformer-based sequential recommendation benchmarks across various evaluation metrics. Thus, Style4Rec presents a significant step forward in personalized e-commerce recommendation systems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          YETI (YET to Intervene) Proactive Interventions by Multimodal AI Agents in Augmented Reality Tasks", "authors": "Saptarashmi Bandyopadhyay, Vikas Bahirwani, Lavisha Aggarwal, Bhanu Guda, Lin Li, Andrea Colaco", "subjects": "Subjects:\nArtificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Emerging Technologies (cs.ET); Multiagent Systems (cs.MA)", "abstract": "Multimodal AI Agents are AI models that have the capability of interactively and cooperatively assisting human users to solve day-to-day tasks. Augmented Reality (AR) head worn devices can uniquely improve the user experience of solving procedural day-to-day tasks by providing egocentric multimodal (audio and video) observational capabilities to AI Agents. Such AR capabilities can help AI Agents see and listen to actions that users take which can relate to multimodal capabilities of human users. Existing AI Agents, either Large Language Models (LLMs) or Multimodal Vision-Language Models (VLMs) are reactive in nature, which means that models cannot take an action without reading or listening to the human user's prompts. Proactivity of AI Agents on the other hand can help the human user detect and correct any mistakes in agent observed tasks, encourage users when they do tasks correctly or simply engage in conversation with the user - akin to a human teaching or assisting a user. Our proposed YET to Intervene (YETI) multimodal agent focuses on the research question of identifying circumstances that may require the agent to intervene proactively. This allows the agent to understand when it can intervene in a conversation with human users that can help the user correct mistakes on tasks, like cooking, using AR. Our YETI Agent learns scene understanding signals based on interpretable notions of Structural Similarity (SSIM) on consecutive video frames. We also define the alignment signal which the AI Agent can learn to identify if the video frames corresponding to the user's actions on the task are consistent with expected actions. These signals are used by our AI Agent to determine when it should proactively intervene. We compare our results on the instances of proactive intervention in the HoloAssist multimodal benchmark for an expert agent guiding a user to complete procedural tasks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Path Planning for a UAV Swarm Using Formation Teaching-Learning-Based Optimization", "authors": "Van Truong Hoang, Manh Duong Phung", "subjects": "Subjects:\nRobotics (cs.RO); Systems and Control (eess.SY)", "abstract": "This work addresses the path planning problem for a group of unmanned aerial vehicles (UAVs) to maintain a desired formation during operation. Our approach formulates the problem as an optimization task by defining a set of fitness functions that not only ensure the formation but also include constraints for optimal and safe UAV operation. To optimize the fitness function and obtain a suboptimal path, we employ the teaching-learning-based optimization algorithm and then further enhance it with mechanisms such as mutation, elite strategy, and multi-subject combination. A number of simulations and experiments have been conducted to evaluate the proposed method. The results demonstrate that the algorithm successfully generates valid paths for the UAVs to fly in a triangular formation for an inspection task."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Multi-tiered Solution for Personalized Baggage Item Recommendations using FastText and Association Rule Mining", "authors": "Mudavath Ravi, Atul Negi", "subjects": "Subjects:\nInformation Retrieval (cs.IR)", "abstract": "This paper introduces an intelligent baggage item recommendation system to optimize packing for air travelers by providing tailored suggestions based on specific travel needs and destinations. Using FastText word embeddings and Association Rule Mining (ARM), the system ensures efficient luggage space utilization, compliance with weight limits, and an enhanced travel experience. The methodology comprises four phases: (1) data collection and preprocessing with pre-trained FastText embeddings for text representation and similarity scoring (2) a content-based recommendation system enriched by user search history (3) application of ARM to user interactions to uncover meaningful item associations and (4) integration of FastText and ARM for accurate, personalized recommendations. Performance is evaluated using metrics such as coverage, support, confidence, lift, leverage, and conviction. Results demonstrate the system's effectiveness in providing relevant suggestions, improving customer satisfaction, and simplifying the packing process. These insights advance personalized recommendations, targeted marketing, and product optimization in air travel and beyond."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Strategic Base Representation Learning via Feature Augmentations for Few-Shot Class Incremental Learning", "authors": "Parinita Nema, Vinod K Kurmi", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Few-shot class incremental learning implies the model to learn new classes while retaining knowledge of previously learned classes with a small number of training instances. Existing frameworks typically freeze the parameters of the previously learned classes during the incorporation of new classes. However, this approach often results in suboptimal class separation of previously learned classes, leading to overlap between old and new classes. Consequently, the performance of old classes degrades on new classes. To address these challenges, we propose a novel feature augmentation driven contrastive learning framework designed to enhance the separation of previously learned classes to accommodate new classes. Our approach involves augmenting feature vectors and assigning proxy labels to these vectors. This strategy expands the feature space, ensuring seamless integration of new classes within the expanded space. Additionally, we employ a self-supervised contrastive loss to improve the separation between previous classes. We validate our framework through experiments on three FSCIL benchmark datasets: CIFAR100, miniImageNet, and CUB200. The results demonstrate that our Feature Augmentation driven Contrastive Learning framework significantly outperforms other approaches, achieving state-of-the-art performance."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Revisit to Rate-distortion Problems via Optimal Weak Transport Theory", "authors": "Jiayang Zou, Luyao Fan, Jiayang Gao, Jia Wang", "subjects": "Subjects:\nInformation Theory (cs.IT)", "abstract": "This paper revisits the rate-distortion theory from the perspective of optimal weak transport theory, as recently introduced by Gozlan et al. While the conditions for optimality and the existence of solutions are well-understood in the case of discrete alphabets, the extension to abstract alphabets requires more intricate analysis. Within the framework of weak transport problems, we derive a parametric representation of the rate-distortion function, thereby connecting the rate-distortion function with the Schr\u00f6dinger bridge problem, and establish necessary conditions for its optimality. As a byproduct of our analysis, we reproduce K. Rose's conclusions regarding the achievability of Shannon lower bound concisely, without reliance on variational calculus."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Identification of Traditional Medicinal Plant Leaves Using an effective Deep Learning model and Self-Curated Dataset", "authors": "Deepjyoti Chetia, Sanjib Kr Kalita, Prof Partha Pratim Baruah, Debasish Dutta, Tanaz Akhter", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Medicinal plants have been a key component in producing traditional and modern medicines, especially in the field of Ayurveda, an ancient Indian medical system. Producing these medicines and collecting and extracting the right plant is a crucial step due to the visually similar nature of some plants. The extraction of these plants from nonmedicinal plants requires human expert intervention. To solve the issue of accurate plant identification and reduce the need for a human expert in the collection process; employing computer vision methods will be efficient and beneficial. In this paper, we have proposed a model that solves such issues. The proposed model is a custom convolutional neural network (CNN) architecture with 6 convolution layers, max-pooling layers, and dense layers. The model was tested on three different datasets named Indian Medicinal Leaves Image Dataset,MED117 Medicinal Plant Leaf Dataset, and the self-curated dataset by the authors. The proposed model achieved respective accuracies of 99.5%, 98.4%, and 99.7% using various optimizers including Adam, RMSprop, and SGD with momentum."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          PICE: A Semantic-Driven Progressive Inference System for LLM Serving in Cloud-Edge Networks", "authors": "Huiyou Zhan, Xuan Zhang, Haisheng Tan, Han Tian, Dongping Yong, Junyang Zhang, Xiang-Yang Li", "subjects": "Subjects:\nDistributed, Parallel, and Cluster Computing (cs.DC)", "abstract": "Large language models (LLMs), while driving a new wave of interactive AI applications across numerous domains, suffer from high inference costs and heavy cloud dependency. Motivated by the redundancy phenomenon in linguistics, we propose a progressive inference paradigm over cloud and edge, i.e., firstly generating the sketch of the answer by LLMs at cloud, and then conducting parallel extension to fill in details by small models (SLMs) at edge. Progressive inference offers potential benefits to improve throughput and reduce inference latency while facing key implementation challenges, including decreased response quality from SLMs, a tradeoff between the brevity and comprehensiveness of sketches, as well as increased latency caused by network transmission and edge inference. In this work, we propose and implement PICE, an LLM serving system with semantic-level cloud-edge collaboration, enhancing inference throughput and quality through dynamic inference task scheduling, ensemble learning, and parallel edge inference. Extensive testbed experiments illustrate that our approach achieves $1.5-2\\times$ throughput enhancement and up to 43% latency reduction, while also potentially enhancing the quality compared to SOTA systems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Aligning Instruction Tuning with Pre-training", "authors": "Yiming Liang, Tianyu Zheng, Xinrun Du, Ge Zhang, Xingwei Qu, Xiang Yue, Chujie Zheng, Jiaheng Liu, Lei Ma, Wenhu Chen, Guoyin Wang, Zhaoxiang Zhang, Wenhao Huang, Jiajun Zhang", "subjects": "Subjects:\nArtificial Intelligence (cs.AI)", "abstract": "Instruction tuning enhances large language models (LLMs) to follow human instructions across diverse tasks, relying on high-quality datasets to guide behavior. However, these datasets, whether manually curated or synthetically generated, are often narrowly focused and misaligned with the broad distributions captured during pre-training, limiting LLM generalization and effective use of pre-trained knowledge. We propose *Aligning Instruction Tuning with Pre-training* (AITP), a method that bridges this gap by identifying coverage shortfalls in instruction-tuning datasets and rewriting underrepresented pre-training data into high-quality instruction-response pairs. This approach enriches dataset diversity while preserving task-specific objectives. Evaluations on three fully open LLMs across eight benchmarks demonstrate consistent performance improvements with AITP. Ablations highlight the benefits of adaptive data selection, controlled rewriting, and balanced integration, emphasizing the importance of aligning instruction tuning with pre-training distributions to unlock the full potential of LLMs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Image Segmentation with transformers: An Overview, Challenges and Future", "authors": "Deepjyoti Chetia, Debasish Dutta, Sanjib Kr Kalita", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Image segmentation, a key task in computer vision, has traditionally relied on convolutional neural networks (CNNs), yet these models struggle with capturing complex spatial dependencies, objects with varying scales, need for manually crafted architecture components and contextual information. This paper explores the shortcomings of CNN-based models and the shift towards transformer architectures -to overcome those limitations. This work reviews state-of-the-art transformer-based segmentation models, addressing segmentation-specific challenges and their solutions. The paper discusses current challenges in transformer-based segmentation and outlines promising future trends, such as lightweight architectures and enhanced data efficiency. This survey serves as a guide for understanding the impact of transformers in advancing segmentation capabilities and overcoming the limitations of traditional models."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          First Experiments with Neural cvc5", "authors": "Jelle Piepenbrock, Mikol\u00e1\u0161 Janota, Jan Jakub\u016fv", "subjects": "Subjects:\nLogic in Computer Science (cs.LO)", "abstract": "he cvc5 solver is today one of the strongest systems for solving first order problems with theories but also without them. In this work we equip its enumeration-based instantiation with a neural network that guides the choice of the quantified formulas and their instances. For that we develop a relatively fast graph neural network that repeatedly scores all available instantiation options with respect to the available formulas. The network runs directly on a CPU without the need for any special hardware. We train the neural guidance on a large set of proofs generated by the e-matching instantiation strategy and evaluate its performance on a set of previously unseen problems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Testing a cellular automata construction method to obtain 9-variable cryptographic Boolean functions", "authors": "Thomas Pr\u00e9vost (I3S), Bruno Martin (I3S)", "subjects": "Subjects:\nCryptography and Security (cs.CR)", "abstract": "We propose a method for constructing 9-variable cryptographic Boolean functions from the iterates of 5-variable cellular automata rules. We then analyze, for important cryptographic properties of 5-variable cellular automata rules, how they are preserved after extension to 9-variable Boolean functions. For each cryptographic property, we analyze the proportion of 5-variable cellular automata rules that preserve it for each of the 48 affine equivalence classes."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Non-linear Partition of Unity method", "authors": "Jos\u00e9 Manuel Ram\u00f3n, Juan Ruiz-Alvarez, Dionisio F. Y\u00e1\u00f1ez", "subjects": "Subjects:\nNumerical Analysis (math.NA)", "abstract": "This paper introduces the Non-linear Partition of Unity Method, a novel technique integrating Radial Basis Function interpolation and Weighted Essentially Non-Oscillatory algorithms. It addresses challenges in high-accuracy approximations, particularly near discontinuities, by adapting weights dynamically. The method is rooted in the Partition of Unity framework, enabling efficient decomposition of large datasets into subproblems while maintaining accuracy. Smoothness indicators and compactly supported functions ensure precision in regions with discontinuities. Error bounds are calculated and validate its effectiveness, showing improved interpolation in discontinuous and smooth regions. Some numerical experiments are performed to check the theoretical results."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Adaptive Contextual Caching for Mobile Edge Large Language Model Service", "authors": "Guangyuan Liu, Yinqiu Liu, Jiacheng Wang, Hongyang Du, Dusit Niyato, Jiawen Kang, Zehui Xiong", "subjects": "Subjects:\nNetworking and Internet Architecture (cs.NI)", "abstract": "Mobile edge Large Language Model (LLM) deployments face inherent constraints, such as limited computational resources and network bandwidth. Although Retrieval-Augmented Generation (RAG) mitigates some challenges by integrating external knowledge bases, inefficient cache management can still result in high retrieval latency and frequent cache updates. To address these issues, we propose an Adaptive Contextual Caching (ACC) framework that anticipates user needs by proactively caching semantically relevant data for mobile-edge LLMs. ACC utilizes a deep reinforcement learning (DRL) module to refine cache replacement policies, balancing user context, document similarity, and the overhead associated with cache misses. Experimental results demonstrate that ACC increases cache hit rates to over 80\\% after only 11 training episodes, outperforming FIFO, LRU, and semantic-only caching while reducing retrieval latency by up to 40\\%. In particular, ACC also reduces local caching overhead (i.e., the cost of updating the cache when a miss occurs) by as much as 55\\%, enabling scalable, low-latency LLM services in resource-constrained edge environments."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Evaluating LLM Abilities to Understand Tabular Electronic Health Records: A Comprehensive Study of Patient Data Extraction and Retrieval", "authors": "Jesus Lovon (IRIT-IRIS), Martin Mouysset (IRIT-IRIS), Jo Oleiwan (IRIT-IRIS), Jose G. Moreno (IRIT-IRIS), Christine Damase-Michel, Lynda Tamine (IRIT-IRIS)", "subjects": "Subjects:\nComputation and Language (cs.CL); Information Retrieval (cs.IR)", "abstract": "Electronic Health Record (EHR) tables pose unique challenges among which is the presence of hidden contextual dependencies between medical features with a high level of data dimensionality and sparsity. This study presents the first investigation into the abilities of LLMs to comprehend EHRs for patient data extraction and retrieval. We conduct extensive experiments using the MIMICSQL dataset to explore the impact of the prompt structure, instruction, context, and demonstration, of two backbone LLMs, Llama2 and Meditron, based on task performance. Through quantitative and qualitative analyses, our findings show that optimal feature selection and serialization methods can enhance task performance by up to 26.79% compared to naive approaches. Similarly, in-context learning setups with relevant example selection improve data extraction performance by 5.95%. Based on our study findings, we propose guidelines that we believe would help the design of LLM-based models to support health search."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Contract-Inspired Contest Theory for Controllable Image Generation in Mobile Edge Metaverse", "authors": "Guangyuan Liu, Hongyang Du, Jiacheng Wang, Dusit Niyato, Dong In Kim", "subjects": "Subjects:\nNetworking and Internet Architecture (cs.NI)", "abstract": "The rapid advancement of immersive technologies has propelled the development of the Metaverse, where the convergence of virtual and physical realities necessitates the generation of high-quality, photorealistic images to enhance user experience. However, generating these images, especially through Generative Diffusion Models (GDMs), in mobile edge computing environments presents significant challenges due to the limited computing resources of edge devices and the dynamic nature of wireless networks. This paper proposes a novel framework that integrates contract-inspired contest theory, Deep Reinforcement Learning (DRL), and GDMs to optimize image generation in these resource-constrained environments. The framework addresses the critical challenges of resource allocation and semantic data transmission quality by incentivizing edge devices to efficiently transmit high-quality semantic data, which is essential for creating realistic and immersive images. The use of contest and contract theory ensures that edge devices are motivated to allocate resources effectively, while DRL dynamically adjusts to network conditions, optimizing the overall image generation process. Experimental results demonstrate that the proposed approach not only improves the quality of generated images but also achieves superior convergence speed and stability compared to traditional methods. This makes the framework particularly effective for optimizing complex resource allocation tasks in mobile edge Metaverse applications, offering enhanced performance and efficiency in creating immersive virtual environments."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SVIA: A Street View Image Anonymization Framework for Self-Driving Applications", "authors": "Dongyu Liu, Xuhong Wang, Cen Chen, Yanhao Wang, Shengyue Yao, Yilun Lin", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "In recent years, there has been an increasing interest in image anonymization, particularly focusing on the de-identification of faces and individuals. However, for self-driving applications, merely de-identifying faces and individuals might not provide sufficient privacy protection since street views like vehicles and buildings can still disclose locations, trajectories, and other sensitive information. Therefore, it remains crucial to extend anonymization techniques to street view images to fully preserve the privacy of users, pedestrians, and vehicles. In this paper, we propose a Street View Image Anonymization (SVIA) framework for self-driving applications. The SVIA framework consists of three integral components: a semantic segmenter to segment an input image into functional regions, an inpainter to generate alternatives to privacy-sensitive regions, and a harmonizer to seamlessly stitch modified regions to guarantee visual coherence. Compared to existing methods, SVIA achieves a much better trade-off between image generation quality and privacy protection, as evidenced by experimental results for five common metrics on two widely used public datasets."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          ELM-DeepONets: Backpropagation-Free Training of Deep Operator Networks via Extreme Learning Machines", "authors": "Hwijae Son", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI); Numerical Analysis (math.NA)", "abstract": "Deep Operator Networks (DeepONets) are among the most prominent frameworks for operator learning, grounded in the universal approximation theorem for operators. However, training DeepONets typically requires significant computational resources. To address this limitation, we propose ELM-DeepONets, an Extreme Learning Machine (ELM) framework for DeepONets that leverages the backpropagation-free nature of ELM. By reformulating DeepONet training as a least-squares problem for newly introduced parameters, the ELM-DeepONet approach significantly reduces training complexity. Validation on benchmark problems, including nonlinear ODEs and PDEs, demonstrates that the proposed method not only achieves superior accuracy but also drastically reduces computational costs. This work offers a scalable and efficient alternative for operator learning in scientific computing."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Collision Risk Analysis for LEO Satellites with Confidential Orbital Data", "authors": "Svenja Lage, Felicitas H\u00f6rmann, Felix Hanke, Michael Karl", "subjects": "Subjects:\nCryptography and Security (cs.CR)", "abstract": "The growing number of satellites in low Earth orbit (LEO) has increased concerns about the risk of satellite collisions, which can ultimately result in the irretrievable loss of satellites and a growing amount of space debris. To mitigate this risk, accurate collision risk analysis is essential. However, this requires access to sensitive orbital data, which satellite operators are often unwilling to share due to privacy concerns. This contribution proposes a solution based on fully homomorphic encryption (FHE) and thus enables secure and private collision risk analysis. In contrast to existing methods, this approach ensures that collision risk analysis can be performed on sensitive orbital data without revealing it to other parties. To display the challenges and opportunities of FHE in this context, an implementation of the CKKS scheme is adapted and analyzed for its capacity to satisfy the theoretical requirements of precision and run time."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Boosting Performance of Iterative Applications on GPUs: Kernel Batching with CUDA Graphs", "authors": "Jonah Ekelund, Stefano Markidis, Ivy Peng", "subjects": "Subjects:\nDistributed, Parallel, and Cluster Computing (cs.DC)", "abstract": "Graphics Processing Units (GPUs) have become the standard in accelerating scientific applications on heterogeneous systems. However, as GPUs are getting faster, one potential performance bottleneck with GPU-accelerated applications is the overhead from launching several fine-grained kernels. CUDA Graph addresses these performance challenges by enabling a graph-based execution model that captures operations as nodes and dependence as edges in a static graph. Thereby consolidating several kernel launches into one graph launch. We propose a performance optimization strategy for iteratively launched kernels. By grouping kernel launches into iteration batches and then unrolling these batches into a CUDA Graph, iterative applications can benefit from CUDA Graph for performance boosting. We analyze the performance gain and overhead from this approach by designing a skeleton application. The skeleton application also serves as a generalized example of converting an iterative solver to CUDA Graph, and for deriving a performance model. Using the skeleton application, we show that when unrolling iteration batches for a given platform, there is an optimal size of the iteration batch, which is independent of workload, balancing the extra overhead from graph creation with the performance gain of the graph execution. Depending on workload, we show that the optimal iteration batch size gives more than 1.4x speed-up in the skeleton application. Furthermore, we show that similar speed-up can be gained in Hotspot and Hotspot3D from the Rodinia benchmark suite and a Finite-Difference Time-Domain (FDTD) Maxwell solver."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Fast Searching of Extreme Operating Conditions for Relay Protection Setting Calculation Based on Graph Neural Network and Reinforcement Learning", "authors": "Yan Li, Jingyu Wang, Jiankang Zhang, Huaiqiang Li, Longfei Ren, Yinhong Li, Dongyuan Shi, Xianzhong Duan", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "Searching for the Extreme Operating Conditions (EOCs) is one of the core problems of power system relay protection setting calculation. The current methods based on brute-force search, heuristic algorithms, and mathematical programming can hardly meet the requirements of today's power systems in terms of computation speed due to the drastic changes in operating conditions induced by renewables and power electronics. This paper proposes an EOC fast search method, named Graph Dueling Double Deep Q Network (Graph D3QN), which combines graph neural network and deep reinforcement learning to address this challenge. First, the EOC search problem is modeled as a Markov decision process, where the information of the underlying power system is extracted using graph neural networks, so that the EOC of the system can be found via deep reinforcement learning. Then, a two-stage Guided Learning and Free Exploration (GLFE) training framework is constructed to accelerate the convergence speed of reinforcement learning. Finally, the proposed Graph D3QN method is validated through case studies of searching maximum fault current for relay protection setting calculation on the IEEE 39-bus and 118-bus systems. The experimental results demonstrate that Graph D3QN can reduce the computation time by 10 to 1000 times while guaranteeing the accuracy of the selected EOCs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Joint Antenna Selection and Beamforming Design for Active RIS-aided ISAC Systems", "authors": "Wei Ma, Peichang Zhang, Junjie Ye, Rouyang Guan, Xiao-Peng Li, Lei Huang", "subjects": "Subjects:\nInformation Theory (cs.IT); Signal Processing (eess.SP)", "abstract": "Active reconfigurable intelligent surface (A-RIS) aided integrated sensing and communications (ISAC) system has been considered as a promising paradigm to improve spectrum efficiency. However, massive energy-hungry radio frequency (RF) chains hinder its large-scale deployment. To address this issue, an A-RIS-aided ISAC system with antenna selection (AS) is proposed in this work, where a target is sensed while multiple communication users are served with specifically selected antennas. Specifically, a cuckoo search-based scheme is first utilized to select the antennas associated with high-gain channels. Subsequently, with the properly selected antennas, the weighted sum-rate (WSR) of the system is optimized under the condition of radar probing power level, power budget for the A-RIS and transmitter. To solve the highly non-convex optimization problem, we develop an efficient algorithm based on weighted minimum mean square error (WMMSE) and fractional programming (FP). Simulation results show that the proposed AS scheme and the algorithm are effective, which reduce the number of RF chains without significant performance degradation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Towards a Framework for Enterprise Architecture in Mobile Government: A Case Study", "authors": "Son Pham, Duong Dang, Son Hoang, Byeongnam Yoon", "subjects": "Subjects:\nComputers and Society (cs.CY)", "abstract": "Mobile government (m-government) represents a distinct paradigm shift from electronic government (e-government), offering a new avenue for governments worldwide to deliver services and applications to their customers. The m-government model deviates from e-government in terms of information technology (IT) infrastructure, security, and application management and implementation. Enterprise architecture (EA) has been developed and utilized globally to enhance efficiency and information and communication technology (ICT) utilization in the public sector through e-government. However, the application of EA within the context of m-government, particularly in developing countries, has largely been overlooked by scholars. This study aims to address this gap. This study seeks to develop an EA specifically tailored for m-government in a developmental context. Our contribution to the literature is the illustration of a proposed EA framework for m-government. The practical implementation of this study is to identify critical considerations when designing and adopting m-government to avoid redundant investments during the integration of infrastructure and applications from e-government to m-government."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Artificial Intelligence, Ambient Backscatter Communication and Non-Terrestrial Networks: A 6G Commixture", "authors": "Muhammad Ali Jamshed, Bushra Haq, Muhammad Ahmed Mohsin, Ali Nauman, Halim Yanikomeroglu", "subjects": "Subjects:\nNetworking and Internet Architecture (cs.NI); Signal Processing (eess.SP)", "abstract": "The advent of Non-Terrestrial Networks (NTN) represents a compelling response to the International Mobile Telecommunications 2030 (IMT-2030) framework, enabling the delivery of advanced, seamless connectivity that supports reliable, sustainable, and resilient communication systems. Nevertheless, the integration of NTN with Terrestrial Networks (TN) necessitates considerable alterations to the existing cellular infrastructure in order to address the challenges intrinsic to NTN implementation. Additionally, Ambient Backscatter Communication (AmBC), which utilizes ambient Radio Frequency (RF) signals to transmit data to the intended recipient by altering and reflecting these signals, exhibits considerable potential for the effective integration of NTN and TN. Furthermore, AmBC is constrained by its limitations regarding power, interference, and other related factors. In contrast, the application of Artificial Intelligence (AI) within wireless networks demonstrates significant potential for predictive analytics through the use of extensive datasets. AI techniques enable the real-time optimization of network parameters, mitigating interference and power limitations in AmBC. These predictive models also enhance the adaptive integration of NTN and TN, driving significant improvements in network reliability and Energy Efficiency (EE). In this paper, we present a comprehensive examination of how the commixture of AI, AmBC, and NTN can facilitate the integration of NTN and TN. We also provide a thorough analysis indicating a marked enhancement in EE predicated on this triadic relationship."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          NEBULA: A National Scale Dataset for Neighbourhood-Level Urban Building Energy Modelling for England and Wales", "authors": "Grace Colverd, Ronita Bardhan, Jonathan Cullen", "subjects": "Subjects:\nComputers and Society (cs.CY)", "abstract": "Buildings are significant contributors to global greenhouse gas emissions, accounting for 26% of global energy sector emissions in 2022. Meeting net zero goals requires a rapid reduction in building emissions, both directly from the buildings and indirectly from the production of electricity and heat used in buildings. National energy planning for net zero demands both detailed and comprehensive building energy consumption data. However, geo-located building-level energy data is rarely available in Europe, with analysis typically relying on anonymised, simulated or low-resolution data. To address this problem, we introduce a dataset of Neighbourhood Energy, Buildings, and Urban Landscapes (NEBULA) for modelling domestic energy consumption for small neighbourhoods (5-150 households). NEBULA integrates data on building characteristics, climate, urbanisation, environment, and socio-demographics and contains 609,964 samples across England and Wales."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          On the distribution of the statistical sum related to BSC", "authors": "M. V. Burnashev", "subjects": "Subjects:\nInformation Theory (cs.IT); Probability (math.PR)", "abstract": "The distribution function of the sum of i.i.d. random variables of the special form is considered. Such sum describes messages posterior probabilities for random coding in binary symmetric channel. Close non-asymptotic lower and upper bounds for that function are derived."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          mGeNTE: A Multilingual Resource for Gender-Neutral Language and Translation", "authors": "Beatrice Savoldi, Eleonora Cupin, Manjinder Thind, Anne Lauscher, Luisa Bentivogli", "subjects": "Subjects:\nComputation and Language (cs.CL)", "abstract": "Gender-neutral language reflects societal and linguistic shifts towards greater inclusivity by avoiding the implication that one gender is the norm over others. This is particularly relevant for grammatical gender languages, which heavily encode the gender of terms for human referents and over-relies on masculine forms, even when gender is unspecified or irrelevant. Language technologies are known to mirror these inequalities, being affected by a male bias and perpetuating stereotypical associations when translating into languages with extensive gendered morphology. In such cases, gender-neutral language can help avoid undue binary assumptions. However, despite its importance for creating fairer multi- and cross-lingual technologies, inclusive language research remains scarce and insufficiently supported in current resources. To address this gap, we present the multilingual mGeNTe dataset. Derived from the bilingual GeNTE (Piergentili et al., 2023), mGeNTE extends the original corpus to include the English-Italian/German/Spanish language pairs. Since each language pair is English-aligned with gendered and neutral sentences in the target languages, mGeNTE enables research in both automatic Gender-Neutral Translation (GNT) and language modelling for three grammatical gender languages."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          MoE$^2$: Optimizing Collaborative Inference for Edge Large Language Models", "authors": "Lyudong Jin, Yanning Zhang, Yanhan Li, Shurong Wang, Howard H. Yang, Jian Wu, Meng Zhang", "subjects": "Subjects:\nNetworking and Internet Architecture (cs.NI); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities across a wide range of natural language processing tasks. Exploiting the heterogeneous capabilities of edge LLMs is crucial for diverse emerging applications, as it enables greater cost-effectiveness and reduced latency. In this work, we introduce \\textit{Mixture-of-Edge-Experts (MoE$^2$)}, a novel collaborative inference framework for edge LLMs. We formulate the joint gating and expert selection problem to optimize inference performance under energy and latency constraints. Unlike conventional MoE problems, LLM expert selection is significantly more challenging due to the combinatorial nature and the heterogeneity of edge LLMs across various attributes. To this end, we propose a two-level expert selection mechanism through which we uncover an optimality-preserving property of gating parameters across expert selections. This property enables the decomposition of the training and selection processes, significantly reducing complexity. Furthermore, we leverage the objective's monotonicity and design a discrete monotonic optimization algorithm for optimal expert selection. We implement edge servers with NVIDIA Jetson AGX Orins and NVIDIA RTX 4090 GPUs, and perform extensive experiments. Our results validate that performance improvements of various LLM models and show that our MoE$^2$ method can achieve optimal trade-offs among different delay and energy budgets, and outperforms baselines under various system resource constraints."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Towards Robust and Realistic Human Pose Estimation via WiFi Signals", "authors": "Yang Chen, Jingcai Guo, Song Guo, Jingren Zhou, Dacheng Tao", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Robust WiFi-based human pose estimation is a challenging task that bridges discrete and subtle WiFi signals to human skeletons. This paper revisits this problem and reveals two critical yet overlooked issues: 1) cross-domain gap, i.e., due to significant variations between source-target domain pose distributions; and 2) structural fidelity gap, i.e., predicted skeletal poses manifest distorted topology, usually with misplaced joints and disproportionate bone lengths. This paper fills these gaps by reformulating the task into a novel two-phase framework dubbed DT-Pose: Domain-consistent representation learning and Topology-constrained Pose decoding. Concretely, we first propose a temporal-consistent contrastive learning strategy with uniformity regularization, coupled with self-supervised masking-reconstruction operations, to enable robust learning of domain-consistent and motion-discriminative WiFi-specific representations. Beyond this, we introduce a simple yet effective pose decoder with task prompts, which integrates Graph Convolution Network (GCN) and Transformer layers to constrain the topology structure of the generated skeleton by exploring the adjacent-overarching relationships among human joints. Extensive experiments conducted on various benchmark datasets highlight the superior performance of our method in tackling these fundamental challenges in both 2D/3D human pose estimation tasks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          FASP: Fast and Accurate Structured Pruning of Large Language Models", "authors": "Hanyu Hu, Pengxiang Zhao, Ping Li, Yi Zheng, Zhefeng Wang, Xiaoming Yuan", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "The rapid increase in the size of large language models (LLMs) has significantly escalated their computational and memory demands, posing challenges for efficient deployment, especially on resource-constrained devices. Structured pruning has emerged as an effective model compression method that can reduce these demands while preserving performance. In this paper, we introduce FASP (Fast and Accurate Structured Pruning), a novel structured pruning framework for LLMs that emphasizes both speed and accuracy. FASP employs a distinctive pruning structure that interlinks sequential layers, allowing for the removal of columns in one layer while simultaneously eliminating corresponding rows in the preceding layer without incurring additional performance loss. The pruning metric, inspired by Wanda, is computationally efficient and effectively selects components to prune. Additionally, we propose a restoration mechanism that enhances model fidelity by adjusting the remaining weights post-pruning. We evaluate FASP on the OPT and LLaMA model families, demonstrating superior performance in terms of perplexity and accuracy on downstream tasks compared to state-of-the-art methods. Our approach achieves significant speed-ups, pruning models such as OPT-125M in 17 seconds and LLaMA-30B in 15 minutes on a single NVIDIA RTX 4090 GPU, making it a highly practical solution for optimizing LLMs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Verified and Optimized Implementation of Orthologic Proof Search", "authors": "Simon Guilloud, Cl\u00e9ment Pit-Claudel", "subjects": "Subjects:\nLogic in Computer Science (cs.LO)", "abstract": "We report on the development of an optimized and verified decision procedure for orthologic equalities and inequalities. We start by formalizing, in the Coq proof assistant, a proof system in sequent-calculus style for orthologic. We then prove its soundness and completeness with respect to the algebraic variety of ortholattices, and we formalize a cut-elimination theorem (in doing so, we discover and fix a missing case in a previously published proof). We then implement and verify a complete decision procedure for orthologic. To obtain an optimal quadratic runtime, we optimize the implementation by memoizing its results and simulating reference equality testing. We leverage the resulting correctness theorem to implement a reflective Coq tactic."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Dynamic Neural Style Transfer for Artistic Image Generation using VGG19", "authors": "Kapil Kashyap, Mehak Garg, Sean Fargose, Sindhu Nair", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Image and Video Processing (eess.IV)", "abstract": "Throughout history, humans have created remark- able works of art, but artificial intelligence has only recently started to make strides in generating visually compelling art. Breakthroughs in the past few years have focused on using convolutional neural networks (CNNs) to separate and manipulate the content and style of images, applying texture synthesis techniques. Nevertheless, a number of current techniques continue to encounter obstacles, including lengthy processing times, restricted choices of style images, and the inability to modify the weight ratio of styles. We proposed a neural style transfer system that can add various artistic styles to a desired image to address these constraints allowing flexible adjustments to style weight ratios and reducing processing time. The system uses the VGG19 model for feature extraction, ensuring high-quality, flexible stylization without compromising content integrity."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Vision-Language Models Do Not Understand Negation", "authors": "Kumail Alhamoud, Shaden Alshammari, Yonglong Tian, Guohao Li, Philip Torr, Yoon Kim, Marzyeh Ghassemi", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL)", "abstract": "Many practical vision-language applications require models that understand negation, e.g., when using natural language to retrieve images which contain certain objects but not others. Despite advancements in vision-language models (VLMs) through large-scale training, their ability to comprehend negation remains underexplored. This study addresses the question: how well do current VLMs understand negation? We introduce NegBench, a new benchmark designed to evaluate negation understanding across 18 task variations and 79k examples spanning image, video, and medical datasets. The benchmark consists of two core tasks designed to evaluate negation understanding in diverse multimodal settings: Retrieval with Negation and Multiple Choice Questions with Negated Captions. Our evaluation reveals that modern VLMs struggle significantly with negation, often performing at chance level. To address these shortcomings, we explore a data-centric approach wherein we finetune CLIP models on large-scale synthetic datasets containing millions of negated captions. We show that this approach can result in a 10% increase in recall on negated queries and a 40% boost in accuracy on multiple-choice questions with negated captions."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          AutoCBT: An Autonomous Multi-agent Framework for Cognitive Behavioral Therapy in Psychological Counseling", "authors": "Ancheng Xu, Di Yang, Renhao Li, Jingwei Zhu, Minghuan Tan, Min Yang, Wanxin Qiu, Mingchen Ma, Haihong Wu, Bingyu Li, Feng Sha, Chengming Li, Xiping Hu, Qiang Qu, Derek F.Wong, Ruifeng Xu", "subjects": "Subjects:\nComputation and Language (cs.CL)", "abstract": "Traditional in-person psychological counseling remains primarily niche, often chosen by individuals with psychological issues, while online automated counseling offers a potential solution for those hesitant to seek help due to feelings of shame. Cognitive Behavioral Therapy (CBT) is an essential and widely used approach in psychological counseling. The advent of large language models (LLMs) and agent technology enables automatic CBT diagnosis and treatment. However, current LLM-based CBT systems use agents with a fixed structure, limiting their self-optimization capabilities, or providing hollow, unhelpful suggestions due to redundant response patterns. In this work, we utilize Quora-like and YiXinLi single-round consultation models to build a general agent framework that generates high-quality responses for single-turn psychological consultation scenarios. We use a bilingual dataset to evaluate the quality of single-response consultations generated by each framework. Then, we incorporate dynamic routing and supervisory mechanisms inspired by real psychological counseling to construct a CBT-oriented autonomous multi-agent framework, demonstrating its general applicability. Experimental results indicate that AutoCBT can provide higher-quality automated psychological counseling services."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          AugRefer: Advancing 3D Visual Grounding via Cross-Modal Augmentation and Spatial Relation-based Referring", "authors": "Xinyi Wang, Na Zhao, Zhiyuan Han, Dan Guo, Xun Yang", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "3D visual grounding (3DVG), which aims to correlate a natural language description with the target object within a 3D scene, is a significant yet challenging task. Despite recent advancements in this domain, existing approaches commonly encounter a shortage: a limited amount and diversity of text3D pairs available for training. Moreover, they fall short in effectively leveraging different contextual clues (e.g., rich spatial relations within the 3D visual space) for grounding. To address these limitations, we propose AugRefer, a novel approach for advancing 3D visual grounding. AugRefer introduces cross-modal augmentation designed to extensively generate diverse text-3D pairs by placing objects into 3D scenes and creating accurate and semantically rich descriptions using foundation models. Notably, the resulting pairs can be utilized by any existing 3DVG methods for enriching their training data. Additionally, AugRefer presents a language-spatial adaptive decoder that effectively adapts the potential referring objects based on the language description and various 3D spatial relations. Extensive experiments on three benchmark datasets clearly validate the effectiveness of AugRefer."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          ADAGE: A generic two-layer framework for adaptive agent based modelling", "authors": "Benjamin Patrick Evans, Sihan Zeng, Sumitra Ganesh, Leo Ardon", "subjects": "Subjects:\nMultiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); General Economics (econ.GN); Computational Finance (q-fin.CP)", "abstract": "Agent-based models (ABMs) are valuable for modelling complex, potentially out-of-equilibria scenarios. However, ABMs have long suffered from the Lucas critique, stating that agent behaviour should adapt to environmental changes. Furthermore, the environment itself often adapts to these behavioural changes, creating a complex bi-level adaptation problem. Recent progress integrating multi-agent reinforcement learning into ABMs introduces adaptive agent behaviour, beginning to address the first part of this critique, however, the approaches are still relatively ad hoc, lacking a general formulation, and furthermore, do not tackle the second aspect of simultaneously adapting environmental level characteristics in addition to the agent behaviours. In this work, we develop a generic two-layer framework for ADaptive AGEnt based modelling (ADAGE) for addressing these problems. This framework formalises the bi-level problem as a Stackelberg game with conditional behavioural policies, providing a consolidated framework for adaptive agent-based modelling based on solving a coupled set of non-linear equations. We demonstrate how this generic approach encapsulates several common (previously viewed as distinct) ABM tasks, such as policy design, calibration, scenario generation, and robust behavioural learning under one unified framework. We provide example simulations on multiple complex economic and financial environments, showing the strength of the novel framework under these canonical settings, addressing long-standing critiques of traditional ABMs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          HpC: A Calculus for Hybrid and Mobile Systems -- Full Version", "authors": "Xiong Xu, Jean-Pierre Talpin, Shuling Wang, Hao Wu, Bohua Zhan, Xinxin Liu, Naijun Zhan", "subjects": "Subjects:\nProgramming Languages (cs.PL); Logic in Computer Science (cs.LO); Networking and Internet Architecture (cs.NI); Systems and Control (eess.SY)", "abstract": "Networked cybernetic and physical systems of the Internet of Things (IoT) immerse civilian and industrial infrastructures into an interconnected and dynamic web of hybrid and mobile devices. The key feature of such systems is the hybrid and tight coupling of mobile and pervasive discrete communications in a continuously evolving environment (discrete computations with predominant continuous dynamics). In the aim of ensuring the correctness and reliability of such heterogeneous infrastructures, we introduce the hybrid {\\pi}-calculus (HpC), to formally capture both mobility, pervasiveness and hybridisation in infrastructures where the network topology and its communicating entities evolve continuously in the physical world. The {\\pi}-calculus proposed by Robin Milner et al. is a process calculus that can model mobile communications and computations in a very elegant manner. The HpC we propose is a conservative extension of the classical {\\pi}-calculus, i.e., the extension is ``minimal'', and yet describes mobility, time and physics of systems, while allowing to lift all theoretical results (e.g. bisimulation) to the context of that extension. We showcase the HpC by considering a realistic handover protocol among mobile devices."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Survey on Responsible LLMs: Inherent Risk, Malicious Use, and Mitigation Strategy", "authors": "Huandong Wang, Wenjie Fu, Yingzhou Tang, Zhilong Chen, Yuxi Huang, Jinghua Piao, Chen Gao, Fengli Xu, Tao Jiang, Yong Li", "subjects": "Subjects:\nArtificial Intelligence (cs.AI); Computation and Language (cs.CL); Cryptography and Security (cs.CR); Computers and Society (cs.CY)", "abstract": "While large language models (LLMs) present significant potential for supporting numerous real-world applica- tions and delivering positive social impacts, they still face significant challenges in terms of the inherent risk of privacy leakage, hallucinated outputs, and value misalignment, and can be maliciously used for generating toxic content and unethical purposes after been jailbroken. Therefore, in this survey, we present a comprehensive review of recent advancements aimed at mitigating these issues, organized across the four phases of LLM development and usage: data collecting and pre-training, fine-tuning and alignment, prompting and reasoning, and post-processing and auditing. We elaborate on the recent advances for enhancing the performance of LLMs in terms of privacy protection, hallucination reduction, value alignment, toxicity elimination, and jailbreak defenses. In contrast to previous surveys that focus on a single dimension of responsible LLMs, this survey presents a unified framework that encompasses these diverse dimensions, providing a comprehensive view of enhancing LLMs to better serve real-world applications."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          CaPa: Carve-n-Paint Synthesis for Efficient 4K Textured Mesh Generation", "authors": "Hwan Heo, Jangyeong Kim, Seongyeong Lee, Jeong A Wi, Junyoung Choi, Sangjun Ahn", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR)", "abstract": "The synthesis of high-quality 3D assets from textual or visual inputs has become a central objective in modern generative modeling. Despite the proliferation of 3D generation algorithms, they frequently grapple with challenges such as multi-view inconsistency, slow generation times, low fidelity, and surface reconstruction problems. While some studies have addressed some of these issues, a comprehensive solution remains elusive. In this paper, we introduce \\textbf{CaPa}, a carve-and-paint framework that generates high-fidelity 3D assets efficiently. CaPa employs a two-stage process, decoupling geometry generation from texture synthesis. Initially, a 3D latent diffusion model generates geometry guided by multi-view inputs, ensuring structural consistency across perspectives. Subsequently, leveraging a novel, model-agnostic Spatially Decoupled Attention, the framework synthesizes high-resolution textures (up to 4K) for a given geometry. Furthermore, we propose a 3D-aware occlusion inpainting algorithm that fills untextured regions, resulting in cohesive results across the entire model. This pipeline generates high-quality 3D assets in less than 30 seconds, providing ready-to-use outputs for commercial applications. Experimental results demonstrate that CaPa excels in both texture fidelity and geometric stability, establishing a new standard for practical, scalable 3D asset generation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Agile System Development Lifecycle for AI Systems: Decision Architecture", "authors": "Asif Q. Gill", "subjects": "Subjects:\nSoftware Engineering (cs.SE)", "abstract": "Agile system development life cycle (SDLC) focuses on typical functional and non-functional system requirements for developing traditional software systems. However, Artificial Intelligent (AI) systems are different in nature and have distinct attributes such as (1) autonomy, (2) adaptiveness, (3) content generation, (4) decision-making, (5) predictability and (6) recommendation. Agile SDLC needs to be enhanced to support the AI system development and ongoing post-deployment adaptation. The challenge is: how can agile SDLC be enhanced to support AI systems? The scope of this paper is limited to AI system enabled decision automation. Thus, this paper proposes the use of decision science to enhance the agile SDLC to support the AI system development. Decision science is the study of decision-making, which seems useful to identify, analyse and describe decisions and their architecture subject to automation via AI systems. Specifically, this paper discusses the decision architecture in detail within the overall context of agile SDLC for AI systems. The application of the proposed approach is demonstrated with the help of an example scenario of insurance claim processing. This initial work indicated the usability of a decision science to enhancing the agile SDLC for designing and implementing the AI systems for decision-automation. This work provides an initial foundation for further work in this new area of decision architecture and agile SDLC for AI systems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Scaling up self-supervised learning for improved surgical foundation models", "authors": "Tim J.M. Jaspers, Ronald L.P.D. de Jong, Yiping Li, Carolus H.J. Kusters, Franciscus H.A. Bakker, Romy C. van Jaarsveld, Gino M. Kuiper, Richard van Hillegersberg, Jelle P. Ruurda, Willem M. Brinkman, Josien P.W. Pluim, Peter H.N. de With, Marcel Breeuwer, Yasmina Al Khalil, Fons van der Sommen", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Foundation models have revolutionized computer vision by achieving vastly superior performance across diverse tasks through large-scale pretraining on extensive datasets. However, their application in surgical computer vision has been limited. This study addresses this gap by introducing SurgeNetXL, a novel surgical foundation model that sets a new benchmark in surgical computer vision. Trained on the largest reported surgical dataset to date, comprising over 4.7 million video frames, SurgeNetXL achieves consistent top-tier performance across six datasets spanning four surgical procedures and three tasks, including semantic segmentation, phase recognition, and critical view of safety (CVS) classification. Compared with the best-performing surgical foundation models, SurgeNetXL shows mean improvements of 2.4, 9.0, and 12.6 percent for semantic segmentation, phase recognition, and CVS classification, respectively. Additionally, SurgeNetXL outperforms the best-performing ImageNet-based variants by 14.4, 4.0, and 1.6 percent in the respective tasks. In addition to advancing model performance, this study provides key insights into scaling pretraining datasets, extending training durations, and optimizing model architectures specifically for surgical computer vision. These findings pave the way for improved generalizability and robustness in data-scarce scenarios, offering a comprehensive framework for future research in this domain. All models and a subset of the SurgeNetXL dataset, including over 2 million video frames, are publicly available at: this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Effects of Social Contextual Variation Using Partner Avatars on Memory Acquisition and Retention", "authors": "Takato Mizuho, Takuji Narumi, Hideaki Kuzuoka", "subjects": "Subjects:\nHuman-Computer Interaction (cs.HC)", "abstract": "This study investigates how partner avatar design affects learning and memory when an avatar serves as a lecturer. Based on earlier research on the environmental context dependency of memory, we hypothesize that the use of diverse partner avatars results in a slower learning rate but better memory retention than that of a constant partner avatar. Accordingly, participants were tasked with memorizing Tagalog--Japanese word pairs. On the first day of the experiment, they repeatedly learned the pairs over six sessions from a partner avatar in an immersive virtual environment. One week later, on the second day of the experiment, they underwent a recall test in a real environment. We employed a between-participants design to compare the following conditions: the varied avatar condition, in which each repetition used a different avatar, and the constant avatar condition, in which the same avatar was used throughout the experiment. Results showed that, compared to the constant avatar condition, the varied avatar condition resulted in significantly lower recall performance in the repeated learning trials conducted on the first day. However, the avatar conditions showed no significant differences in the final recall test on the second day. We discuss these effects in relation to the social presence of the partner avatar. This study opens up a novel approach to optimizing the effectiveness of instructor avatars in immersive virtual environments."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Solving the unsolvable: Translating case law in Hong Kong", "authors": "King-kui Sin, Xi Xuan, Chunyu Kit, Clara Ho-yan Chan, Honic Ho-kin Ip", "subjects": "Subjects:\nComputation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "abstract": "This paper addresses the challenges translating case law under Hong Kong's bilingual legal system. It highlights the initial success of translating all written statutes into Chinese before the 1997 handover, a task mandated by the Basic Law. The effort involved significant collaboration among legal, linguistic, and translation experts, resulting in a comprehensive and culturally appropriate bilingual legal system. However, translating case law remains a significant challenge due to the sheer volume and continuous growth of judicial decisions. The paper critiques the governments and judiciarys sporadic and uncoordinated efforts to translate case law, contrasting it with the thorough approach previously taken for statute translation. Although the government acknowledges the importance of legal bilingualism, it lacks a sustainable strategy for translating case law. The Judiciarys position that translating all judgments is unnecessary, unrealistic, and not cost-effectiveis analyzed and critiqued for its impact on legal transparency and public trust. A proposed solution involves leveraging machine translation technology through a human-machine interactive translation platform, which undergoes two major transitions. Initially based on a neural model, the platform transitions to using a large language model for improved translation accuracy. Furthermore, it evolves from a single-agent system to a multi-agent system, incorporating Translator, Annotator, and Proofreader agents. This multi-agent approach, supported by a grant, aims to facilitate efficient, high-quality translation of judicial judgments by integrating advanced artificial intelligence and continuous feedback mechanisms, thus better meeting the needs of a bilingual legal system."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Double Visual Defense: Adversarial Pre-training and Instruction Tuning for Improving Vision-Language Model Robustness", "authors": "Zeyu Wang, Cihang Xie, Brian Bartoldson, Bhavya Kailkhura", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "This paper investigates the robustness of vision-language models against adversarial visual perturbations and introduces a novel ``double visual defense\" to enhance this robustness. Unlike previous approaches that resort to lightweight adversarial fine-tuning of a pre-trained CLIP model, we perform large-scale adversarial vision-language pre-training from scratch using web-scale data. We then strengthen the defense by incorporating adversarial visual instruction tuning. The resulting models from each stage, $\\Delta$CLIP and $\\Delta^2$LLaVA, show substantially enhanced zero-shot robustness and set a new state-of-the-art in adversarial defense for vision-language models. For example, the adversarial robustness of $\\Delta$CLIP surpasses that of the previous best models on ImageNet-1k by ~20%. %For example, $\\Delta$CLIP surpasses the previous best models on ImageNet-1k by ~20% in terms of adversarial robustness. Similarly, compared to prior art, $\\Delta^2$LLaVA brings a ~30% robustness improvement to image captioning task and a ~20% robustness improvement to visual question answering task. Furthermore, our models exhibit stronger zero-shot recognition capability, fewer hallucinations, and superior reasoning performance compared to baselines. Our project page is this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Real-Time Generation of Near-Minimum-Energy Trajectories via Constraint-Informed Residual Learning", "authors": "Domenico Dona', Giovanni Franzese, Cosimo Della Santina, Paolo Boscariol, Basilio Lenzo", "subjects": "Subjects:\nRobotics (cs.RO)", "abstract": "Industrial robotics demands significant energy to operate, making energy-reduction methodologies increasingly important. Strategies for planning minimum-energy trajectories typically involve solving nonlinear optimal control problems (OCPs), which rarely cope with real-time requirements. In this paper, we propose a paradigm for generating near minimum-energy trajectories for manipulators by learning from optimal solutions. Our paradigm leverages a residual learning approach, which embeds boundary conditions while focusing on learning only the adjustments needed to steer a standard solution to an optimal one. Compared to a computationally expensive OCP-based planner, our paradigm achieves 87.3% of the performance near the training dataset and 50.8% far from the dataset, while being two to three orders of magnitude faster."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Scaling Graph-Based Dependency Parsing with Arc Vectorization and Attention-Based Refinement", "authors": "Nicolas Floquet, Joseph Le Roux, Nadi Tomeh, Thierry Charnois", "subjects": "Subjects:\nComputation and Language (cs.CL)", "abstract": "We propose a novel architecture for graph-based dependency parsing that explicitly constructs vectors, from which both arcs and labels are scored. Our method addresses key limitations of the standard two-pipeline approach by unifying arc scoring and labeling into a single network, reducing scalability issues caused by the information bottleneck and lack of parameter sharing. Additionally, our architecture overcomes limited arc interactions with transformer layers to efficiently simulate higher-order dependencies. Experiments on PTB and UD show that our model outperforms state-of-the-art parsers in both accuracy and efficiency."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          On the Relation between Optical Aperture and Automotive Object Detection", "authors": "Ofer Bar-Shalom, Tzvi Philipp, Eran Kishon", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "We explore the impact of aperture size and shape on automotive camera systems for deep-learning-based tasks like traffic sign recognition and light state detection. A method is proposed to simulate optical effects using the point spread function (PSF), enhancing realism and reducing the domain gap between synthetic and real-world images. Computer-generated scenes are refined with this technique to model optical distortions and improve simulation accuracy."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          \"A Great Start, But...\": Evaluating LLM-Generated Mind Maps for Information Mapping in Video-Based Design", "authors": "Tianhao He, Karthi Saravanan, Evangelos Niforatos, Gerd Kortuem", "subjects": "Subjects:\nHuman-Computer Interaction (cs.HC)", "abstract": "Extracting concepts and understanding relationships from videos is essential in Video-Based Design (VBD), where videos serve as a primary medium for exploration but require significant effort in managing meta-information. Mind maps, with their ability to visually organize complex data, offer a promising approach for structuring and analysing video content. Recent advancements in Large Language Models (LLMs) provide new opportunities for meta-information processing and visual understanding in VBD, yet their application remains underexplored. This study recruited 28 VBD practitioners to investigate the use of prompt-tuned LLMs for generating mind maps from ethnographic videos. Comparing LLM-generated mind maps with those created by professional designers, we evaluated rated scores, design effectiveness, and user experience across two contexts. Findings reveal that LLMs effectively capture central concepts but struggle with hierarchical organization and contextual grounding. We discuss trust, customization, and workflow integration as key factors to guide future research on LLM-supported information mapping in VBD."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Teaching Wav2Vec2 the Language of the Brain", "authors": "Tobias Fiedler, Leon Hermann, Florian M\u00fcller, Sarel Cohen, Peter Chin, Tobias Friedrich, Eilon Vaadia", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "The decoding of continuously spoken speech from neuronal activity has the potential to become an important clinical solution for paralyzed patients. Deep Learning Brain Computer Interfaces (BCIs) have recently successfully mapped neuronal activity to text contents in subjects who attempted to formulate speech. However, only small BCI datasets are available. In contrast, labeled data and pre-trained models for the closely related task of speech recognition from audio are widely available. One such model is Wav2Vec2 which has been trained in a self-supervised fashion to create meaningful representations of speech audio data. In this study, we show that patterns learned by Wav2Vec2 are transferable to brain data. Specifically, we replace its audio feature extractor with an untrained Brain Feature Extractor (BFE) model. We then execute full fine-tuning with pre-trained weights for Wav2Vec2, training ''from scratch'' without pre-trained weights as well as freezing a pre-trained Wav2Vec2 and training only the BFE each for 45 different BFE architectures. Across these experiments, the best run is from full fine-tuning with pre-trained weights, achieving a Character Error Rate (CER) of 18.54\\%, outperforming the best training from scratch run by 20.46\\% and that of frozen Wav2Vec2 training by 15.92\\% percentage points. These results indicate that knowledge transfer from audio speech recognition to brain decoding is possible and significantly improves brain decoding performance for the same architectures. Related source code is available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Normal-NeRF: Ambiguity-Robust Normal Estimation for Highly Reflective Scenes", "authors": "Ji Shi, Xianghua Ying, Ruohao Guo, Bowei Xing, Wenzhen Yue", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Neural Radiance Fields (NeRF) often struggle with reconstructing and rendering highly reflective scenes. Recent advancements have developed various reflection-aware appearance models to enhance NeRF's capability to render specular reflections. However, the robust reconstruction of highly reflective scenes is still hindered by the inherent shape ambiguity on specular surfaces. Existing methods typically rely on additional geometry priors to regularize the shape prediction, but this can lead to oversmoothed geometry in complex scenes. Observing the critical role of surface normals in parameterizing reflections, we introduce a transmittance-gradient-based normal estimation technique that remains robust even under ambiguous shape conditions. Furthermore, we propose a dual activated densities module that effectively bridges the gap between smooth surface normals and sharp object boundaries. Combined with a reflection-aware appearance model, our proposed method achieves robust reconstruction and high-fidelity rendering of scenes featuring both highly specular reflections and intricate geometric structures. Extensive experiments demonstrate that our method outperforms existing state-of-the-art methods on various datasets."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Pruning for Sparse Diffusion Models based on Gradient Flow", "authors": "Ben Wan, Tianyi Zheng, Zhaoyu Chen, Yuxiao Wang, Jia Wang", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "Diffusion Models (DMs) have impressive capabilities among generation models, but are limited to slower inference speeds and higher computational costs. Previous works utilize one-shot structure pruning to derive lightweight DMs from pre-trained ones, but this approach often leads to a significant drop in generation quality and may result in the removal of crucial weights. Thus we propose a iterative pruning method based on gradient flow, including the gradient flow pruning process and the gradient flow pruning criterion. We employ a progressive soft pruning strategy to maintain the continuity of the mask matrix and guide it along the gradient flow of the energy function based on the pruning criterion in sparse space, thereby avoiding the sudden information loss typically caused by one-shot pruning. Gradient-flow based criterion prune parameters whose removal increases the gradient norm of loss function and can enable fast convergence for a pruned model in iterative pruning stage. Our extensive experiments on widely used datasets demonstrate that our method achieves superior performance in efficiency and consistency with pre-trained models."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          RE-POSE: Synergizing Reinforcement Learning-Based Partitioning and Offloading for Edge Object Detection", "authors": "Jianrui Shi, Yong Zhao, Zeyang Cui, Xiaoming Shen, Minhang Zeng, Xiaojie Liu", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)", "abstract": "Object detection plays a crucial role in smart video analysis, with applications ranging from autonomous driving and security to smart cities. However, achieving real-time object detection on edge devices presents significant challenges due to their limited computational resources and the high demands of deep neural network (DNN)-based detection models, particularly when processing high-resolution video. Conventional strategies, such as input down-sampling and network up-scaling, often compromise detection accuracy for faster performance or lead to higher inference latency. To address these issues, this paper introduces RE-POSE, a Reinforcement Learning (RL)-Driven Partitioning and Edge Offloading framework designed to optimize the accuracy-latency trade-off in resource-constrained edge environments. Our approach features an RL-Based Dynamic Clustering Algorithm (RL-DCA) that partitions video frames into non-uniform blocks based on object distribution and the computational characteristics of DNNs. Furthermore, a parallel edge offloading scheme is implemented to distribute these blocks across multiple edge servers for concurrent processing. Experimental evaluations show that RE-POSE significantly enhances detection accuracy and reduces inference latency, surpassing existing methods."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          DEFOM-Stereo: Depth Foundation Model Based Stereo Matching", "authors": "Hualie Jiang, Zhiqiang Lou, Laiyan Ding, Rui Xu, Minglang Tan, Wenjie Jiang, Rui Huang", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Stereo matching is a key technique for metric depth estimation in computer vision and robotics. Real-world challenges like occlusion and non-texture hinder accurate disparity estimation from binocular matching cues. Recently, monocular relative depth estimation has shown remarkable generalization using vision foundation models. Thus, to facilitate robust stereo matching with monocular depth cues, we incorporate a robust monocular relative depth model into the recurrent stereo-matching framework, building a new framework for depth foundation model-based stereo-matching, DEFOM-Stereo. In the feature extraction stage, we construct the combined context and matching feature encoder by integrating features from conventional CNNs and DEFOM. In the update stage, we use the depth predicted by DEFOM to initialize the recurrent disparity and introduce a scale update module to refine the disparity at the correct scale. DEFOM-Stereo is verified to have comparable performance on the Scene Flow dataset with state-of-the-art (SOTA) methods and notably shows much stronger zero-shot generalization. Moreover, DEFOM-Stereo achieves SOTA performance on the KITTI 2012, KITTI 2015, Middlebury, and ETH3D benchmarks, ranking 1st on many metrics. In the joint evaluation under the robust vision challenge, our model simultaneously outperforms previous models on the individual benchmarks. Both results demonstrate the outstanding capabilities of the proposed model."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Sensorimotor Control Strategies for Tactile Robotics", "authors": "Enrico Donato, Matteo Lo Preti, Lucia Beccai, Egidio Falotico", "subjects": "Subjects:\nRobotics (cs.RO)", "abstract": "How are robots becoming smarter at interacting with their surroundings? Recent advances have reshaped how robots use tactile sensing to perceive and engage with the world. Tactile sensing is a game-changer, allowing robots to embed sensorimotor control strategies to interact with complex environments and skillfully handle heterogeneous objects. Such control frameworks plan contact-driven motions while staying responsive to sudden changes. We review the latest methods for building perception and control systems in tactile robotics while offering practical guidelines for their design and implementation. We also address key challenges to shape the future of intelligent robots."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Predicting Air Temperature from Volumetric Urban Morphology with Machine Learning", "authors": "Berk K\u0131v\u0131lc\u0131m, Patrick Erik Bradley", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "In this study, we firstly introduce a method that converts CityGML data into voxels which works efficiently and fast in high resolution for large scale datasets such as cities but by sacrificing some building details to overcome the limitations of previous voxelization methodologies that have been computationally intensive and inefficient at transforming large-scale urban areas into voxel representations for high resolution. Those voxelized 3D city data from multiple cities and corresponding air temperature data are used to develop a machine learning model. Before the model training, Gaussian blurring is implemented on input data to consider spatial relationships, as a result the correlation rate between air temperature and volumetric building morphology is also increased after the Gaussian blurring. After the model training, the prediction results are not just evaluated with Mean Square Error (MSE) but some image similarity metrics such as Structural Similarity Index Measure (SSIM) and Learned Perceptual Image Patch Similarity (LPIPS) that are able to detect and consider spatial relations during the evaluation process. This trained model is capable of predicting the spatial distribution of air temperature by using building volume information of corresponding pixel as input. By doing so, this research aims to assist urban planners in incorporating environmental parameters into their planning strategies, thereby facilitating more sustainable and inhabitable urban environments."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Guided Debugging of Auto-Translated Code Using Differential Testing", "authors": "Shengnan Wu, Xinyu Sun, Xin Wang, Yangfan Zhou", "subjects": "Subjects:\nSoftware Engineering (cs.SE)", "abstract": "Large Language Models (LLMs) hold great promise in the task of code translation. However, the lack of explainability complicates the identification of the inevitable translation errors. In this paper, we propose tHinter, a debugging tool to locate translation errors in auto-translated code. The core idea of tHinter is that correctly translated, the source and translated code should present the same functionalities, giving the same output for the same input. Hence, lines in the translated code responsible for output differences are possibly translation errors. First, tHinter employs fuzzing to generate diverse test cases that thoroughly explore the translated code. Then, tHinter relies on a heuristic algorithm to pinpoint translation errors from coverage information and differential testing execution results of those test cases. This heuristic algorithm is designed to leverage both the statistics and the expertise of developers. Comprehensive experiments with real code show its effectiveness. It reduces 71% lines developers need to review during debugging and increases the likelihood of the LLM fixing translation errors in a single query by 59%. Developers generally consider it satisfactory and helpful."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Connectivity for AI enabled cities -- A field survey based study of emerging economies", "authors": "Dibakar Das, Jyotsna Bapat, Angeliki Katsenou, Sushmita Shrestha", "subjects": "Subjects:\nComputers and Society (cs.CY)", "abstract": "The impact of Artificial Intelligence (AI) is transforming various aspects of urban life, including, governance, policy and planning, healthcare, sustainability, economics, entrepreneurship, etc. Although AI immense potential for positively impacting urban living, its success depends on overcoming significant challenges, particularly in telecommunications infrastructure. Smart city applications, such as, federated learning, Internet of Things (IoT), and online financial services, require reliable Quality of Service (QoS) from telecommunications networks to ensure effective information transfer. However, with over three billion people underserved or lacking access to internet, many of these AI-driven applications are at risk of either remaining underutilized or failing altogether. Furthermore, many IoT and video-based applications in densely populated urban areas require high-quality connectivity. This paper explores these issues, focusing on the challenges that need to be mitigated to make AI succeed in emerging countries, where more than 80% of the world population resides and urban migration grows. In this context, an overview of a case study conducted in Kathmandu, Nepal, highlights citizens' aspirations for affordable, high-quality internet-based services. The findings underscore the pressing need for advanced telecommunication networks to meet diverse user requirements while addressing investment and infrastructure gaps. This discussion provides insights into bridging the digital divide and enabling AI's transformative potential in urban areas."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Utilizing AI Language Models to Identify Prognostic Factors for Coronary Artery Disease: A Study in Mashhad Residents", "authors": "Bami Zahra, Behnampour Nasser, Doosti Hassan, Ghayour Mobarhan Majid", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "Abstract: Background: Understanding cardiovascular artery disease risk factors, the leading global cause of mortality, is crucial for influencing its etiology, prevalence, and treatment. This study aims to evaluate prognostic markers for coronary artery disease in Mashhad using Naive Bayes, REP Tree, J48, CART, and CHAID algorithms. Methods: Using data from the 2009 MASHAD STUDY, prognostic factors for coronary artery disease were determined with Naive Bayes, REP Tree, J48, CART, CHAID, and Random Forest algorithms using R 3.5.3 and WEKA 3.9.4. Model efficiency was compared by sensitivity, specificity, and accuracy. Cases were patients with coronary artery disease; each had three controls (totally 940). Results: Prognostic factors for coronary artery disease in Mashhad residents varied by algorithm. CHAID identified age, myocardial infarction history, and hypertension. CART included depression score and physical activity. REP added education level and anxiety score. NB included diabetes and family history. J48 highlighted father's heart disease and weight loss. CHAID had the highest accuracy (0.80). Conclusion: Key prognostic factors for coronary artery disease in CART and CHAID models include age, myocardial infarction history, hypertension, depression score, physical activity, and BMI. NB, REP Tree, and J48 identified numerous factors. CHAID had the highest accuracy, sensitivity, and specificity. CART offers simpler interpretation, aiding physician and paramedic model selection based on specific. Keywords: RF, Na\u00efve Bayes, REP, J48 algorithms, Coronary Artery Disease (CAD)."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          MonoSOWA: Scalable monocular 3D Object detector Without human Annotations", "authors": "Jan Skvrna, Lukas Neumann", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Detecting the three-dimensional position and orientation of objects using a single RGB camera is a foundational task in computer vision with many important applications. Traditionally, 3D object detection methods are trained in a fully-supervised setup, requiring vast amounts of human annotations, which are laborious, costly, and do not scale well with the ever-increasing amounts of data being captured. In this paper, we present the first method to train 3D object detectors for monocular RGB cameras without domain-specific human annotations, thus making orders of magnitude more data available for training. Thanks to newly proposed Canonical Object Space, the method can not only exploit data across a variety of datasets and camera setups to train a single 3D detector, but unlike previous work it also works out of the box in previously unseen camera setups. All this is crucial for practical applications, where the data and cameras are extremely heterogeneous. The method is evaluated on two standard autonomous driving datasets, where it outperforms previous works, which, unlike our method, still rely on 2D human annotations."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Building Bridges across Papua New Guinea's Digital Divide in Growing the ICT Industry", "authors": "Marc Cheong, Sankwi Abuzo, Hideaki Hata, Priscilla Kevin, Winifred Kula, Benson Mirou, Christoph Treude, Dong Wang, Raula Gaikovina Kula", "subjects": "Subjects:\nComputers and Society (cs.CY)", "abstract": "Papua New Guinea (PNG) is an emerging tech society with an opportunity to overcome geographic and social boundaries, in order to engage with the global market. However, the current tech landscape, dominated by Big Tech in Silicon Valley and other multinational companies in the Global North, tends to overlook the requirements of emerging economies such as PNG. This is becoming more obvious as issues such as algorithmic bias (in tech product deployments) and the digital divide (as in the case of non-affordable commercial software) are affecting PNG users. The Open Source Software (OSS) movement, based on extant research, is seen as a way to level the playing field in the digitalization and adoption of Information and Communications Technologies (ICTs) in PNG. This perspectives paper documents the outcome of the second International Workshop on BRIdging the Divides with Globally Engineered Software} (BRIDGES2023) in the hopes of proposing ideas for future research into ICT education, uplifting software engineering (SE) capability, and OSS adoption in promoting a more equitable digital future for PNG."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Exploring the Inquiry-Diagnosis Relationship with Advanced Patient Simulators", "authors": "Zhaocheng Liu, Quan Tu, Wen Ye, Yu Xiao, Zhishou Zhang, Hengfu Cui, Yalun Zhu, Qiang Ju, Shizheng Li, Jian Xie", "subjects": "Subjects:\nComputation and Language (cs.CL)", "abstract": "Online medical consultation (OMC) restricts doctors to gathering patient information solely through inquiries, making the already complex sequential decision-making process of diagnosis even more challenging. Recently, the rapid advancement of large language models has demonstrated a significant potential to transform OMC. However, most studies have primarily focused on improving diagnostic accuracy under conditions of relatively sufficient information, while paying limited attention to the \"inquiry\" phase of the consultation process. This lack of focus has left the relationship between \"inquiry\" and \"diagnosis\" insufficiently explored. In this paper, we first extract real patient interaction strategies from authentic doctor-patient conversations and use these strategies to guide the training of a patient simulator that closely mirrors real-world behavior. By inputting medical records into our patient simulator to simulate patient responses, we conduct extensive experiments to explore the relationship between \"inquiry\" and \"diagnosis\" in the consultation process. Experimental results demonstrate that inquiry and diagnosis adhere to the Liebig's law: poor inquiry quality limits the effectiveness of diagnosis, regardless of diagnostic capability, and vice versa. Furthermore, the experiments reveal significant differences in the inquiry performance of various models. To investigate this phenomenon, we categorize the inquiry process into four types: (1) chief complaint inquiry; (2) specification of known symptoms; (3) inquiry about accompanying symptoms; and (4) gathering family or medical history. We analyze the distribution of inquiries across the four types for different models to explore the reasons behind their significant performance differences. We plan to open-source the weights and related code of our patient simulator at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          The Devil is in the Details: Simple Remedies for Image-to-LiDAR Representation Learning", "authors": "Wonjun Jo, Kwon Byung-Ki, Kim Ji-Yeon, Hawook Jeong, Kyungdon Joo, Tae-Hyun Oh", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "LiDAR is a crucial sensor in autonomous driving, commonly used alongside cameras. By exploiting this camera-LiDAR setup and recent advances in image representation learning, prior studies have shown the promising potential of image-to-LiDAR distillation. These prior arts focus on the designs of their own losses to effectively distill the pre-trained 2D image representations into a 3D model. However, the other parts of the designs have been surprisingly unexplored. We find that fundamental design elements, e.g., the LiDAR coordinate system, quantization according to the existing input interface, and data utilization, are more critical than developing loss functions, which have been overlooked in prior works. In this work, we show that simple fixes to these designs notably outperform existing methods by 16% in 3D semantic segmentation on the nuScenes dataset and 13% in 3D object detection on the KITTI dataset in downstream task performance. We focus on overlooked design choices along the spatial and temporal axes. Spatially, prior work has used cylindrical coordinate and voxel sizes without considering their side effects yielded with a commonly deployed sparse convolution layer input interface, leading to spatial quantization errors in 3D models. Temporally, existing work has avoided cumbersome data curation by discarding unsynced data, limiting the use to only the small portion of data that is temporally synced across sensors. We analyze these effects and propose simple solutions for each overlooked aspect."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Comparison of Various SLAM Systems for Mobile Robot in an Indoor Environment", "authors": "Maksim Filipenko, Ilya Afanasyev", "subjects": "Subjects:\nRobotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "This article presents a comparative analysis of a mobile robot trajectories computed by various ROS-based SLAM systems. For this reason we developed a prototype of a mobile robot with common sensors: 2D lidar, a monocular and ZED stereo cameras. Then we conducted experiments in a typical office environment and collected data from all sensors, running all tested SLAM systems based on the acquired dataset. We studied the following SLAM systems: (a) 2D lidar-based: GMapping, Hector SLAM, Cartographer; (b) monocular camera-based: Large Scale Direct monocular SLAM (LSD SLAM), ORB SLAM, Direct Sparse Odometry (DSO); and (c) stereo camera-based: ZEDfu, Real-Time Appearance-Based Mapping (RTAB map), ORB SLAM, Stereo Parallel Tracking and Mapping (S-PTAM). Since all SLAM methods were tested on the same dataset we compared results for different SLAM systems with appropriate metrics, demonstrating encouraging results for lidar-based Cartographer SLAM, Monocular ORB SLAM and Stereo RTAB Map methods."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Evaluating Conversational Recommender Systems with Large Language Models: A User-Centric Evaluation Framework", "authors": "Nuo Chen, Quanyu Dai, Xiaoyu Dong, Xiao-Ming Wu, Zhenhua Dong", "subjects": "Subjects:\nInformation Retrieval (cs.IR)", "abstract": "Conversational recommender systems (CRS) involve both recommendation and dialogue tasks, which makes their evaluation a unique challenge. Although past research has analyzed various factors that may affect user satisfaction with CRS interactions from the perspective of user studies, few evaluation metrics for CRS have been proposed. Recent studies have shown that LLMs can align with human preferences, and several LLM-based text quality evaluation measures have been introduced. However, the application of LLMs in CRS evaluation remains relatively limited. To address this research gap and advance the development of user-centric conversational recommender systems, this study proposes an automated LLM-based CRS evaluation framework, building upon existing research in human-computer interaction and psychology. The framework evaluates CRS from four dimensions: dialogue behavior, language expression, recommendation items, and response content. We use this framework to evaluate four different conversational recommender systems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          VanGogh: A Unified Multimodal Diffusion-based Framework for Video Colorization", "authors": "Zixun Fang, Zhiheng Liu, Kai Zhu, Yu Liu, Ka Leong Cheng, Wei Zhai, Yang Cao, Zheng-Jun Zha", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Video colorization aims to transform grayscale videos into vivid color representations while maintaining temporal consistency and structural integrity. Existing video colorization methods often suffer from color bleeding and lack comprehensive control, particularly under complex motion or diverse semantic cues. To this end, we introduce VanGogh, a unified multimodal diffusion-based framework for video colorization. VanGogh tackles these challenges using a Dual Qformer to align and fuse features from multiple modalities, complemented by a depth-guided generation process and an optical flow loss, which help reduce color overflow. Additionally, a color injection strategy and luma channel replacement are implemented to improve generalization and mitigate flickering artifacts. Thanks to this design, users can exercise both global and local control over the generation process, resulting in higher-quality colorized videos. Extensive qualitative and quantitative evaluations, and user studies, demonstrate that VanGogh achieves superior temporal consistency and color this http URL page: this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Lattice Rules Meet Kernel Cubature", "authors": "Vesa Kaarnioja, Ilja Klebanov, Claudia Schillings, Yuya Suzuki", "subjects": "Subjects:\nNumerical Analysis (math.NA); Statistics Theory (math.ST)", "abstract": "Rank-1 lattice rules are a class of equally weighted quasi-Monte Carlo methods that achieve essentially linear convergence rates for functions in a reproducing kernel Hilbert space (RKHS) characterized by square-integrable first-order mixed partial derivatives. In this work, we explore the impact of replacing the equal weights in lattice rules with optimized cubature weights derived using the reproducing kernel. We establish a theoretical result demonstrating a doubled convergence rate in the one-dimensional case and provide numerical investigations of convergence rates in higher dimensions. We also present numerical results for an uncertainty quantification problem involving an elliptic partial differential equation with a random coefficient."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Omni-Emotion: Extending Video MLLM with Detailed Face and Audio Modeling for Multimodal Emotion Analysis", "authors": "Qize Yang, Detao Bai, Yi-Xing Peng, Xihan Wei", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Understanding emotions accurately is essential for fields like human-computer interaction. Due to the complexity of emotions and their multi-modal nature (e.g., emotions are influenced by facial expressions and audio), researchers have turned to using multi-modal models to understand human emotions rather than single-modality. However, current video multi-modal large language models (MLLMs) encounter difficulties in effectively integrating audio and identifying subtle facial micro-expressions. Furthermore, the lack of detailed emotion analysis datasets also limits the development of multimodal emotion analysis. To address these issues, we introduce a self-reviewed dataset and a human-reviewed dataset, comprising 24,137 coarse-grained samples and 3,500 manually annotated samples with detailed emotion annotations, respectively. These datasets allow models to learn from diverse scenarios and better generalize to real-world applications. Moreover, in addition to the audio modeling, we propose to explicitly integrate facial encoding models into the existing advanced Video MLLM, enabling the MLLM to effectively unify audio and the subtle facial cues for emotion understanding. By aligning these features within a unified space and employing instruction tuning in our proposed datasets, our Omni-Emotion achieves state-of-the-art performance in both emotion recognition and reasoning tasks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          AnyStory: Towards Unified Single and Multiple Subject Personalization in Text-to-Image Generation", "authors": "Junjie He, Yuxiang Tuo, Binghui Chen, Chongyang Zhong, Yifeng Geng, Liefeng Bo", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Recently, large-scale generative models have demonstrated outstanding text-to-image generation capabilities. However, generating high-fidelity personalized images with specific subjects still presents challenges, especially in cases involving multiple subjects. In this paper, we propose AnyStory, a unified approach for personalized subject generation. AnyStory not only achieves high-fidelity personalization for single subjects, but also for multiple subjects, without sacrificing subject fidelity. Specifically, AnyStory models the subject personalization problem in an \"encode-then-route\" manner. In the encoding step, AnyStory utilizes a universal and powerful image encoder, i.e., ReferenceNet, in conjunction with CLIP vision encoder to achieve high-fidelity encoding of subject features. In the routing step, AnyStory utilizes a decoupled instance-aware subject router to accurately perceive and predict the potential location of the corresponding subject in the latent space, and guide the injection of subject conditions. Detailed experimental results demonstrate the excellent performance of our method in retaining subject details, aligning text descriptions, and personalizing for multiple subjects. The project page is at this https URL ."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          HydraMix: Multi-Image Feature Mixing for Small Data Image Classification", "authors": "Christoph Reinders, Frederik Schubert, Bodo Rosenhahn", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Training deep neural networks requires datasets with a large number of annotated examples. The collection and annotation of these datasets is not only extremely expensive but also faces legal and privacy problems. These factors are a significant limitation for many real-world applications. To address this, we introduce HydraMix, a novel architecture that generates new image compositions by mixing multiple different images from the same class. HydraMix learns the fusion of the content of various images guided by a segmentation-based mixing mask in feature space and is optimized via a combination of unsupervised and adversarial training. Our data augmentation scheme allows the creation of models trained from scratch on very small datasets. We conduct extensive experiments on ciFAIR-10, STL-10, and ciFAIR-100. Additionally, we introduce a novel text-image metric to assess the generality of the augmented datasets. Our results show that HydraMix outperforms existing state-of-the-art methods for image classification on small datasets."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Multimodal Marvels of Deep Learning in Medical Diagnosis: A Comprehensive Review of COVID-19 Detection", "authors": "Md Shofiqul Islama, Khondokar Fida Hasanc, Hasibul Hossain Shajeebd, Humayan Kabir Ranae, Md Saifur Rahmand, Md Munirul Hasanb, AKM Azadf, Ibrahim Abdullahg, Mohammad Ali Moni", "subjects": "Subjects:\nMachine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS); Image and Video Processing (eess.IV)", "abstract": "This study presents a comprehensive review of the potential of multimodal deep learning (DL) in medical diagnosis, using COVID-19 as a case example. Motivated by the success of artificial intel- ligence applications during the COVID-19 pandemic, this research aims to uncover the capabilities of DL in disease screening, prediction, and classification, and to derive insights that enhance the resilience, sustainability, and inclusiveness of science, technology, and innovation systems. Adopting a systematic approach, we investigate the fundamental methodologies, data sources, preprocessing steps, and challenges encountered in various studies and implementations. We explore the architecture of deep learning models, emphasising their data-specific structures and underlying algorithms. Subsequently, we compare different deep learning strategies utilised in COVID-19 analysis, evaluating them based on methodology, data, performance, and prerequisites for future research. By examining diverse data types and diagnostic modalities, this research contributes to scientific understanding and knowledge of the multimodal application of DL and its effectiveness in diagnosis. We have implemented and analysed 11 deep learning models using COVID-19 image, text, and speech (ie, cough) data. Our analysis revealed that the MobileNet model achieved the highest accuracy of 99.97% for COVID-19 image data and 93.73% for speech data (i.e., cough). However, the BiGRU model demonstrated superior performance in COVID-19 text classification with an accuracy of 99.89%. The broader implications of this research suggest potential benefits for other domains and disciplines that could leverage deep learning techniques for image, text, and speech analysis."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Power-Efficient RAN Intelligent Controllers Through Optimized KPI Monitoring", "authors": "Jo\u00e3o Paulo S. H. Lima, George N. Katsaros, Konstantinos Nikitopoulos", "subjects": "Subjects:\nSystems and Control (eess.SY)", "abstract": "The Open Radio Access Network (RAN) paradigm envisions a more flexible, interoperable, and intelligent RAN ecosystem via new open interfaces and elements like the RAN Intelligent Controller (RIC). However, the impact of these elements on Open RAN's power consumption remains heavily unexplored. This work for the first time evaluates the impact of Key Performance Indicator (KPI) monitoring on RIC's power consumption using real traffic and power measurements. By analyzing various RIC-RAN communication scenarios, we identify that RIC's power consumption can become a scalability bottleneck, particularly in large-scale deployments, even when RIC is limited to its core operational functionalities and without incorporating application-specific processes. In this context, also for the first time we explore potential power savings through the elimination of redundant KPI transmissions, extending existing techniques for identical subscription removal and KPI selection, achieving significant power consumption gains exceeding 87\\% of the overall RIC power consumption."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          PIER: A Novel Metric for Evaluating What Matters in Code-Switching", "authors": "Enes Yavuz Ugan, Ngoc-Quan Pham, Leonard B\u00e4rmann, Alex Waibel", "subjects": "Subjects:\nComputation and Language (cs.CL); Machine Learning (cs.LG)", "abstract": "Code-switching, the alternation of languages within a single discourse, presents a significant challenge for Automatic Speech Recognition. Despite the unique nature of the task, performance is commonly measured with established metrics such as Word-Error-Rate (WER). However, in this paper, we question whether these general metrics accurately assess performance on code-switching. Specifically, using both Connectionist-Temporal-Classification and Encoder-Decoder models, we show fine-tuning on non-code-switched data from both matrix and embedded language improves classical metrics on code-switching test sets, although actual code-switched words worsen (as expected). Therefore, we propose Point-of-Interest Error Rate (PIER), a variant of WER that focuses only on specific words of interest. We instantiate PIER on code-switched utterances and show that this more accurately describes the code-switching performance, showing huge room for improvement in future work. This focused evaluation allows for a more precise assessment of model performance, particularly in challenging aspects such as inter-word and intra-word code-switching."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Dataset Generation Toolbox for Dynamic Security Assessment: On the Role of the Security Boundary", "authors": "Bastien Giraud, Lola Charles, Agnes Marjorie Nakiganda, Johanna Vorwerk, Spyros Chatzivasileiadis", "subjects": "Subjects:\nSystems and Control (eess.SY)", "abstract": "Dynamic security assessment (DSA) is crucial for ensuring the reliable operation of power systems. However, conventional DSA approaches are becoming intractable for future power systems, driving interest in more computationally efficient data-driven methods. Efficient dataset generation is a cornerstone of these methods. While importance and generic sampling techniques often focus on operating points near the system's security boundary, systematic methods for sampling in this region remain scarce. Furthermore, the impact of sampling near the security boundary on the performance of data-driven DSA methods has yet to be established. This paper highlights the critical role of accurately capturing security boundaries for effective security assessment. As such, we propose a novel method for generating a high number of samples close to the security boundary, considering both AC feasibility and small-signal stability. Case studies on the PGLib-OPF 39-bus and PGLib-OPF 162-bus systems demonstrate the importance of including boundary-adjacent operating points in training datasets while maintaining a balanced distribution of secure and insecure points."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Runtime Analysis of the Multi-Valued Compact Genetic Algorithm on Generalized LeadingOnes", "authors": "Sumit Adak, Carsten Witt", "subjects": "Subjects:\nNeural and Evolutionary Computing (cs.NE)", "abstract": "In the literature on runtime analyses of estimation of distribution algorithms (EDAs), researchers have recently explored univariate EDAs for multi-valued decision variables. Particularly, Jedidia et al. gave the first runtime analysis of the multi-valued UMDA on the r-valued LeadingOnes (r-LeadingOnes) functions and Adak et al. gave the first runtime analysis of the multi-valued cGA (r-cGA) on the r-valued OneMax function. We utilize their framework to conduct an analysis of the multi-valued cGA on the r-valued LeadingOnes function. Even for the binary case, a runtime analysis of the classical cGA on LeadingOnes was not yet available. In this work, we show that the runtime of the r-cGA on r-LeadingOnes is O(n^2r^2 log^3 n log^2 r) with high probability."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          RWZC: A Model-Driven Approach for Learning-based Robust Wyner-Ziv Coding", "authors": "Yuxuan Shi, Shuo Shao, Yongpeng Wu, Wenjun Zhang, Merouane Debbah", "subjects": "Subjects:\nInformation Theory (cs.IT)", "abstract": "In this paper, a novel learning-based Wyner-Ziv coding framework is considered under a distributed image transmission scenario, where the correlated source is only available at the receiver. Unlike other learnable frameworks, our approach demonstrates robustness to non-stationary source correlation, where the overlapping information between image pairs varies. Specifically, we first model the affine relationship between correlated images and leverage this model for learnable mask generation and rate-adaptive joint source-channel coding. Moreover, we also provide a warping-prediction network to remove the distortion from channel interference and affine transform. Intuitively, the observed performance improvement is largely due to focusing on the simple geometric relationship, rather than the complex joint distribution between the sources. Numerical results show that our framework achieves a 1.5 dB gain in PSNR and a 0.2 improvement in MS-SSIM, along with a significant superiority in perceptual metrics, compared to state-of-the-art methods when applied to real-world samples with non-stationary correlations."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Augmenting a Large Language Model with a Combination of Text and Visual Data for Conversational Visualization of Global Geospatial Data", "authors": "Omar Mena, Alexandre Kouyoumdjian, Lonni Besan\u00e7on, Michael Gleicher, Ivan Viola, Anders Ynnerman", "subjects": "Subjects:\nHuman-Computer Interaction (cs.HC); Computation and Language (cs.CL)", "abstract": "We present a method for augmenting a Large Language Model (LLM) with a combination of text and visual data to enable accurate question answering in visualization of scientific data, making conversational visualization possible. LLMs struggle with tasks like visual data interaction, as they lack contextual visual information. We address this problem by merging a text description of a visualization and dataset with snapshots of the visualization. We extract their essential features into a structured text file, highly compact, yet descriptive enough to appropriately augment the LLM with contextual information, without any fine-tuning. This approach can be applied to any visualization that is already finally rendered, as long as it is associated with some textual description."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Merging Models on the Fly Without Retraining: A Sequential Approach to Scalable Continual Model Merging", "authors": "Anke Tang, Enneng Yang, Li Shen, Yong Luo, Han Hu, Bo Du, Dacheng Tao", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "Deep model merging represents an emerging research direction that combines multiple fine-tuned models to harness their specialized capabilities across different tasks and domains. Current model merging techniques focus on merging all available models simultaneously, with weight interpolation-based methods being the predominant approaches. However, these conventional approaches are not well-suited for scenarios where models become available sequentially, and they often suffer from high memory requirements and potential interference between tasks. In this study, we propose a training-free projection-based continual merging method that processes models sequentially through orthogonal projections of weight matrices and adaptive scaling mechanisms. Our method operates by projecting new parameter updates onto subspaces orthogonal to existing merged parameter updates while using an adaptive scaling mechanism to maintain stable parameter distances, enabling efficient sequential integration of task-specific knowledge. Our approach maintains constant memory complexity to the number of models, minimizes interference between tasks through orthogonal projections, and retains the performance of previously merged models through adaptive task vector scaling. Extensive experiments on CLIP-ViT models demonstrate that our method achieves a 5-8% average accuracy improvement while maintaining robust performance in different task orderings."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Class Incremental Fault Diagnosis under Limited Fault Data via Supervised Contrastive Knowledge Distillation", "authors": "Hanrong Zhang, Yifei Yao, Zixuan Wang, Jiayuan Su, Mengxuan Li, Peng Peng, Hongwei Wang", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Class-incremental fault diagnosis requires a model to adapt to new fault classes while retaining previous knowledge. However, limited research exists for imbalanced and long-tailed data. Extracting discriminative features from few-shot fault data is challenging, and adding new fault classes often demands costly model retraining. Moreover, incremental training of existing methods risks catastrophic forgetting, and severe class imbalance can bias the model's decisions toward normal classes. To tackle these issues, we introduce a Supervised Contrastive knowledge distiLlation for class Incremental Fault Diagnosis (SCLIFD) framework proposing supervised contrastive knowledge distillation for improved representation learning capability and less forgetting, a novel prioritized exemplar selection method for sample replay to alleviate catastrophic forgetting, and the Random Forest Classifier to address the class imbalance. Extensive experimentation on simulated and real-world industrial datasets across various imbalance ratios demonstrates the superiority of SCLIFD over existing approaches. Our code can be found at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Confidence Estimation for Error Detection in Text-to-SQL Systems", "authors": "Oleg Somov, Elena Tutubalina", "subjects": "Subjects:\nMachine Learning (cs.LG); Computation and Language (cs.CL)", "abstract": "Text-to-SQL enables users to interact with databases through natural language, simplifying the retrieval and synthesis of information. Despite the success of large language models (LLMs) in converting natural language questions into SQL queries, their broader adoption is limited by two main challenges: achieving robust generalization across diverse queries and ensuring interpretative confidence in their predictions. To tackle these issues, our research investigates the integration of selective classifiers into Text-to-SQL systems. We analyse the trade-off between coverage and risk using entropy based confidence estimation with selective classifiers and assess its impact on the overall performance of Text-to-SQL models. Additionally, we explore the models' initial calibration and improve it with calibration techniques for better model alignment between confidence and accuracy. Our experimental results show that encoder-decoder T5 is better calibrated than in-context-learning GPT 4 and decoder-only Llama 3, thus the designated external entropy-based selective classifier has better performance. The study also reveal that, in terms of error detection, selective classifier with a higher probability detects errors associated with irrelevant questions rather than incorrect query generations."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Make yourself comfortable: Nudging urban heat and noise mitigation with smartwatch-based Just-in-time Adaptive Interventions (JITAI)", "authors": "Clayton Miller, Yun Xuan Chua, Matias Quintana, Binyu Lei, Filip Biljecki, Mario Frei", "subjects": "Subjects:\nHuman-Computer Interaction (cs.HC)", "abstract": "Humans can play a more active role in improving their comfort in the built environment if given the right information at the right place and time. This paper outlines the use of Just-in-Time Adaptive Interventions (JITAI) implemented in the context of the built environment to provide information that helps humans minimize the impact of heat and noise on their daily lives. This framework builds upon the open-source Cozie iOS smartwatch platform. It includes data collection through micro-surveys and intervention messages triggered by environmental, contextual, and personal history conditions. An eight-month deployment of the method was completed in Singapore with 103 participants who submitted over 12,000 micro-surveys and delivered over 3,600 JITAI intervention messages. A weekly survey conducted during two deployment phases revealed an overall increase in perceived usefulness ranging from 8-19% over the first three weeks of data collection. For noise-related interventions, participants showed an overall increase in location changes ranging from 4-11% and a 2-17% increase in earphone use to mitigate noise distractions. For thermal comfort-related interventions, participants demonstrated a 3-13% increase in adjustments to their location or thermostat to feel more comfortable. The analysis found evidence that personality traits (such as conscientiousness), gender, and environmental preferences could be factors in determining the perceived helpfulness of JITAIs and influencing behavior change. These findings underscore the importance of tailoring intervention strategies to individual traits and environmental conditions, setting the stage for future research to refine the delivery, timing, and content of intervention messages."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          MOGNET: A Mux-residual quantized Network leveraging Online-Generated weights", "authors": "Van Thien Nguyen, William Guicquero, Gilles Sicard", "subjects": "Subjects:\nMachine Learning (cs.LG); Hardware Architecture (cs.AR)", "abstract": "This paper presents a compact model architecture called MOGNET, compatible with a resource-limited hardware. MOGNET uses a streamlined Convolutional factorization block based on a combination of 2 point-wise (1x1) convolutions with a group-wise convolution in-between. To further limit the overall model size and reduce the on-chip required memory, the second point-wise convolution's parameters are on-line generated by a Cellular Automaton structure. In addition, MOGNET enables the use of low-precision weights and activations, by taking advantage of a Multiplexer mechanism with a proper Bitshift rescaling for integrating residual paths without increasing the hardware-related complexity. To efficiently train this model we also introduce a novel weight ternarization method favoring the balance between quantized levels. Experimental results show that given tiny memory budget (sub-2Mb), MOGNET can achieve higher accuracy with a clear gap up to 1% at a similar or even lower model size compared to recent state-of-the-art methods."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          AdaFV: Accelerating VLMs with Self-Adaptive Cross-Modality Attention Mixture", "authors": "Jiayi Han, Liang Du, Yiwen Wu, Xiangguo Zhou, Hongwei Du, Weibo Zheng", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "The success of VLMs often relies on the dynamic high-resolution schema that adaptively augments the input images to multiple crops, so that the details of the images can be retained. However, such approaches result in a large number of redundant visual tokens, thus significantly reducing the efficiency of the VLMs. To improve the VLMs' efficiency without introducing extra training costs, many research works are proposed to reduce the visual tokens by filtering the uninformative visual tokens or aggregating their information. Some approaches propose to reduce the visual tokens according to the self-attention of VLMs, which are biased, to result in inaccurate responses. The token reduction approaches solely rely on visual cues are text-agnostic, and fail to focus on the areas that are most relevant to the question, especially when the queried objects are non-salient to the image. In this work, we first conduct experiments to show that the original text embeddings are aligned with the visual tokens, without bias on the tailed visual tokens. We then propose a self-adaptive cross-modality attention mixture mechanism that dynamically leverages the effectiveness of visual saliency and text-to-image similarity in the pre-LLM layers to select the visual tokens that are informative. Extensive experiments demonstrate that the proposed approach achieves state-of-the-art training-free VLM acceleration performance, especially when the reduction rate is sufficiently large."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          AI in Support of Diversity and Inclusion", "authors": "\u00c7i\u00e7ek G\u00fcven, Afra Alishahi, Henry Brighton, Gonzalo N\u00e1poles, Juan Sebastian Olier, Marie \u0160af\u00e1\u0159, Eric Postma, Dimitar Shterionov, Mirella De Sisto, Eva Vanmassenhove", "subjects": "Subjects:\nArtificial Intelligence (cs.AI)", "abstract": "In this paper, we elaborate on how AI can support diversity and inclusion and exemplify research projects conducted in that direction. We start by looking at the challenges and progress in making large language models (LLMs) more transparent, inclusive, and aware of social biases. Even though LLMs like ChatGPT have impressive abilities, they struggle to understand different cultural contexts and engage in meaningful, human like conversations. A key issue is that biases in language processing, especially in machine translation, can reinforce inequality. Tackling these biases requires a multidisciplinary approach to ensure AI promotes diversity, fairness, and inclusion. We also highlight AI's role in identifying biased content in media, which is important for improving representation. By detecting unequal portrayals of social groups, AI can help challenge stereotypes and create more inclusive technologies. Transparent AI algorithms, which clearly explain their decisions, are essential for building trust and reducing bias in AI systems. We also stress AI systems need diverse and inclusive training data. Projects like the Child Growth Monitor show how using a wide range of data can help address real world problems like malnutrition and poverty. We present a project that demonstrates how AI can be applied to monitor the role of search engines in spreading disinformation about the LGBTQ+ community. Moreover, we discuss the SignON project as an example of how technology can bridge communication gaps between hearing and deaf people, emphasizing the importance of collaboration and mutual trust in developing inclusive AI. Overall, with this paper, we advocate for AI systems that are not only effective but also socially responsible, promoting fair and inclusive interactions between humans and machines."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Analyzing Continuous Semantic Shifts with Diachronic Word Similarity Matrices", "authors": "Hajime Kiyama, Taichi Aida, Mamoru Komachi, Toshinobu Ogiso, Hiroya Takamura, Daichi Mochihashi", "subjects": "Subjects:\nComputation and Language (cs.CL)", "abstract": "The meanings and relationships of words shift over time. This phenomenon is referred to as semantic this http URL focused on understanding how semantic shifts occur over multiple time periods is essential for gaining a detailed understanding of semantic this http URL, detecting change points only between adjacent time periods is insufficient for analyzing detailed semantic shifts, and using BERT-based methods to examine word sense proportions incurs a high computational this http URL address those issues, we propose a simple yet intuitive framework for how semantic shifts occur over multiple time periods by leveraging a similarity matrix between the embeddings of the same word through this http URL compute a diachronic word similarity matrix using fast and lightweight word embeddings across arbitrary time periods, making it deeper to analyze continuous semantic this http URL, by clustering the similarity matrices for different words, we can categorize words that exhibit similar behavior of semantic shift in an unsupervised manner."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Hardness of clique approximation for monotone circuits", "authors": "Jaros\u0142aw B\u0142asiok, Linus Meierh\u00f6fer", "subjects": "Subjects:\nComputational Complexity (cs.CC)", "abstract": "We consider a problem of approximating the size of the largest clique in a graph, with a monotone circuit. Concretely, we focus on distinguishing a random Erd\u0151s-Renyi graph $\\mathcal{G}_{n,p}$, with $p=n^{-\\frac{2}{\\alpha-1}}$ chosen st. with high probability it does not even have an $\\alpha$-clique, from a random clique on $\\beta$ vertices (where $\\alpha \\leq \\beta$). Using the approximation method of Razborov, Alon and Boppana showed in 1987 that as long as $\\sqrt{\\alpha} \\beta < n^{1-\\delta}/\\log n$, this problem requires a monotone circuit of size $n^{\\Omega(\\delta\\sqrt{\\alpha})}$, implying a lower bound of $2^{\\tilde\\Omega(n^{1/3})}$ for the exact version of the problem when $k\\approx n^{2/3}$. Recently Cavalar, Kumar, and Rossman improved their result by showing the tight lower bound $n^{\\Omega(k)}$, in a limited range $k \\leq n^{1/3}$, implying a comparable $2^{\\tilde{\\Omega}(n^{1/3})}$ lower bound. We combine the ideas of Cavalar, Kumar and Rossman with the recent breakthrough results on the sunflower conjecture by Alweiss, Lovett, Wu and Zhang to show that as long as $\\alpha \\beta < n^{1-\\delta}/\\log n$, any monotone circuit rejecting $\\mathcal{G}_{n,p}$ while accepting a $\\beta$-clique needs to have size at least $n^{\\Omega(\\delta^2 \\alpha)}$; this implies a stronger $2^{\\tilde{\\Omega}(\\sqrt{n})}$ lower bound for the unrestricted version of the problem. We complement this result with a construction of an explicit monotone circuit of size $O(n^{\\delta^2 \\alpha/2})$ which rejects $\\mathcal{G}_{n,p}$, and accepts any graph containing $\\beta$-clique whenever $\\beta > n^{1-\\delta}$. Those two theorems explain the largest $\\beta$-clique that can be distinguished from $\\mathcal{G}_{n, 1/2}$: when $\\beta > n / 2^{C \\sqrt{\\log n}}$, polynomial size circuit co do it, while for $\\beta < n / 2^{\\omega(\\sqrt{\\log n})}$ every circuit needs size $n^{\\omega(1)}$."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Intra-day Solar and Power Forecast for Optimization of Intraday Market Participation", "authors": "Nelson Salazar-Pe\u00f1a, Adolfo Palma-Vergara, Mateo Montes, Mar\u00eda Alejandra Vargas-Torres, Adriana Salinas, Andr\u00e9s Velasco, Alejandra Tabares, Andr\u00e9s Gonz\u00e1lez-Mancera", "subjects": "Subjects:\nMachine Learning (cs.LG); Signal Processing (eess.SP); Systems and Control (eess.SY)", "abstract": "The prediction of solar irradiance enhances reliability in photovoltaic (PV) solar plant generation and grid integration. In Colombia, PV plants face penalties if energy production deviates beyond governmental thresholds from intraday market offers. This research employs Long Short-Term Memory (LSTM) and Bidirectional-LSTM (Bi-LSTM) models, utilizing meteorological data from a PV plant in El Paso, Cesar, Colombia, to predict solar irradiance with a 6-hour horizon and 10-minute resolution. While Bi-LSTM showed superior performance, the LSTM model achieved comparable results with significantly reduced training time (6 hours versus 18 hours), making it computationally advantageous. The LSTM predictions were averaged to create an hourly resolution model, evaluated using Mean Absolute Error, Root-Mean-Square Error, Normalized Root-Mean-Square Error, and Mean Absolute Percentage Error metrics. Comparison with the Global Forecast System (GFS) revealed similar performance, with both models effectively capturing daily solar irradiance patterns. The forecast model integrates with an Object-Oriented power production model, enabling accurate energy offers in the intraday market while minimizing penalty costs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Exploring AI-based System Design for Pixel-level Protected Health Information Detection in Medical Images", "authors": "Tuan Truong, Ivo M. Baltruschat, Mark Klemens, Grit Werner, Matthias Lenga", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "De-identification of medical images is a critical step to ensure privacy during data sharing in research and clinical settings. The initial step in this process involves detecting Protected Health Information (PHI), which can be found in image metadata or imprinted within image pixels. Despite the importance of such systems, there has been limited evaluation of existing AI-based solutions, creating barriers to the development of reliable and robust tools. In this study, we present an AI-based pipeline for PHI detection, comprising three key components: text detection, text extraction, and analysis of PHI content in medical images. By experimenting with exchanging roles of vision and language models within the pipeline, we evaluate the performance and recommend the best setup for the PHI detection task."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Text-driven Adaptation of Foundation Models for Few-shot Surgical Workflow Analysis", "authors": "Tingxuan Chen, Kun Yuan, Vinkle Srivastav, Nassir Navab, Nicolas Padoy", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Purpose: Surgical workflow analysis is crucial for improving surgical efficiency and safety. However, previous studies rely heavily on large-scale annotated datasets, posing challenges in cost, scalability, and reliance on expert annotations. To address this, we propose Surg-FTDA (Few-shot Text-driven Adaptation), designed to handle various surgical workflow analysis tasks with minimal paired image-label data. Methods: Our approach has two key components. First, Few-shot selection-based modality alignment selects a small subset of images and aligns their embeddings with text embeddings from the downstream task, bridging the modality gap. Second, Text-driven adaptation leverages only text data to train a decoder, eliminating the need for paired image-text data. This decoder is then applied to aligned image embeddings, enabling image-related tasks without explicit image-text pairs. Results: We evaluate our approach to generative tasks (image captioning) and discriminative tasks (triplet recognition and phase recognition). Results show that Surg-FTDA outperforms baselines and generalizes well across downstream tasks. Conclusion: We propose a text-driven adaptation approach that mitigates the modality gap and handles multiple downstream tasks in surgical workflow analysis, with minimal reliance on large annotated datasets. The code and dataset will be released in this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Overshoot: Taking advantage of future gradients in momentum-based stochastic optimization", "authors": "Jakub Kopal, Michal Gregor, Santiago de Leon-Martinez, Jakub Simko", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "Overshoot is a novel, momentum-based stochastic gradient descent optimization method designed to enhance performance beyond standard and Nesterov's momentum. In conventional momentum methods, gradients from previous steps are aggregated with the gradient at current model weights before taking a step and updating the model. Rather than calculating gradient at the current model weights, Overshoot calculates the gradient at model weights shifted in the direction of the current momentum. This sacrifices the immediate benefit of using the gradient w.r.t. the exact model weights now, in favor of evaluating at a point, which will likely be more relevant for future updates. We show that incorporating this principle into momentum-based optimizers (SGD with momentum and Adam) results in faster convergence (saving on average at least 15% of steps). Overshoot consistently outperforms both standard and Nesterov's momentum across a wide range of tasks and integrates into popular momentum-based optimizers with zero memory and small computational overhead."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Core Hours and Carbon Credits: Incentivizing Sustainability in HPC", "authors": "Alok Kamatar, Maxime Gonthier, Valerie Hayot-Sasson, Andre Bauer, Marcin Copik, Torsten Hoefler, Raul Castro Fernandez, Kyle Chard, Ian Foster", "subjects": "Subjects:\nDistributed, Parallel, and Cluster Computing (cs.DC)", "abstract": "Realizing a shared responsibility between providers and consumers is critical to manage the sustainability of HPC. However, while cost may motivate efficiency improvements by infrastructure operators, broader progress is impeded by a lack of user incentives. We conduct a survey of HPC users that reveals fewer than 30 percent are aware of their energy consumption, and that energy efficiency is among users' lowest priority concerns. One explanation is that existing pricing models may encourage users to prioritize performance over energy efficiency. We propose two transparent multi-resource pricing schemes, Energy- and Carbon-Based Accounting, that seek to change this paradigm by incentivizing more efficient user behavior. These two schemes charge for computations based on their energy consumption or carbon footprint, respectively, rewarding users who leverage efficient hardware and software. We evaluate these two pricing schemes via simulation, in a prototype, and a user study."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          On a Variant of the Minimum Path Cover Problem in Acyclic Digraphs: Computational Complexity Results and Exact Method", "authors": "Nour ElHouda Tellache, Roberto Baldacci", "subjects": "Subjects:\nDiscrete Mathematics (cs.DM); Optimization and Control (math.OC)", "abstract": "The Minimum Path Cover (MPC) problem consists of finding a minimum-cardinality set of node-disjoint paths that cover all nodes in a given graph. We explore a variant of the MPC problem on acyclic digraphs (DAGs) where, given a subset of arcs, each path within the MPC should contain at least one arc from this subset. We prove that the feasibility problem is strongly NP-hard on arbitrary DAGs, but the problem can be solved in polynomial time when the DAG is the transitive closure of a path. Given that the problem may not always be feasible, our solution focuses on covering a maximum number of nodes with a minimum number of node-disjoint paths, such that each path includes at least one arc from the predefined subset of arcs. This paper introduces and investigates two integer programming formulations for this problem. We propose several valid inequalities to enhance the linear programming relaxations, employing them as cutting planes in a branch-and-cut approach. The procedure is implemented and tested on a wide range of instances, including real-world instances derived from an airline crew scheduling problem, demonstrating the effectiveness of the proposed approach."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Stylomech: Unveiling Authorship via Computational Stylometry in English and Romanized Sinhala", "authors": "Nabeelah Faumi, Adeepa Gunathilake, Benura Wickramanayake, Deelaka Dias, TGDK Sumanathilaka", "subjects": "Subjects:\nComputation and Language (cs.CL)", "abstract": "With the advent of Web 2.0, the development in social technology coupled with global communication systematically brought positive and negative impacts to society. Copyright claims and Author identification are deemed crucial as there has been a considerable amount of increase in content violation owing to the lack of proper ethics in society. The Author's attribution in both English and Romanized Sinhala became a major requirement in the last few decades. As an area largely unexplored, particularly within the context of Romanized Sinhala, the research contributes significantly to the field of computational linguistics. The proposed author attribution system offers a unique approach, allowing for the comparison of only two sets of text: suspect author and anonymous text, a departure from traditional methodologies which often rely on larger corpora. This work focuses on using the numerical representation of various pairs of the same and different authors allowing for, the model to train on these representations as opposed to text, this allows for it to apply to a multitude of authors and contexts, given that the suspected author text, and the anonymous text are of reasonable quality. By expanding the scope of authorship attribution to encompass diverse linguistic contexts, the work contributes to fostering trust and accountability in digital communication, especially in Sri Lanka. This research presents a pioneering approach to author attribution in both English and Romanized Sinhala, addressing a critical need for content verification and intellectual property rights enforcement in the digital age."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Rethinking cloud abstractions for tenant-provider cooperative optimization of AI workloads", "authors": "Marco Canini, Ricardo Bianchini, \u00cd\u00f1igo Goiri, Dejan Kosti\u0107, Peter Pietzuch", "subjects": "Subjects:\nDistributed, Parallel, and Cluster Computing (cs.DC)", "abstract": "AI workloads, often hosted in multi-tenant cloud environments, require vast computational resources but suffer inefficiencies due to limited tenant-provider coordination. Tenants lack infrastructure insights, while providers lack workload details to optimize tasks like partitioning, scheduling, and fault tolerance. We propose the HarmonAIze project to redefine cloud abstractions, enabling cooperative optimization for improved performance, efficiency, resiliency, and sustainability. This paper outlines key opportunities, challenges, and a research agenda to realize this vision."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A New Teacher-Reviewer-Student Framework for Semi-supervised 2D Human Pose Estimation", "authors": "Wulian Yun, Mengshi Qi, Fei Peng, Huadong Ma", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Conventional 2D human pose estimation methods typically require extensive labeled annotations, which are both labor-intensive and expensive. In contrast, semi-supervised 2D human pose estimation can alleviate the above problems by leveraging a large amount of unlabeled data along with a small portion of labeled data. Existing semi-supervised 2D human pose estimation methods update the network through backpropagation, ignoring crucial historical information from the previous training process. Therefore, we propose a novel semi-supervised 2D human pose estimation method by utilizing a newly designed Teacher-Reviewer-Student framework. Specifically, we first mimic the phenomenon that human beings constantly review previous knowledge for consolidation to design our framework, in which the teacher predicts results to guide the student's learning and the reviewer stores important historical parameters to provide additional supervision signals. Secondly, we introduce a Multi-level Feature Learning strategy, which utilizes the outputs from different stages of the backbone to estimate the heatmap to guide network training, enriching the supervisory information while effectively capturing keypoint relationships. Finally, we design a data augmentation strategy, i.e., Keypoint-Mix, to perturb pose information by mixing different keypoints, thus enhancing the network's ability to discern keypoints. Extensive experiments on publicly available datasets, demonstrate our method achieves significant improvements compared to the existing methods."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          MatrixNet: Learning over symmetry groups using learned group representations", "authors": "Lucas Laird, Circe Hsu, Asilata Bapat, Robin Walters", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI); Representation Theory (math.RT)", "abstract": "Group theory has been used in machine learning to provide a theoretically grounded approach for incorporating known symmetry transformations in tasks from robotics to protein modeling. In these applications, equivariant neural networks use known symmetry groups with predefined representations to learn over geometric input data. We propose MatrixNet, a neural network architecture that learns matrix representations of group element inputs instead of using predefined representations. MatrixNet achieves higher sample efficiency and generalization over several standard baselines in prediction tasks over the several finite groups and the Artin braid group. We also show that MatrixNet respects group relations allowing generalization to group elements of greater word length than in the training set."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Sequential PatchCore: Anomaly Detection for Surface Inspection using Synthetic Impurities", "authors": "Runzhou Mao, Juraj Fulir, Christoph Garth, Petra Gospodneti\u0107", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR); Machine Learning (cs.LG)", "abstract": "The appearance of surface impurities (e.g., water stains, fingerprints, stickers) is an often-mentioned issue that causes degradation of automated visual inspection systems. At the same time, synthetic data generation techniques for visual surface inspection have focused primarily on generating perfect examples and defects, disregarding impurities. This study highlights the importance of considering impurities when generating synthetic data. We introduce a procedural method to include photorealistic water stains in synthetic data. The synthetic datasets are generated to correspond to real datasets and are further used to train an anomaly detection model and investigate the influence of water stains. The high-resolution images used for surface inspection lead to memory bottlenecks during anomaly detection training. To address this, we introduce Sequential PatchCore - a method to build coresets sequentially and make training on large images using consumer-grade hardware tractable. This allows us to perform transfer learning using coresets pre-trained on different dataset versions. Our results show the benefits of using synthetic data for pre-training an explicit coreset anomaly model and the extended performance benefits of finetuning the coreset using real data. We observed how the impurities and labelling ambiguity lower the model performance and have additionally reported the defect-wise recall to provide an industrially relevant perspective on model performance."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Atleus: Accelerating Transformers on the Edge Enabled by 3D Heterogeneous Manycore Architectures", "authors": "Pratyush Dhingra, Janardhan Rao Doppa, Partha Pratim Pande", "subjects": "Subjects:\nHardware Architecture (cs.AR); Machine Learning (cs.LG)", "abstract": "Transformer architectures have become the standard neural network model for various machine learning applications including natural language processing and computer vision. However, the compute and memory requirements introduced by transformer models make them challenging to adopt for edge applications. Furthermore, fine-tuning pre-trained transformers (e.g., foundation models) is a common task to enhance the model's predictive performance on specific tasks/applications. Existing transformer accelerators are oblivious to complexities introduced by fine-tuning. In this paper, we propose the design of a three-dimensional (3D) heterogeneous architecture referred to as Atleus that incorporates heterogeneous computing resources specifically optimized to accelerate transformer models for the dual purposes of fine-tuning and inference. Specifically, Atleus utilizes non-volatile memory and systolic array for accelerating transformer computational kernels using an integrated 3D platform. Moreover, we design a suitable NoC to achieve high performance and energy efficiency. Finally, Atleus adopts an effective quantization scheme to support model compression. Experimental results demonstrate that Atleus outperforms existing state-of-the-art by up to 56x and 64.5x in terms of performance and energy efficiency respectively"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Metrics for Inter-Dataset Similarity with Example Applications in Synthetic Data and Feature Selection Evaluation - Extended Version", "authors": "Muhammad Rajabinasab, Anton D. Lautrup, Arthur Zimek", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "Measuring inter-dataset similarity is an important task in machine learning and data mining with various use cases and applications. Existing methods for measuring inter-dataset similarity are computationally expensive, limited, or sensitive to different entities and non-trivial choices for parameters. They also lack a holistic perspective on the entire dataset. In this paper, we propose two novel metrics for measuring inter-dataset similarity. We discuss the mathematical foundation and the theoretical basis of our proposed metrics. We demonstrate the effectiveness of the proposed metrics by investigating two applications in the evaluation of synthetic data and in the evaluation of feature selection methods. The theoretical and empirical studies conducted in this paper illustrate the effectiveness of the proposed metrics."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Clinicians don't know what explanations they need: A case study on eliciting AI software explainability requirements", "authors": "Tor Sporsem, Stine Rasdal Finser\u00e5s, Inga Str\u00fcmke", "subjects": "Subjects:\nSoftware Engineering (cs.SE)", "abstract": "This paper analyses how software developers elicit explainability requirements when creating a software application with an AI component, through a case study using AI in the medical context of predicting cerebral palsy (CP) risk in infants. Following a small software development team at a Norwegian hospital, we observe their process of simultaneously developing the AI application and discovering what explanations clinicians require from the AI predictions. Since clinicians struggled to articulate their explainability needs before interacting with the system, an iterative approach proved effective: the team started with minimal explanations and refined these based on clinicians' responses during real patient examinations. Our preliminary findings from the first two iterations show that clinicians valued \"interrogative explanations\" - i.e., tools that let them explore and compare the AI predictions with their own assessments - over detailed technical explanations of the AI model's inner workings. Based on our analysis, we suggest that successful explainability requirements emerge through iterative collaboration between developers and users rather than being fully specified upfront. To the best of our knowledge, this is the first empirical case study on eliciting explainability requirements in software engineering."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          IFRA: a machine learning-based Instrumented Fall Risk Assessment Scale derived from Instrumented Timed Up and Go test in stroke patients", "authors": "Simone Macci\u00f2, Alessandro Carf\u00ec, Alessio Capitanelli, Peppino Tropea, Massimo Corbo, Fulvio Mastrogiovanni, Michela Picardi", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Effective fall risk assessment is critical for post-stroke patients. The present study proposes a novel, data-informed fall risk assessment method based on the instrumented Timed Up and Go (ITUG) test data, bringing in many mobility measures that traditional clinical scales fail to capture. IFRA, which stands for Instrumented Fall Risk Assessment, has been developed using a two-step process: first, features with the highest predictive power among those collected in a ITUG test have been identified using machine learning techniques; then, a strategy is proposed to stratify patients into low, medium, or high-risk strata. The dataset used in our analysis consists of 142 participants, out of which 93 were used for training (15 synthetically generated), 17 for validation and 32 to test the resulting IFRA scale (22 non-fallers and 10 fallers). Features considered in the IFRA scale include gait speed, vertical acceleration during sit-to-walk transition, and turning angular velocity, which align well with established literature on the risk of fall in neurological patients. In a comparison with traditional clinical scales such as the traditional Timed Up & Go and the Mini-BESTest, IFRA demonstrates competitive performance, being the only scale to correctly assign more than half of the fallers to the high-risk stratum (Fischer's Exact test p = 0.004). Despite the dataset's limited size, this is the first proof-of-concept study to pave the way for future evidence regarding the use of IFRA tool for continuous patient monitoring and fall prevention both in clinical stroke rehabilitation and at home post-discharge."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Reducing the Sensitivity of Neural Physics Simulators to Mesh Topology via Pretraining", "authors": "Nathan Vaska, Justin Goodwin, Robin Walters, Rajmonda S. Caceres", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Meshes are used to represent complex objects in high fidelity physics simulators across a variety of domains, such as radar sensing and aerodynamics. There is growing interest in using neural networks to accelerate physics simulations, and also a growing body of work on applying neural networks directly to irregular mesh data. Since multiple mesh topologies can represent the same object, mesh augmentation is typically required to handle topological variation when training neural networks. Due to the sensitivity of physics simulators to small changes in mesh shape, it is challenging to use these augmentations when training neural network-based physics simulators. In this work, we show that variations in mesh topology can significantly reduce the performance of neural network simulators. We evaluate whether pretraining can be used to address this issue, and find that employing an established autoencoder pretraining technique with graph embedding models reduces the sensitivity of neural network simulators to variations in mesh topology. Finally, we highlight future research directions that may further reduce neural simulator sensitivity to mesh topology."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Mesh2SLAM in VR: A Fast Geometry-Based SLAM Framework for Rapid Prototyping in Virtual Reality Applications", "authors": "Carlos Augusto Pinheiro de Sousa, Heiko Hamann, Oliver Deussen", "subjects": "Subjects:\nRobotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "SLAM is a foundational technique with broad applications in robotics and AR/VR. SLAM simulations evaluate new concepts, but testing on resource-constrained devices, such as VR HMDs, faces challenges: high computational cost and restricted sensor data access. This work proposes a sparse framework using mesh geometry projections as features, which improves efficiency and circumvents direct sensor data access, advancing SLAM research as we demonstrate in VR and through numerical evaluation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Anatomy of a Digital Bubble: Lessons Learned from the NFT and Metaverse Frenzy", "authors": "Daisuke Kawai, Kyle Soska, Bryan Routledge, Ariel Zetlin-Jones, Nicolas Christin", "subjects": "Subjects:\nComputers and Society (cs.CY)", "abstract": "In the past few years, \"metaverse\" and \"non-fungible tokens (NFT)\" have become buzzwords, and the prices of related assets have shown speculative bubble-like behavior. In this paper, we attempt to better understand the underlying economic dynamics. To do so, we look at Decentraland, a virtual world platform where land parcels are sold as NFT collections. We find that initially, land prices followed traditional real estate pricing models -- in particular, value decreased with distance from the most desirable areas -- suggesting Decentraland behaved much like a virtual city. However, these real estate pricing models stopped applying when both the metaverse and NFTs gained increased popular attention and enthusiasm in 2021, suggesting a new driving force for the underlying asset prices. At that time, following a substantial rise in NFT market values, short-term holders of multiple parcels began to take major selling positions in the Decentraland market, which hints that, rather than building a metaverse community, early Decentraland investors preferred to cash out when land valuations became overly inflated. Our analysis also shows that while the majority of buyers are new entrants to the market (many of whom joined during the bubble), liquidity (i.e., parcels) was mostly provided by early adopters selling, which caused stark differences in monetary gains. Early adopters made money -- more than 10,000 USD on average per parcel sold -- but users who joined later typically made no profit or even incurred losses in the order of 1,000 USD per parcel. Unlike established markets such as financial and real estate markets, newly emergent digital marketplaces are mostly self-regulated. As a result, the significant financial risks we identify indicate a strong need for establishing appropriate standards of business conduct and improving user awareness."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          From Scarcity to Capability: Empowering Fake News Detection in Low-Resource Languages with LLMs", "authors": "Hrithik Majumdar Shibu, Shrestha Datta, Md. Sumon Miah, Nasrullah Sami, Mahruba Sharmin Chowdhury, Md. Saiful Islam", "subjects": "Subjects:\nComputation and Language (cs.CL)", "abstract": "The rapid spread of fake news presents a significant global challenge, particularly in low-resource languages like Bangla, which lack adequate datasets and detection tools. Although manual fact-checking is accurate, it is expensive and slow to prevent the dissemination of fake news. Addressing this gap, we introduce BanFakeNews-2.0, a robust dataset to enhance Bangla fake news detection. This version includes 11,700 additional, meticulously curated fake news articles validated from credible sources, creating a proportional dataset of 47,000 authentic and 13,000 fake news items across 13 categories. In addition, we created a manually curated independent test set of 460 fake and 540 authentic news items for rigorous evaluation. We invest efforts in collecting fake news from credible sources and manually verified while preserving the linguistic richness. We develop a benchmark system utilizing transformer-based architectures, including fine-tuned Bidirectional Encoder Representations from Transformers variants (F1-87\\%) and Large Language Models with Quantized Low-Rank Approximation (F1-89\\%), that significantly outperforms traditional methods. BanFakeNews-2.0 offers a valuable resource to advance research and application in fake news detection for low-resourced languages. We publicly release our dataset and model on Github to foster research in this direction."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Managed-Retention Memory: A New Class of Memory for the AI Era", "authors": "Sergey Legtchenko, Ioan Stefanovici, Richard Black, Antony Rowstron, Junyi Liu, Paolo Costa, Burcu Canakci, Dushyanth Narayanan, Xingbo Wu", "subjects": "Subjects:\nHardware Architecture (cs.AR); Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Emerging Technologies (cs.ET)", "abstract": "AI clusters today are one of the major uses of High Bandwidth Memory (HBM). However, HBM is suboptimal for AI workloads for several reasons. Analysis shows HBM is overprovisioned on write performance, but underprovisioned on density and read bandwidth, and also has significant energy per bit overheads. It is also expensive, with lower yield than DRAM due to manufacturing complexity. We propose a new memory class: Managed-Retention Memory (MRM), which is more optimized to store key data structures for AI inference workloads. We believe that MRM may finally provide a path to viability for technologies that were originally proposed to support Storage Class Memory (SCM). These technologies traditionally offered long-term persistence (10+ years) but provided poor IO performance and/or endurance. MRM makes different trade-offs, and by understanding the workload IO patterns, MRM foregoes long-term data retention and write performance for better potential performance on the metrics important for these workloads."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Local US officials' views on the impacts and governance of AI: Evidence from 2022 and 2023 survey waves", "authors": "Sophia Hatz, Noemi Dreksler, Kevin Wei, Baobao Zhang", "subjects": "Subjects:\nComputers and Society (cs.CY)", "abstract": "This paper presents a survey of local US policymakers' views on the future impact and regulation of AI. Our survey provides insight into US policymakers' expectations regarding the effects of AI on local communities and the nation, as well as their attitudes towards specific regulatory policies. Conducted in two waves (2022 and 2023), the survey captures changes in attitudes following the release of ChatGPT and the subsequent surge in public awareness of AI. Local policymakers express a mix of concern, optimism, and uncertainty about AI's impacts, anticipating significant societal risks such as increased surveillance, misinformation, and political polarization, alongside potential benefits in innovation and infrastructure. Many also report feeling underprepared and inadequately informed to make AI-related decisions. On regulation, a majority of policymakers support government oversight and favor specific policies addressing issues such as data privacy, AI-related unemployment, and AI safety and fairness. Democrats show stronger and more consistent support for regulation than Republicans, but the latter experienced a notable shift towards majority support between 2022 and 2023. Our study contributes to understanding the perspectives of local policymakers-key players in shaping state and federal AI legislation-by capturing evolving attitudes, partisan dynamics, and their implications for policy formation. The findings highlight the need for capacity-building initiatives and bi-partisan coordination to mitigate policy fragmentation and build a cohesive framework for AI governance in the US."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A posteriori error estimates for the Lindblad master equation", "authors": "Paul-Louis Etienney, R\u00e9mi Robin, Pierre Rouchon", "subjects": "Subjects:\nNumerical Analysis (math.NA); Quantum Physics (quant-ph)", "abstract": "We are interested in the simulation of open quantum systems governed by the Lindblad master equation in an infinite-dimensional Hilbert space. To simulate the solution of this equation, the standard approach involves two sequential approximations: first, we truncate the Hilbert space to derive a differential equation in a finite-dimensional subspace. Then, we use discrete time-step to obtain a numerical solution to the finite-dimensional evolution. In this paper, we establish bounds for these two approximations that can be explicitely computed to guarantee the accuracy of the numerical results. Through numerical examples, we demonstrate the efficiency of our method, empirically highlighting the tightness of the upper bound. While adaptive time-stepping is already a common practice in the time discretization of the Lindblad equation, we extend this approach by showing how to dynamically adjust the truncation of the Hilbert space. This enables fully adaptive simulations of the density matrix. For large-scale simulations, this approach significantly reduces computational time and relieves users of the challenge of selecting an appropriate truncation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Metric Learning with Progressive Self-Distillation for Audio-Visual Embedding Learning", "authors": "Donghuo Zeng, Kazushi Ikeda", "subjects": "Subjects:\nSound (cs.SD); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Information Retrieval (cs.IR); Multimedia (cs.MM); Audio and Speech Processing (eess.AS)", "abstract": "Metric learning projects samples into an embedded space, where similarities and dissimilarities are quantified based on their learned representations. However, existing methods often rely on label-guided representation learning, where representations of different modalities, such as audio and visual data, are aligned based on annotated labels. This approach tends to underutilize latent complex features and potential relationships inherent in the distributions of audio and visual data that are not directly tied to the labels, resulting in suboptimal performance in audio-visual embedding learning. To address this issue, we propose a novel architecture that integrates cross-modal triplet loss with progressive self-distillation. Our method enhances representation learning by leveraging inherent distributions and dynamically refining soft audio-visual alignments -- probabilistic alignments between audio and visual data that capture the inherent relationships beyond explicit labels. Specifically, the model distills audio-visual distribution-based knowledge from annotated labels in a subset of each batch. This self-distilled knowledge is used t"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Adversarial-Ensemble Kolmogorov Arnold Networks for Enhancing Indoor Wi-Fi Positioning: A Defensive Approach Against Spoofing and Signal Manipulation Attacks", "authors": "Mitul Goswami, Romit Chatterjee, Somnath Mahato, Prasant Kumar Pattnaik", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "The research presents a study on enhancing the robustness of Wi-Fi-based indoor positioning systems against adversarial attacks. The goal is to improve the positioning accuracy and resilience of these systems under two attack scenarios: Wi-Fi Spoofing and Signal Strength Manipulation. Three models are developed and evaluated: a baseline model (M_Base), an adversarially trained robust model (M_Rob), and an ensemble model (M_Ens). All models utilize a Kolmogorov-Arnold Network (KAN) architecture. The robust model is trained with adversarially perturbed data, while the ensemble model combines predictions from both the base and robust models. Experimental results show that the robust model reduces positioning error by approximately 10% compared to the baseline, achieving 2.03 meters error under Wi-Fi spoofing and 2.00 meters under signal strength manipulation. The ensemble model further outperforms with errors of 2.01 meters and 1.975 meters for the respective attack types. This analysis highlights the effectiveness of adversarial training techniques in mitigating attack impacts. The findings underscore the importance of considering adversarial scenarios in developing indoor positioning systems, as improved resilience can significantly enhance the accuracy and reliability of such systems in mission-critical environments."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          EVaDE : Event-Based Variational Thompson Sampling for Model-Based Reinforcement Learning", "authors": "Siddharth Aravindan, Dixant Mittal, Wee Sun Lee", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "Posterior Sampling for Reinforcement Learning (PSRL) is a well-known algorithm that augments model-based reinforcement learning (MBRL) algorithms with Thompson sampling. PSRL maintains posterior distributions of the environment transition dynamics and the reward function, which are intractable for tasks with high-dimensional state and action spaces. Recent works show that dropout, used in conjunction with neural networks, induces variational distributions that can approximate these posteriors. In this paper, we propose Event-based Variational Distributions for Exploration (EVaDE), which are variational distributions that are useful for MBRL, especially when the underlying domain is object-based. We leverage the general domain knowledge of object-based domains to design three types of event-based convolutional layers to direct exploration. These layers rely on Gaussian dropouts and are inserted between the layers of the deep neural network model to help facilitate variational Thompson sampling. We empirically show the effectiveness of EVaDE-equipped Simulated Policy Learning (EVaDE-SimPLe) on the 100K Atari game suite."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          ARMAX identification of low rank graphical models", "authors": "Wenqi Cao, Aming Li", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "In large-scale systems, complex internal relationships are often present. Such interconnected systems can be effectively described by low rank stochastic processes. When identifying a predictive model of low rank processes from sampling data, the rank-deficient property of spectral densities is often obscured by the inevitable measurement noise in practice. However, existing low rank identification approaches often did not take noise into explicit consideration, leading to non-negligible inaccuracies even under weak noise. In this paper, we address the identification issue of low rank processes under measurement noise. We find that the noisy measurement model admits a sparse plus low rank structure in latent-variable graphical models. Specifically, we first decompose the problem into a maximum entropy covariance extension problem, and a low rank graphical estimation problem based on an autoregressive moving-average with exogenous input (ARMAX) model. To identify the ARMAX low rank graphical models, we propose an estimation approach based on maximum likelihood. The identifiability and consistency of this approach are proven under certain conditions. Simulation results confirm the reliable performance of the entire algorithm in both the parameter estimation and noisy data filtering."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          WMamba: Wavelet-based Mamba for Face Forgery Detection", "authors": "Siran Peng, Tianshuo Zhang, Li Gao, Xiangyu Zhu, Haoyuan Zhang, Kai Pang, Zhen Lei", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "With the rapid advancement of deepfake generation technologies, the demand for robust and accurate face forgery detection algorithms has become increasingly critical. Recent studies have demonstrated that wavelet analysis can uncover subtle forgery artifacts that remain imperceptible in the spatial domain. Wavelets effectively capture important facial contours, which are often slender, fine-grained, and global in nature. However, existing wavelet-based approaches fail to fully leverage these unique characteristics, resulting in sub-optimal feature extraction and limited generalizability. To address this challenge, we introduce WMamba, a novel wavelet-based feature extractor built upon the Mamba architecture. WMamba maximizes the utility of wavelet information through two key innovations. First, we propose Dynamic Contour Convolution (DCConv), which employs specially crafted deformable kernels to adaptively model slender facial contours. Second, by leveraging the Mamba architecture, our method captures long-range spatial relationships with linear computational complexity. This efficiency allows for the extraction of fine-grained, global forgery artifacts from small image patches. Extensive experimental results show that WMamba achieves state-of-the-art (SOTA) performance, highlighting its effectiveness and superiority in face forgery detection."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Beyond Reward Hacking: Causal Rewards for Large Language Model Alignment", "authors": "Chaoqi Wang, Zhuokai Zhao, Yibo Jiang, Zhaorun Chen, Chen Zhu, Yuxin Chen, Jiayi Liu, Lizhu Zhang, Xiangjun Fan, Hao Ma, Sinong Wang", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Recent advances in large language models (LLMs) have demonstrated significant progress in performing complex tasks. While Reinforcement Learning from Human Feedback (RLHF) has been effective in aligning LLMs with human preferences, it is susceptible to spurious correlations in reward modeling. Consequently, it often introduces biases-such as length bias, sycophancy, conceptual bias, and discrimination that hinder the model's ability to capture true causal relationships. To address this, we propose a novel causal reward modeling approach that integrates causal inference to mitigate these spurious correlations. Our method enforces counterfactual invariance, ensuring reward predictions remain consistent when irrelevant variables are altered. Through experiments on both synthetic and real-world datasets, we show that our approach mitigates various types of spurious correlations effectively, resulting in more reliable and fair alignment of LLMs with human preferences. As a drop-in enhancement to the existing RLHF workflow, our causal reward modeling provides a practical way to improve the trustworthiness and fairness of LLM finetuning."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Weight for Robustness: A Comprehensive Approach towards Optimal Fault-Tolerant Asynchronous ML", "authors": "Tehila Dahan, Kfir Y. Levy", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "We address the challenges of Byzantine-robust training in asynchronous distributed machine learning systems, aiming to enhance efficiency amid massive parallelization and heterogeneous computing resources. Asynchronous systems, marked by independently operating workers and intermittent updates, uniquely struggle with maintaining integrity against Byzantine failures, which encompass malicious or erroneous actions that disrupt learning. The inherent delays in such settings not only introduce additional bias to the system but also obscure the disruptions caused by Byzantine faults. To tackle these issues, we adapt the Byzantine framework to asynchronous dynamics by introducing a novel weighted robust aggregation framework. This allows for the extension of robust aggregators and a recent meta-aggregator to their weighted versions, mitigating the effects of delayed updates. By further incorporating a recent variance-reduction technique, we achieve an optimal convergence rate for the first time in an asynchronous Byzantine environment. Our methodology is rigorously validated through empirical and theoretical analysis, demonstrating its effectiveness in enhancing fault tolerance and optimizing performance in asynchronous ML systems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Artificial Intelligence-Driven Clinical Decision Support Systems", "authors": "Muhammet Alkan, Idris Zakariyya, Samuel Leighton, Kaushik Bhargav Sivangi, Christos Anagnostopoulos, Fani Deligianni", "subjects": "Subjects:\nArtificial Intelligence (cs.AI)", "abstract": "As artificial intelligence (AI) becomes increasingly embedded in healthcare delivery, this chapter explores the critical aspects of developing reliable and ethical Clinical Decision Support Systems (CDSS). Beginning with the fundamental transition from traditional statistical models to sophisticated machine learning approaches, this work examines rigorous validation strategies and performance assessment methods, including the crucial role of model calibration and decision curve analysis. The chapter emphasizes that creating trustworthy AI systems in healthcare requires more than just technical accuracy; it demands careful consideration of fairness, explainability, and privacy. The challenge of ensuring equitable healthcare delivery through AI is stressed, discussing methods to identify and mitigate bias in clinical predictive models. The chapter then delves into explainability as a cornerstone of human-centered CDSS. This focus reflects the understanding that healthcare professionals must not only trust AI recommendations but also comprehend their underlying reasoning. The discussion advances in an analysis of privacy vulnerabilities in medical AI systems, from data leakage in deep learning models to sophisticated attacks against model explanations. The text explores privacy-preservation strategies such as differential privacy and federated learning, while acknowledging the inherent trade-offs between privacy protection and model performance. This progression, from technical validation to ethical considerations, reflects the multifaceted challenges of developing AI systems that can be seamlessly and reliably integrated into daily clinical practice while maintaining the highest standards of patient care and data protection."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Empowering Large Language Models in Wireless Communication: A Novel Dataset and Fine-Tuning Framework", "authors": "Yushen Lin, Ruichen Zhang, Wenqi Huang, Kaidi Wang, Zhiguo Ding, Daniel K. C. So, Dusit Niyato", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "In this work, we develop a specialized dataset aimed at enhancing the evaluation and fine-tuning of large language models (LLMs) specifically for wireless communication applications. The dataset includes a diverse set of multi-hop questions, including true/false and multiple-choice types, spanning varying difficulty levels from easy to hard. By utilizing advanced language models for entity extraction and question generation, rigorous data curation processes are employed to maintain high quality and relevance. Additionally, we introduce a Pointwise V-Information (PVI) based fine-tuning method, providing a detailed theoretical analysis and justification for its use in quantifying the information content of training data with 2.24\\% and 1.31\\% performance boost for different models compared to baselines, respectively. To demonstrate the effectiveness of the fine-tuned models with the proposed methodologies on practical tasks, we also consider different tasks, including summarizing optimization problems from technical papers and solving the mathematical problems related to non-orthogonal multiple access (NOMA), which are generated by using the proposed multi-agent framework. Simulation results show significant performance gain in summarization tasks with 20.9\\% in the ROUGE-L metrics. We also study the scaling laws of fine-tuning LLMs and the challenges LLMs face in the field of wireless communications, offering insights into their adaptation to wireless communication tasks. This dataset and fine-tuning methodology aim to enhance the training and evaluation of LLMs, contributing to advancements in LLMs for wireless communication research and applications."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Platform-Aware Mission Planning", "authors": "Stefan Panjkovic, Alessandro Cimatti, Andrea Micheli, Stefano Tonetta", "subjects": "Subjects:\nArtificial Intelligence (cs.AI)", "abstract": "Planning for autonomous systems typically requires reasoning with models at different levels of abstraction, and the harmonization of two competing sets of objectives: high-level mission goals that refer to an interaction of the system with the external environment, and low-level platform constraints that aim to preserve the integrity and the correct interaction of the subsystems. The complicated interplay between these two models makes it very hard to reason on the system as a whole, especially when the objective is to find plans with robustness guarantees, considering the non-deterministic behavior of the lower layers of the system. In this paper, we introduce the problem of Platform-Aware Mission Planning (PAMP), addressing it in the setting of temporal durative actions. The PAMP problem differs from standard temporal planning for its exists-forall nature: the high-level plan dealing with mission goals is required to satisfy safety and executability constraints, for all the possible non-deterministic executions of the low-level model of the platform and the environment. We propose two approaches for solving PAMP. The first baseline approach amalgamates the mission and platform levels, while the second is based on an abstraction-refinement loop that leverages the combination of a planner and a verification engine. We prove the soundness and completeness of the proposed approaches and validate them experimentally, demonstrating the importance of heterogeneous modeling and the superiority of the technique based on abstraction-refinement."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Convergence Analysis for Nonlinear GMRES", "authors": "Yunhui He", "subjects": "Subjects:\nNumerical Analysis (math.NA)", "abstract": "In this work, we revisit nonlinear generalized minimal residual method (NGMRES) applied to nonlinear problems. NGMRES is used to accelerate the convergence of fixed-point iterations, which can substantially improve the performance of the underlying fixed-point iterations. We consider NGMRES with a finite window size $m$, denoted as NGMRES($m$). However, there is no convergence analysis for NGMRES($m$) applied to nonlinear systems. We prove that for general $m>0$, the residuals of NGMRES($m$) converge r-linearly under some conditions. For $m=0$, we prove that the residuals of NGMRES(0) converge q-linearly."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Unified Face Matching and Physical-Digital Spoofing Attack Detection", "authors": "Arun Kunwar, Ajita Rattani", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Face recognition technology has dramatically transformed the landscape of security, surveillance, and authentication systems, offering a user-friendly and non-invasive biometric solution. However, despite its significant advantages, face recognition systems face increasing threats from physical and digital spoofing attacks. Current research typically treats face recognition and attack detection as distinct classification challenges. This approach necessitates the implementation of separate models for each task, leading to considerable computational complexity, particularly on devices with limited resources. Such inefficiencies can stifle scalability and hinder performance. In response to these challenges, this paper introduces an innovative unified model designed for face recognition and detection of physical and digital attacks. By leveraging the advanced Swin Transformer backbone and incorporating HiLo attention in a convolutional neural network framework, we address unified face recognition and spoof attack detection more effectively. Moreover, we introduce augmentation techniques that replicate the traits of physical and digital spoofing cues, significantly enhancing our model robustness. Through comprehensive experimental evaluation across various datasets, we showcase the effectiveness of our model in unified face recognition and spoof detection. Additionally, we confirm its resilience against unseen physical and digital spoofing attacks, underscoring its potential for real-world applications."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          LLM-Based Routing in Mixture of Experts: A Novel Framework for Trading", "authors": "Kuan-Ming Liu (1), Ming-Chih Lo (2) ((1) National Chengchi University, College of Commerce, (2) National Yang Ming Chiao Tung University, College of Computer Science)", "subjects": "Subjects:\nMachine Learning (cs.LG); Trading and Market Microstructure (q-fin.TR)", "abstract": "Recent advances in deep learning and large language models (LLMs) have facilitated the deployment of the mixture-of-experts (MoE) mechanism in the stock investment domain. While these models have demonstrated promising trading performance, they are often unimodal, neglecting the wealth of information available in other modalities, such as textual data. Moreover, the traditional neural network-based router selection mechanism fails to consider contextual and real-world nuances, resulting in suboptimal expert selection. To address these limitations, we propose LLMoE, a novel framework that employs LLMs as the router within the MoE architecture. Specifically, we replace the conventional neural network-based router with LLMs, leveraging their extensive world knowledge and reasoning capabilities to select experts based on historical price data and stock news. This approach provides a more effective and interpretable selection mechanism. Our experiments on multimodal real-world stock datasets demonstrate that LLMoE outperforms state-of-the-art MoE models and other deep neural network approaches. Additionally, the flexible architecture of LLMoE allows for easy adaptation to various downstream tasks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Electronic Health Records: Towards Digital Twins in Healthcare", "authors": "Muhammet Alkan, Hester Huijsdens, Yola Jones, Fani Deligianni", "subjects": "Subjects:\nArtificial Intelligence (cs.AI)", "abstract": "The pivotal shift from traditional paper-based records to sophisticated Electronic Health Records (EHR), enabled systematic collection and analysis of patient data through descriptive statistics, providing insight into patterns and trends across patient populations. This evolution continued toward predictive analytics, allowing healthcare providers to anticipate patient outcomes and potential complications before they occur. This progression from basic digital record-keeping to sophisticated predictive modelling and digital twins reflects healthcare's broader evolution toward more integrated, patient-centred approaches that combine data-driven insights with personalized care delivery. This chapter explores the evolution and significance of healthcare information systems, beginning with an examination of the implementation of EHR in the UK and the USA. It provides a comprehensive overview of the International Classification of Diseases (ICD) system, tracing its development from ICD-9 to ICD-10. Central to this discussion is the MIMIC-III database, a landmark achievement in healthcare data sharing and arguably the most comprehensive critical care database freely available to researchers worldwide. MIMIC-III has democratized access to high-quality healthcare data, enabling unprecedented opportunities for research and analysis. The chapter examines its structure, clinical outcome analysis capabilities, and practical applications through case studies, with a particular focus on mortality and length of stay metrics, vital signs extraction, and ICD coding. Through detailed entity-relationship diagrams and practical examples, the text illustrates MIMIC's complex data structure and demonstrates how different querying approaches can lead to subtly different results, emphasizing the critical importance of understanding the database's architecture for accurate data extraction."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          CarMem: Enhancing Long-Term Memory in LLM Voice Assistants through Category-Bounding", "authors": "Johannes Kirmayr, Lukas Stappen, Phillip Schneider, Florian Matthes, Elisabeth Andr\u00e9", "subjects": "Subjects:\nArtificial Intelligence (cs.AI); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)", "abstract": "In today's assistant landscape, personalisation enhances interactions, fosters long-term relationships, and deepens engagement. However, many systems struggle with retaining user preferences, leading to repetitive user requests and disengagement. Furthermore, the unregulated and opaque extraction of user preferences in industry applications raises significant concerns about privacy and trust, especially in regions with stringent regulations like Europe. In response to these challenges, we propose a long-term memory system for voice assistants, structured around predefined categories. This approach leverages Large Language Models to efficiently extract, store, and retrieve preferences within these categories, ensuring both personalisation and transparency. We also introduce a synthetic multi-turn, multi-session conversation dataset (CarMem), grounded in real industry data, tailored to an in-car voice assistant setting. Benchmarked on the dataset, our system achieves an F1-score of .78 to .95 in preference extraction, depending on category granularity. Our maintenance strategy reduces redundant preferences by 95% and contradictory ones by 92%, while the accuracy of optimal retrieval is at .87. Collectively, the results demonstrate the system's suitability for industrial applications."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          NS-Gym: Open-Source Simulation Environments and Benchmarks for Non-Stationary Markov Decision Processes", "authors": "Nathaniel S. Keplinger, Baiting Luo, Iliyas Bektas, Yunuo Zhang, Kyle Hollins Wray, Aron Laszka, Abhishek Dubey, Ayan Mukhopadhyay", "subjects": "Subjects:\nArtificial Intelligence (cs.AI)", "abstract": "In many real-world applications, agents must make sequential decisions in environments where conditions are subject to change due to various exogenous factors. These non-stationary environments pose significant challenges to traditional decision-making models, which typically assume stationary dynamics. Non-stationary Markov decision processes (NS-MDPs) offer a framework to model and solve decision problems under such changing conditions. However, the lack of standardized benchmarks and simulation tools has hindered systematic evaluation and advance in this field. We present NS-Gym, the first simulation toolkit designed explicitly for NS-MDPs, integrated within the popular Gymnasium framework. In NS-Gym, we segregate the evolution of the environmental parameters that characterize non-stationarity from the agent's decision-making module, allowing for modular and flexible adaptations to dynamic environments. We review prior work in this domain and present a toolkit encapsulating key problem characteristics and types in NS-MDPs. This toolkit is the first effort to develop a set of standardized interfaces and benchmark problems to enable consistent and reproducible evaluation of algorithms under non-stationary conditions. We also benchmark six algorithmic approaches from prior work on NS-MDPs using NS-Gym. Our vision is that NS-Gym will enable researchers to assess the adaptability and robustness of their decision-making algorithms to non-stationary conditions."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Monte Carlo Tree Search with Velocity Obstacles for safe and efficient motion planning in dynamic environments", "authors": "Lorenzo Bonanni, Daniele Meli, Alberto Castellini, Alessandro Farinelli", "subjects": "Subjects:\nArtificial Intelligence (cs.AI); Robotics (cs.RO)", "abstract": "Online motion planning is a challenging problem for intelligent robots moving in dense environments with dynamic obstacles, e.g., crowds. In this work, we propose a novel approach for optimal and safe online motion planning with minimal information about dynamic obstacles. Specifically, our approach requires only the current position of the obstacles and their maximum speed, but it does not need any information about their exact trajectories or dynamic model. The proposed methodology combines Monte Carlo Tree Search (MCTS), for online optimal planning via model simulations, with Velocity Obstacles (VO), for obstacle avoidance. We perform experiments in a cluttered simulated environment with walls, and up to 40 dynamic obstacles moving with random velocities and directions. With an ablation study, we show the key contribution of VO in scaling up the efficiency of MCTS, selecting the safest and most rewarding actions in the tree of simulations. Moreover, we show the superiority of our methodology with respect to state-of-the-art planners, including Non-linear Model Predictive Control (NMPC), in terms of improved collision rate, computational and task performance."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          The Heap: A Contamination-Free Multilingual Code Dataset for Evaluating Large Language Models", "authors": "Jonathan Katzy, Razvan Mihai Popescu, Arie van Deursen, Maliheh Izadi", "subjects": "Subjects:\nComputation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "The recent rise in the popularity of large language models has spurred the development of extensive code datasets needed to train them. This has left limited code available for collection and use in the downstream investigation of specific behaviors, or evaluation of large language models without suffering from data contamination. To address this problem, we release The Heap, a large multilingual dataset covering 57 programming languages that has been deduplicated with respect to other open datasets of code, enabling researchers to conduct fair evaluations of large language models without significant data cleaning overhead."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Survey of Research in Large Language Models for Electronic Design Automation", "authors": "Jingyu Pan, Guanglei Zhou, Chen-Chia Chang, Isaac Jacobson, Jiang Hu, Yiran Chen", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "Within the rapidly evolving domain of Electronic Design Automation (EDA), Large Language Models (LLMs) have emerged as transformative technologies, offering unprecedented capabilities for optimizing and automating various aspects of electronic design. This survey provides a comprehensive exploration of LLM applications in EDA, focusing on advancements in model architectures, the implications of varying model sizes, and innovative customization techniques that enable tailored analytical insights. By examining the intersection of LLM capabilities and EDA requirements, the paper highlights the significant impact these models have on extracting nuanced understandings from complex datasets. Furthermore, it addresses the challenges and opportunities in integrating LLMs into EDA workflows, paving the way for future research and application in this dynamic field. Through this detailed analysis, the survey aims to offer valuable insights to professionals in the EDA industry, AI researchers, and anyone interested in the convergence of advanced AI technologies and electronic design."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          On the Energy Consumption of Test Generation", "authors": "Fitsum Kifetew, Davide Prandi, Angelo Susi", "subjects": "Subjects:\nSoftware Engineering (cs.SE)", "abstract": "Research in the area of automated test generation has seen remarkable progress in recent years, resulting in several approaches and tools for effective and efficient generation of test cases. In particular, the EvoSuite tool has been at the forefront of this progress embodying various algorithms for automated test generation of Java programs. EvoSuite has been used to generate test cases for a wide variety of programs as well. While there are a number of empirical studies that report results on the effectiveness, in terms of code coverage and other related metrics, of the various test generation strategies and algorithms implemented in EvoSuite, there are no studies, to the best of our knowledge, on the energy consumption associated to the automated test generation. In this paper, we set out to investigate this aspect by measuring the energy consumed by EvoSuite when generating tests. We also measure the energy consumed in the execution of the test cases generated, comparing them with those manually written by developers. The results show that the different test generation algorithms consumed different amounts of energy, in particular on classes with high cyclomatic complexity. Furthermore, we also observe that manual tests tend to consume more energy as compared to automatically generated tests, without necessarily achieving higher code coverage. Our results also give insight into the methods that consume significantly higher levels of energy, indicating potential points of improvement both for EvoSuite as well as the different programs under test."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Fokker-Planck to Callan-Symanzik: evolution of weight matrices under training", "authors": "Wei Bu, Uri Kol, Ziming Liu", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "The dynamical evolution of a neural network during training has been an incredibly fascinating subject of study. First principal derivation of generic evolution of variables in statistical physics systems has proved useful when used to describe training dynamics conceptually, which in practice means numerically solving equations such as Fokker-Planck equation. Simulating entire networks inevitably runs into the curse of dimensionality. In this paper, we utilize Fokker-Planck to simulate the probability density evolution of individual weight matrices in the bottleneck layers of a simple 2-bottleneck-layered auto-encoder and compare the theoretical evolutions against the empirical ones by examining the output data distributions. We also derive physically relevant partial differential equations such as Callan-Symanzik and Kardar-Parisi-Zhang equations from the dynamical equation we have."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Design-Agnostic Distributed Timing Fault Injection Monitor With End-to-End Design Automation", "authors": "Yan He, Yumin Su, Kaiyuan Yang", "subjects": "Subjects:\nSystems and Control (eess.SY)", "abstract": "Fault injection attacks induce hardware failures in circuits and exploit these faults to compromise the security of the system. It has been demonstrated that FIAs can bypass system security mechanisms, cause faulty outputs, and gain access to secret information. Certain types of FIAs can be mounted with little effort by tampering with clock signals and or the chip operating conditions. To mitigate such low cost, yet powerful attacks, we propose a fully synthesizable and distributable in situ fault injection monitor that employs a delay locked loop to track the pulsewidth of the clock. We further develop a fully automated design framework to optimize and implement the FIA monitors at any process node. Our design is fabricated and verified in 65 nm CMOS technology with a small footprint of 1500 um2. It can lock to clock frequencies from 2 MHz to 1.26 GHz while detecting all 12 types of possible clock glitches, as well as timing FIA injections via the supply voltage, electromagnetic signals, and chip temperature."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Evaluating the diversity of scientific discourse on twenty-one multilingual Wikipedias using citation analysis", "authors": "Michael Taylor, Roisi Proven, Carlos Areia", "subjects": "Subjects:\nDigital Libraries (cs.DL)", "abstract": "INTRODUCTION: Wikipedia is a major source of information, particularly for medical and health content, citing over 4 million scholarly publications. However, the representation of research-based knowledge across different languages on Wikipedia has been under explored. This study analyses the largest database of Wikipedia citations collected to date, examining the uniqueness of content and research representation across languages. METHOD: The study included nearly 3.5 million unique research articles and their Wikipedia mentions from 21 languages. These were categorized into three groups: Group A (publications uniquely cited by a single non-English Wikipedia), Group B (co-cited by English and non-English Wikipedias), and Group C (co-cited by multiple non-English Wikipedias). Descriptive and comparative statistics were conducted by Wikipedia language, group, and discipline. RESULTS: Significant differences were found between twenty non-English languages and English Wikipedia (p<0.001). While English Wikipedia is the largest, non-English Wikipedias cite an additional 1.5 million publications. CONCLUSION: English Wikipedia should not be seen as a comprehensive body of information. Non-English Wikipedias cover unique subjects and disciplines, offering a more complete representation of research collectively. The uniqueness of voice in non-English Wikipedias correlates with their size, though other factors may also influence these differences."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Unitary Expressions: A Necessary Abstraction for Extensible Quantum Programming Languages and Systems", "authors": "Ed Younis", "subjects": "Subjects:\nProgramming Languages (cs.PL); Quantum Physics (quant-ph)", "abstract": "Quantum gates are the fundamental instructions of digital quantum computers. Current programming languages, systems, and software development toolkits identify these operational gates by their titles, which requires a shared understanding of their meanings. However, in the continuously developing software ecosystem surrounding quantum computing -- spanning high-level programming systems to low-level control stacks -- this identification process is often error-prone, challenging to debug, maintenance-heavy, and resistant to change. In this paper, we propose replacing this nominal gate representation with a functional one. We introduce the OpenQudit system for describing, parsing, optimizing, analyzing, and utilizing programs comprising gates described as symbolic unitary expressions. As part of this effort, we design the Qudit Gate Language (QGL), a unitary-specific expression language, and implement a differentiating just-in-time compiler in OpenQudit towards embedding this language in quantum programming languages and systems. Additionally, we have precisely designed and implemented the Qudit Virtual Machine (QVM) to evaluate quantum programs and their gradients efficiently. This evaluation is performed millions of times during the compilation of quantum programs. Our QVM can compute gradients approximately ten times faster than current leading numerical quantum compilation frameworks in the most common use cases. Altogether, the OpenQudit system is envisioned to (1) support many-level or qudit-based quantum systems, (2) enable the safe composition of program transformation tools, (3) accelerate circuit optimizers and transpilers, (4) enable compiler extensibility, and (5) provide a productive, simple-to-use interface to quantum practitioners."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Model Predictive Path Integral Docking of Fully Actuated Surface Vessel", "authors": "Akash Vijayakumar, Atmanand M A, Abhilash Somayajula", "subjects": "Subjects:\nRobotics (cs.RO)", "abstract": "Autonomous docking remains one of the most challenging maneuvers in marine robotics, requiring precise control and robust perception in confined spaces. This paper presents a novel approach integrating Model Predictive Path Integral(MPPI) control with real-time LiDAR-based dock detection for autonomous surface vessel docking. Our framework uniquely combines probabilistic trajectory optimization with a multiobjective cost function that simultaneously considers docking precision, safety constraints, and motion efficiency. The MPPI controller generates optimal trajectories by intelligently sampling control sequences and evaluating their costs based on dynamic clearance requirements, orientation alignment, and target position objectives. We introduce an adaptive dock detection pipeline that processes LiDAR point clouds to extract critical geometric features, enabling real-time updates of docking parameters. The proposed method is extensively validated in a physics-based simulation environment that incorporates realistic sensor noise, vessel dynamics, and environmental constraints. Results demonstrate successful docking from various initial positions while maintaining safe clearances and smooth motion characteristics."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Robin: a Suite of Multi-Scale Vision-Language Models and the CHIRP Evaluation Benchmark", "authors": "Alexis Roger, Prateek Humane, Daniel Z. Kaplan, Kshitij Gupta, Qi Sun, George Adamopoulos, Jonathan Siu Chi Lim, Quentin Anthony, Edwin Fennell, Irina Rish", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "The proliferation of Vision-Language Models (VLMs) in the past several years calls for rigorous and comprehensive evaluation methods and benchmarks. This work analyzes existing VLM evaluation techniques, including automated metrics, AI-based assessments, and human evaluations across diverse tasks. We first introduce Robin - a novel suite of VLMs that we built by combining Large Language Models (LLMs) and Vision Encoders (VEs) at multiple scales, and use Robin to identify shortcomings of current evaluation approaches across scales. Next, to overcome the identified limitations, we introduce CHIRP - a new long form response benchmark we developed for more robust and complete VLM evaluation. We provide open access to the Robin training code, model suite, and CHIRP benchmark to promote reproducibility and advance VLM research."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Authenticated Delegation and Authorized AI Agents", "authors": "Tobin South, Samuele Marro, Thomas Hardjono, Robert Mahari, Cedric Deslandes Whitney, Dazza Greenwood, Alan Chan, Alex Pentland", "subjects": "Subjects:\nComputers and Society (cs.CY); Artificial Intelligence (cs.AI); Networking and Internet Architecture (cs.NI)", "abstract": "The rapid deployment of autonomous AI agents creates urgent challenges around authorization, accountability, and access control in digital spaces. New standards are needed to know whom AI agents act on behalf of and guide their use appropriately, protecting online spaces while unlocking the value of task delegation to autonomous agents. We introduce a novel framework for authenticated, authorized, and auditable delegation of authority to AI agents, where human users can securely delegate and restrict the permissions and scope of agents while maintaining clear chains of accountability. This framework builds on existing identification and access management protocols, extending OAuth 2.0 and OpenID Connect with agent-specific credentials and metadata, maintaining compatibility with established authentication and web infrastructure. Further, we propose a framework for translating flexible, natural language permissions into auditable access control configurations, enabling robust scoping of AI agent capabilities across diverse interaction modalities. Taken together, this practical approach facilitates immediate deployment of AI agents while addressing key security and accountability concerns, working toward ensuring agentic AI systems perform only appropriate actions and providing a tool for digital service providers to enable AI agent interactions without risking harm from scalable interaction."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          CoNav Chair: Design of a ROS-based Smart Wheelchair for Shared Control Navigation in the Built Environment", "authors": "Yifan Xu, Qianwei Wang, Jordan Lillie, Vineet Kamat, Carol Menassa", "subjects": "Subjects:\nRobotics (cs.RO)", "abstract": "With the number of people with disabilities (PWD) increasing worldwide each year, the demand for mobility support to enable independent living and social integration is also growing. Wheelchairs commonly support the mobility of PWD in both indoor and outdoor environments. However, current powered wheelchairs (PWC) often fail to meet the needs of PWD, who may find it difficult to operate them. Furthermore, existing research on robotic wheelchairs typically focuses either on full autonomy or enhanced manual control, which can lead to reduced efficiency and user trust. To address these issues, this paper proposes a Robot Operating System (ROS)-based smart wheelchair, called CoNav Chair, that incorporates a shared control navigation algorithm and obstacle avoidance to support PWD while fostering efficiency and trust between the robot and the user. Our design consists of hardware and software components. Experimental results conducted in a typical indoor social environment demonstrate the performance and effectiveness of the smart wheelchair hardware and software design. This integrated design promotes trust and autonomy, which are crucial for the acceptance of assistive mobility technologies in the built environment."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Reward-Guided Controlled Generation for Inference-Time Alignment in Diffusion Models: Tutorial and Review", "authors": "Masatoshi Uehara, Yulai Zhao, Chenyu Wang, Xiner Li, Aviv Regev, Sergey Levine, Tommaso Biancalani", "subjects": "Subjects:\nArtificial Intelligence (cs.AI); Machine Learning (cs.LG); Quantitative Methods (q-bio.QM); Machine Learning (stat.ML)", "abstract": "This tutorial provides an in-depth guide on inference-time guidance and alignment methods for optimizing downstream reward functions in diffusion models. While diffusion models are renowned for their generative modeling capabilities, practical applications in fields such as biology often require sample generation that maximizes specific metrics (e.g., stability, affinity in proteins, closeness to target structures). In these scenarios, diffusion models can be adapted not only to generate realistic samples but also to explicitly maximize desired measures at inference time without fine-tuning. This tutorial explores the foundational aspects of such inference-time algorithms. We review these methods from a unified perspective, demonstrating that current techniques- such as Sequential Monte Carlo (SMC)-based guidance, value-based sampling, and classifier guidance- aim to approximate soft optimal denoising processes (a.k.a. policies in RL) that combine pre-trained denoising processes with value functions serving as look-ahead functions that predict from intermediate states to terminal rewards. Within this framework, we present several novel algorithms not yet covered in the literature. Furthermore, we discuss (1) fine-tuning methods combined with inference-time techniques, (2) inference-time algorithms based on search algorithms such as Monte Carlo tree search, which have received limited attention in current research, and (3) connections between inference-time algorithms in language models and diffusion models. The code of this tutorial on protein design is available at this https URL"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Towards Large Reasoning Models: A Survey of Reinforced Reasoning with Large Language Models", "authors": "Fengli Xu, Qianyue Hao, Zefang Zong, Jingwei Wang, Yunke Zhang, Jingyi Wang, Xiaochong Lan, Jiahui Gong, Tianjian Ouyang, Fanjin Meng, Chenyang Shao, Yuwei Yan, Qinglong Yang, Yiwen Song, Sijian Ren, Xinyuan Hu, Yu Li, Jie Feng, Chen Gao, Yong Li", "subjects": "Subjects:\nArtificial Intelligence (cs.AI); Computation and Language (cs.CL)", "abstract": "Language has long been conceived as an essential tool for human reasoning. The breakthrough of Large Language Models (LLMs) has sparked significant research interest in leveraging these models to tackle complex reasoning tasks. Researchers have moved beyond simple autoregressive token generation by introducing the concept of \"thought\" -- a sequence of tokens representing intermediate steps in the reasoning process. This innovative paradigm enables LLMs' to mimic complex human reasoning processes, such as tree search and reflective thinking. Recently, an emerging trend of learning to reason has applied reinforcement learning (RL) to train LLMs to master reasoning processes. This approach enables the automatic generation of high-quality reasoning trajectories through trial-and-error search algorithms, significantly expanding LLMs' reasoning capacity by providing substantially more training data. Furthermore, recent studies demonstrate that encouraging LLMs to \"think\" with more tokens during test-time inference can further significantly boost reasoning accuracy. Therefore, the train-time and test-time scaling combined to show a new research frontier -- a path toward Large Reasoning Model. The introduction of OpenAI's o1 series marks a significant milestone in this research direction. In this survey, we present a comprehensive review of recent progress in LLM reasoning. We begin by introducing the foundational background of LLMs and then explore the key technical components driving the development of large reasoning models, with a focus on automated data construction, learning-to-reason techniques, and test-time scaling. We also analyze popular open-source projects at building large reasoning models, and conclude with open challenges and future research directions."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          U-Fair: Uncertainty-based Multimodal Multitask Learning for Fairer Depression Detection", "authors": "Jiaee Cheong, Aditya Bangar, Sinan Kalkan, Hatice Gunes", "subjects": "Subjects:\nMachine Learning (cs.LG)", "abstract": "Machine learning bias in mental health is becoming an increasingly pertinent challenge. Despite promising efforts indicating that multitask approaches often work better than unitask approaches, there is minimal work investigat- ing the impact of multitask learning on performance and fairness in depression detection nor leveraged it to achieve fairer prediction outcomes. In this work, we undertake a systematic investigation of using a multitask approach to improve performance and fairness for depression detection. We propose a novel gender-based task-reweighting method using uncertainty grounded in how the PHQ-8 questionnaire is structured. Our results indicate that, although a multitask approach improves performance and fairness compared to a unitask approach, the results are not always consistent and we see evidence of negative transfer and a reduction in the Pareto frontier, which is concerning given the high-stake healthcare setting. Our proposed approach of gender-based reweighting with uncertainty improves performance and fairness and alleviates both challenges to a certain extent. Our findings on each PHQ-8 subitem task difficulty are also in agreement with the largest study conducted on the PHQ-8 subitem discrimination capacity, thus providing the very first tangible evidence linking ML findings with large-scale empirical population studies conducted on the PHQ-8."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Fine-Grained Image-Text Correspondence with Cost Aggregation for Open-Vocabulary Part Segmentation", "authors": "Jiho Choi, Seonho Lee, Minhyun Lee, Seungho Lee, Hyunjung Shim", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Open-Vocabulary Part Segmentation (OVPS) is an emerging field for recognizing fine-grained parts in unseen categories. We identify two primary challenges in OVPS: (1) the difficulty in aligning part-level image-text correspondence, and (2) the lack of structural understanding in segmenting object parts. To address these issues, we propose PartCATSeg, a novel framework that integrates object-aware part-level cost aggregation, compositional loss, and structural guidance from DINO. Our approach employs a disentangled cost aggregation strategy that handles object and part-level costs separately, enhancing the precision of part-level segmentation. We also introduce a compositional loss to better capture part-object relationships, compensating for the limited part annotations. Additionally, structural guidance from DINO features improves boundary delineation and inter-part understanding. Extensive experiments on Pascal-Part-116, ADE20K-Part-234, and PartImageNet datasets demonstrate that our method significantly outperforms state-of-the-art approaches, setting a new baseline for robust generalization to unseen part categories."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Near-optimal Algorithm for Learning Margin Halfspaces with Massart Noise", "authors": "Ilias Diakonikolas, Nikos Zarifis", "subjects": "Subjects:\nMachine Learning (cs.LG); Data Structures and Algorithms (cs.DS); Statistics Theory (math.ST); Machine Learning (stat.ML)", "abstract": "We study the problem of PAC learning $\\gamma$-margin halfspaces in the presence of Massart noise. Without computational considerations, the sample complexity of this learning problem is known to be $\\widetilde{\\Theta}(1/(\\gamma^2 \\epsilon))$. Prior computationally efficient algorithms for the problem incur sample complexity $\\tilde{O}(1/(\\gamma^4 \\epsilon^3))$ and achieve 0-1 error of $\\eta+\\epsilon$, where $\\eta<1/2$ is the upper bound on the noise rate. Recent work gave evidence of an information-computation tradeoff, suggesting that a quadratic dependence on $1/\\epsilon$ is required for computationally efficient algorithms. Our main result is a computationally efficient learner with sample complexity $\\widetilde{\\Theta}(1/(\\gamma^2 \\epsilon^2))$, nearly matching this lower bound. In addition, our algorithm is simple and practical, relying on online SGD on a carefully selected sequence of convex losses."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Simulated Interactive Debugging", "authors": "Yannic Noller, Erick Chandra, Srinidhi HC, Kenny Choo, Cyrille Jegourel, Oka Kurniawan, Christopher M. Poskitt", "subjects": "Subjects:\nSoftware Engineering (cs.SE)", "abstract": "Debugging software, i.e., the localization of faults and their repair, is a main activity in software engineering. Therefore, effective and efficient debugging is one of the core skills a software engineer must develop. However, the teaching of debugging techniques is usually very limited or only taught in indirect ways, e.g., during software projects. As a result, most Computer Science (CS) students learn debugging only in an ad-hoc and unstructured way. In this work, we present our approach called Simulated Interactive Debugging that interactively guides students along the debugging process. The guidance aims to empower the students to repair their solutions and have a proper \"learning\" experience. We envision that such guided debugging techniques can be integrated into programming courses early in the CS education curriculum. To perform an initial evaluation, we developed a prototypical implementation using traditional fault localization techniques and large language models. Students can use features like the automated setting of breakpoints or an interactive chatbot. We designed and executed a controlled experiment that included this IDE-integrated tooling with eight undergraduate CS students. Based on the responses, we conclude that the participants liked the systematic guidance by the assisted debugger. In particular, they rated the automated setting of breakpoints as the most effective, followed by the interactive debugging and chatting, and the explanations for how breakpoints were set. In our future work, we will improve our concept and implementation, add new features, and perform more intensive user studies."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Mitigating Hallucinations in Large Vision-Language Models via DPO: On-Policy Data Hold the Key", "authors": "Zhihe Yang, Xufang Luo, Dongqi Han, Yunjian Xu, Dongsheng Li", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Hallucination remains a major challenge for Large Vision-Language Models (LVLMs). Direct Preference Optimization (DPO) has gained increasing attention as a simple solution to hallucination issues. It directly learns from constructed preference pairs that reflect the severity of hallucinations in responses to the same prompt and image. Nonetheless, different data construction methods in existing works bring notable performance variations. We identify a crucial factor here: outcomes are largely contingent on whether the constructed data aligns on-policy w.r.t the initial (reference) policy of DPO. Theoretical analysis suggests that learning from off-policy data is impeded by the presence of KL-divergence between the updated policy and the reference policy. From the perspective of dataset distribution, we systematically summarize the inherent flaws in existing algorithms that employ DPO to address hallucination issues. To alleviate the problems, we propose On-Policy Alignment (OPA)-DPO framework, which uniquely leverages expert feedback to correct hallucinated responses and aligns both the original and expert-revised responses in an on-policy manner. Notably, with only 4.8k data, OPA-DPO achieves an additional reduction in the hallucination rate of LLaVA-1.5-7B: 13.26% on the AMBER benchmark and 5.39% on the Object-Hal benchmark, compared to the previous SOTA algorithm trained with 16k samples."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Cueless EEG imagined speech for subject identification: dataset and benchmarks", "authors": "Ali Derakhshesh, Zahra Dehghanian, Reza Ebrahimpour, Hamid R. Rabiee", "subjects": "Subjects:\nMachine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Electroencephalogram (EEG) signals have emerged as a promising modality for biometric identification. While previous studies have explored the use of imagined speech with semantically meaningful words for subject identification, most have relied on additional visual or auditory cues. In this study, we introduce a cueless EEG-based imagined speech paradigm, where subjects imagine the pronunciation of semantically meaningful words without any external cues. This innovative approach addresses the limitations of prior methods by requiring subjects to select and imagine words from a predefined list naturally. The dataset comprises over 4,350 trials from 11 subjects across five sessions. We assess a variety of classification methods, including traditional machine learning techniques such as Support Vector Machines (SVM) and XGBoost, as well as time-series foundation models and deep learning architectures specifically designed for EEG classification, such as EEG Conformer and Shallow ConvNet. A session-based hold-out validation strategy was employed to ensure reliable evaluation and prevent data leakage. Our results demonstrate outstanding classification accuracy, reaching 97.93%. These findings highlight the potential of cueless EEG paradigms for secure and reliable subject identification in real-world applications, such as brain-computer interfaces (BCIs)."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Infinity norm bounds for the inverse of Nekrasov matrices using scaling matrices", "authors": "H\u00e9ctor Orera, Juan Manuel Pe\u00f1a", "subjects": "Subjects:\nNumerical Analysis (math.NA)", "abstract": "For many applications, it is convenient to have good upper bounds for the norm of the inverse of a given matrix. In this paper, we obtain such bounds when A is a Nekrasov matrix, by means of a scaling matrix transforming A into a strictly diagonally dominant matrix. Numerical examples and comparisons with other bounds are included. The scaling matrices are also used to derive new error bounds for the linear complementarity problems when the involved matrix is a Nekrasov matrix. These error bounds can improve considerably other previous bounds."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Practical Continual Forgetting for Pre-trained Vision Models", "authors": "Hongbo Zhao, Fei Zhu, Bolin Ni, Feng Zhu, Gaofeng Meng, Zhaoxiang Zhang", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "For privacy and security concerns, the need to erase unwanted information from pre-trained vision models is becoming evident nowadays. In real-world scenarios, erasure requests originate at any time from both users and model owners, and these requests usually form a sequence. Therefore, under such a setting, selective information is expected to be continuously removed from a pre-trained model while maintaining the rest. We define this problem as continual forgetting and identify three key challenges. (i) For unwanted knowledge, efficient and effective deleting is crucial. (ii) For remaining knowledge, the impact brought by the forgetting procedure should be minimal. (iii) In real-world scenarios, the training samples may be scarce or partially missing during the process of forgetting. To address them, we first propose Group Sparse LoRA (GS-LoRA). Specifically, towards (i), we introduce LoRA modules to fine-tune the FFN layers in Transformer blocks for each forgetting task independently, and towards (ii), a simple group sparse regularization is adopted, enabling automatic selection of specific LoRA groups and zeroing out the others. To further extend GS-LoRA to more practical scenarios, we incorporate prototype information as additional supervision and introduce a more practical approach, GS-LoRA++. For each forgotten class, we move the logits away from its original prototype. For the remaining classes, we pull the logits closer to their respective prototypes. We conduct extensive experiments on face recognition, object detection and image classification and demonstrate that our method manages to forget specific classes with minimal impact on other classes. Codes have been released on this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Domain Adaptation of Foundation LLMs for e-Commerce", "authors": "Christian Herold, Michael Kozielski, Tala Bazazo, Pavel Petrushkov, Hadi Hashemi, Patrycja Cieplicka, Dominika Basaj, Shahram Khadivi", "subjects": "Subjects:\nComputation and Language (cs.CL)", "abstract": "We present the e-Llama models: 8 billion and 70 billion parameter large language models that are adapted towards the e-commerce domain. These models are meant as foundation models with deep knowledge about e-commerce, that form a base for instruction- and fine-tuning. The e-Llama models are obtained by continuously pretraining the Llama 3.1 base models on 1 trillion tokens of domain-specific data. We discuss our approach and motivate our choice of hyperparameters with a series of ablation studies. To quantify how well the models have been adapted to the e-commerce domain, we define and implement a set of multilingual, e-commerce specific evaluation tasks. We show that, when carefully choosing the training setup, the Llama 3.1 models can be adapted towards the new domain without sacrificing significant performance on general domain tasks. We also explore the possibility of merging the adapted model and the base model for a better control of the performance trade-off between domains."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          The Goofus & Gallant Story Corpus for Practical Value Alignment", "authors": "Md Sultan Al Nahian, Tasmia Tasrin, Spencer Frazier, Mark Riedl, Brent Harrison", "subjects": "Subjects:\nArtificial Intelligence (cs.AI)", "abstract": "Values or principles are key elements of human society that influence people to behave and function according to an accepted standard set of social rules to maintain social order. As AI systems are becoming ubiquitous in human society, it is a major concern that they could violate these norms or values and potentially cause harm. Thus, to prevent intentional or unintentional harm, AI systems are expected to take actions that align with these principles. Training systems to exhibit this type of behavior is difficult and often requires a specialized dataset. This work presents a multi-modal dataset illustrating normative and non-normative behavior in real-life situations described through natural language and artistic images. This training set contains curated sets of images that are designed to teach young children about social principles. We argue that this is an ideal dataset to use for training socially normative agents given this fact."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          CyberMentor: AI Powered Learning Tool Platform to Address Diverse Student Needs in Cybersecurity Education", "authors": "Tianyu Wang, Nianjun Zhou, Zhixiong Chen", "subjects": "Subjects:\nComputers and Society (cs.CY); Artificial Intelligence (cs.AI)", "abstract": "Many non-traditional students in cybersecurity programs often lack access to advice from peers, family members and professors, which can hinder their educational experiences. Additionally, these students may not fully benefit from various LLM-powered AI assistants due to issues like content relevance, locality of advice, minimum expertise, and timing. This paper addresses these challenges by introducing an application designed to provide comprehensive support by answering questions related to knowledge, skills, and career preparation advice tailored to the needs of these students. We developed a learning tool platform, CyberMentor, to address the diverse needs and pain points of students majoring in cybersecurity. Powered by agentic workflow and Generative Large Language Models (LLMs), the platform leverages Retrieval-Augmented Generation (RAG) for accurate and contextually relevant information retrieval to achieve accessibility and personalization. We demonstrated its value in addressing knowledge requirements for cybersecurity education and for career marketability, in tackling skill requirements for analytical and programming assignments, and in delivering real time on demand learning support. Using three use scenarios, we showcased CyberMentor in facilitating knowledge acquisition and career preparation and providing seamless skill-based guidance and support. We also employed the LangChain prompt-based evaluation methodology to evaluate the platform's impact, confirming its strong performance in helpfulness, correctness, and completeness. These results underscore the system's ability to support students in developing practical cybersecurity skills while improving equity and sustainability within higher education. Furthermore, CyberMentor's open-source design allows for adaptation across other disciplines, fostering educational innovation and broadening its potential impact."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          On equidistant single-orbit cyclic and quasi-cyclic subspace codes", "authors": "Mahak, Maheshanand Bhaintwal", "subjects": "Subjects:\nInformation Theory (cs.IT)", "abstract": "A code is said to be equidistant if the distance between any two distinct codewords of the code is the same. In this paper, we have studied equidistant single-orbit cyclic and quasi-cyclic subspace codes. The orbit code generated by a subspace $U$ in $\\mathbb{F}_{q^n}$ such that the dimension of $U$ over $\\mathbb{F}_q$ is $t$ or $n-t$, $\\mbox{where}~t=\\dim_{\\mathbb{F}_q}(\\mbox{Stab}(U)\\cup\\{0\\})$, is equidistant and is termed a trivial equidistant orbit code. Using the concept of cyclic difference sets, we have proved that only the trivial equidistant single-orbit cyclic subspace codes exist. Further, we have explored equidistant single-orbit quasi-cyclic subspace codes, focusing specifically on those which are sunflowers."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Intelligent OLSR Routing Protocol Optimization for VANETs", "authors": "Jamal Toutouh, Jos\u00e9 Garc\u00eda-Nieto, Enrique Alba", "subjects": "Subjects:\nNeural and Evolutionary Computing (cs.NE); Networking and Internet Architecture (cs.NI)", "abstract": "Recent advances in wireless technologies have given rise to the emergence of vehicular ad hoc networks (VANETs). In such networks, the limited coverage of WiFi and the high mobility of the nodes generate frequent topology changes and network fragmentations. For these reasons, and taking into account that there is no central manager entity, routing packets through the network is a challenging task. Therefore, offering an efficient routing strategy is crucial to the deployment of VANETs. This paper deals with the optimal parameter setting of the optimized link state routing (OLSR), which is a well-known mobile ad hoc network routing protocol, by defining an optimization problem. This way, a series of representative metaheuristic algorithms (particle swarm optimization, differential evolution, genetic algorithm, and simulated annealing) are studied in this paper to find automatically optimal configurations of this routing protocol. In addition, a set of realistic VANET scenarios (based in the city of M\u00e1laga) have been defined to accurately evaluate the performance of the network under our automatic OLSR. In the experiments, our tuned OLSR configurations result in better quality of service (QoS) than the standard request for comments (RFC 3626), as well as several human experts, making it amenable for utilization in VANET configurations."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          FLOL: Fast Baselines for Real-World Low-Light Enhancement", "authors": "Juan C. Benito, Daniel Feijoo, Alvaro Garcia, Marcos V. Conde", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)", "abstract": "Low-Light Image Enhancement (LLIE) is a key task in computational photography and imaging. The problem of enhancing images captured during night or in dark environments has been well-studied in the image signal processing literature. However, current deep learning-based solutions struggle with efficiency and robustness in real-world scenarios (e.g. scenes with noise, saturated pixels, bad illumination). We propose a lightweight neural network that combines image processing in the frequency and spatial domains. Our method, FLOL+, is one of the fastest models for this task, achieving state-of-the-art results on popular real scenes datasets such as LOL and LSRW. Moreover, we are able to process 1080p images under 12ms. Code and models at this https URL"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Comparative Insights from 12 Machine Learning Models in Extracting Economic Ideology from Political Text", "authors": "Jihed Ncib", "subjects": "Subjects:\nComputation and Language (cs.CL)", "abstract": "This study conducts a systematic assessment of the capabilities of 12 machine learning models and model variations in detecting economic ideology. As an evaluation benchmark, I use manifesto data spanning six elections in the United Kingdom and pre-annotated by expert and crowd coders. The analysis assesses the performance of several generative, fine-tuned, and zero-shot models at the granular and aggregate levels. The results show that generative models such as GPT-4o and Gemini 1.5 Flash consistently outperform other models against all benchmarks. However, they pose issues of accessibility and resource availability. Fine-tuning yielded competitive performance and offers a reliable alternative through domain-specific optimization. But its dependency on training data severely limits scalability. Zero-shot models consistently face difficulties with identifying signals of economic ideology, often resulting in negative associations with human coding. Using general knowledge for the domain-specific task of ideology scaling proved to be unreliable. Other key findings include considerable within-party variation, fine-tuning benefiting from larger training data, and zero-shot's sensitivity to prompt content. The assessments include the strengths and limitations of each model and derive best-practices for automated analyses of political content."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Simple Aerial Detection Baseline of Multimodal Language Models", "authors": "Qingyun Li, Yushi Chen, Xinya Shu, Dong Chen, Xin He, Yi Yu, Xue Yang", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "The multimodal language models (MLMs) based on generative pre-trained Transformer are considered powerful candidates for unifying various domains and tasks. MLMs developed for remote sensing (RS) have demonstrated outstanding performance in multiple tasks, such as visual question answering and visual grounding. In addition to visual grounding that detects specific objects corresponded to given instruction, aerial detection, which detects all objects of multiple categories, is also a valuable and challenging task for RS foundation models. However, aerial detection has not been explored by existing RS MLMs because the autoregressive prediction mechanism of MLMs differs significantly from the detection outputs. In this paper, we present a simple baseline for applying MLMs to aerial detection for the first time, named LMMRotate. Specifically, we first introduce a normalization method to transform detection outputs into textual outputs to be compatible with the MLM framework. Then, we propose a evaluation method, which ensures a fair comparison between MLMs and conventional object detection models. We construct the baseline by fine-tuning open-source general-purpose MLMs and achieve impressive detection performance comparable to conventional detector. We hope that this baseline will serve as a reference for future MLM development, enabling more comprehensive capabilities for understanding RS images. Code is available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Attention based Bidirectional GRU hybrid model for inappropriate content detection in Urdu language", "authors": "Ezzah Shoukat, Rabia Irfan, Iqra Basharat, Muhammad Ali Tahir, Sameen Shaukat", "subjects": "Subjects:\nComputation and Language (cs.CL); Machine Learning (cs.LG)", "abstract": "With the increased use of the internet and social networks for online discussions, the spread of toxic and inappropriate content on social networking sites has also increased. Several studies have been conducted in different languages. However, there is less work done for South Asian languages for inappropriate content identification using deep learning techniques. In Urdu language, the spellings are not unique, and people write different common spellings for the same word, while mixing it other languages, like English in the text makes it more challenging, and limited research work is available to process such language with the finest algorithms. The use of attention layer with a deep learning model can help handling the long-term dependencies and increase its efficiency . To explore the effects of the attention layer, this study proposes attention-based Bidirectional GRU hybrid model for identifying inappropriate content in Urdu Unicode text language. Four different baseline deep learning models; LSTM, Bi-LSTM, GRU, and TCN, are used to compare the performance of the proposed model. The results of these models were compared based on evaluation metrics, dataset size, and impact of the word embedding layer. The pre-trained Urdu word2Vec embeddings were utilized for our case. Our proposed model BiGRU-A outperformed all other baseline models by yielding 84\\% accuracy without using pre-trained word2Vec layer. From our experiments, we have established that the attention layer improves the model's efficiency, and pre-trained word2Vec embedding does not work well with an inappropriate content dataset."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Parallel multi-objective metaheuristics for smart communications in vehicular networks", "authors": "Jamal Toutouh, Enrique Alba", "subjects": "Subjects:\nNeural and Evolutionary Computing (cs.NE); Artificial Intelligence (cs.AI); Networking and Internet Architecture (cs.NI)", "abstract": "This article analyzes the use of two parallel multi-objective soft computing algorithms to automatically search for high-quality settings of the Ad hoc On Demand Vector routing protocol for vehicular networks. These methods are based on an evolutionary algorithm and on a swarm intelligence approach. The experimental analysis demonstrates that the configurations computed by our optimization algorithms outperform other state-of-the-art optimized ones. In turn, the computational efficiency achieved by all the parallel versions is greater than 87 %. Therefore, the line of work presented in this article represents an efficient framework to improve vehicular communications."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Generating particle physics Lagrangians with transformers", "authors": "Yong Sheng Koay, Rikard Enberg, Stefano Moretti, Eliel Camargo-Molina", "subjects": "Subjects:\nMachine Learning (cs.LG); Symbolic Computation (cs.SC); High Energy Physics - Phenomenology (hep-ph); High Energy Physics - Theory (hep-th)", "abstract": "In physics, Lagrangians provide a systematic way to describe laws governing physical systems. In the context of particle physics, they encode the interactions and behavior of the fundamental building blocks of our universe. By treating Lagrangians as complex, rule-based constructs similar to linguistic expressions, we trained a transformer model -- proven to be effective in natural language tasks -- to predict the Lagrangian corresponding to a given list of particles. We report on the transformer's performance in constructing Lagrangians respecting the Standard Model $\\mathrm{SU}(3)\\times \\mathrm{SU}(2)\\times \\mathrm{U}(1)$ gauge symmetries. The resulting model is shown to achieve high accuracies (over 90\\%) with Lagrangians up to six matter fields, with the capacity to generalize beyond the training distribution, albeit within architectural constraints. We show through an analysis of input embeddings that the model has internalized concepts such as group representations and conjugation operations as it learned to generate Lagrangians. We make the model and training datasets available to the community. An interactive demonstration can be found at: \\url{this https URL}."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Inference-Time Scaling for Diffusion Models beyond Scaling Denoising Steps", "authors": "Nanye Ma, Shangyuan Tong, Haolin Jia, Hexiang Hu, Yu-Chuan Su, Mingda Zhang, Xuan Yang, Yandong Li, Tommi Jaakkola, Xuhui Jia, Saining Xie", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Generative models have made significant impacts across various domains, largely due to their ability to scale during training by increasing data, computational resources, and model size, a phenomenon characterized by the scaling laws. Recent research has begun to explore inference-time scaling behavior in Large Language Models (LLMs), revealing how performance can further improve with additional computation during inference. Unlike LLMs, diffusion models inherently possess the flexibility to adjust inference-time computation via the number of denoising steps, although the performance gains typically flatten after a few dozen. In this work, we explore the inference-time scaling behavior of diffusion models beyond increasing denoising steps and investigate how the generation performance can further improve with increased computation. Specifically, we consider a search problem aimed at identifying better noises for the diffusion sampling process. We structure the design space along two axes: the verifiers used to provide feedback, and the algorithms used to find better noise candidates. Through extensive experiments on class-conditioned and text-conditioned image generation benchmarks, our findings reveal that increasing inference-time compute leads to substantial improvements in the quality of samples generated by diffusion models, and with the complicated nature of images, combinations of the components in the framework can be specifically chosen to conform with different application scenario."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          ComplexVAD: Detecting Interaction Anomalies in Video", "authors": "Furkan Mumcu, Michael J. Jones, Yasin Yilmaz, Anoop Cherian", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Existing video anomaly detection datasets are inadequate for representing complex anomalies that occur due to the interactions between objects. The absence of complex anomalies in previous video anomaly detection datasets affects research by shifting the focus onto simple anomalies. To address this problem, we introduce a new large-scale dataset: ComplexVAD. In addition, we propose a novel method to detect complex anomalies via modeling the interactions between objects using a scene graph with spatio-temporal attributes. With our proposed method and two other state-of-the-art video anomaly detection methods, we obtain baseline scores on ComplexVAD and demonstrate that our new method outperforms existing works."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Tensor-based Dinkelbach method for computing generalized tensor eigenvalues and its applications", "authors": "Haibin Chen, Wenqi Zhu, Coralia Cartis", "subjects": "Subjects:\nNumerical Analysis (math.NA); Optimization and Control (math.OC)", "abstract": "In this paper, we propose a novel tensor-based Dinkelbach--Type method for computing extremal tensor generalized eigenvalues. We show that the extremal tensor generalized eigenvalue can be reformulated as a critical subproblem of the classical Dinkelbach--Type method, which can subsequently be expressed as a multilinear optimization problem (MOP). The MOP is solved under a spherical constraint using an efficient proximal alternative minimization method, in which we rigorously establish the global convergence. Additionally, the equivalent MOP is reformulated as an unconstrained optimization problem, allowing for the analysis of the Kurdyka-Lojasiewicz (KL) exponent and providing an explicit expression for the convergence rate of the proposed algorithm. Preliminary numerical experiments on solving extremal tensor generalized eigenvalues and minimizing high-order trust-region subproblems are provided, validating the efficacy and practical utility of the proposed method."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          MultiGraphMatch: a subgraph matching algorithm for multigraphs", "authors": "Giovanni Micale, Antonio Di Maria, Roberto Grasso, Vincenzo Bonnici, Alfredo Ferro, Dennis Shasha, Rosalba Giugno, Alfredo Pulvirenti", "subjects": "Subjects:\nDatabases (cs.DB)", "abstract": "Subgraph matching is the problem of finding all the occurrences of a small graph, called the query, in a larger graph, called the target. Although the problem has been widely studied in simple graphs, few solutions have been proposed for multigraphs, in which two nodes can be connected by multiple edges, each denoting a possibly different type of relationship. In our new algorithm MultiGraphMatch, nodes and edges can be associated with labels and multiple properties. MultiGraphMatch introduces a novel data structure called bit matrix to efficiently index both the query and the target and filter the set of target edges that are matchable with each query edge. In addition, the algorithm proposes a new technique for ordering the processing of query edges based on the cardinalities of the sets of matchable edges. Using the CYPHER query definition language, MultiGraphMatch can perform queries with logical conditions on node and edge labels. We compare MultiGraphMatch with SuMGra and graph database systems Memgraph and Neo4J, showing comparable or better performance in all queries on a wide variety of synthetic and real-world graphs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Regulation of Algorithmic Collusion, Refined: Testing Pessimistic Calibrated Regret", "authors": "Jason D. Hartline, Chang Wang, Chenhao Zhang", "subjects": "Subjects:\nComputer Science and Game Theory (cs.GT); Theoretical Economics (econ.TH)", "abstract": "We study the regulation of algorithmic (non-)collusion amongst sellers in dynamic imperfect price competition by auditing their data as introduced by Hartline et al. [2024]. We develop an auditing method that tests whether a seller's pessimistic calibrated regret is low. The pessimistic calibrated regret is the highest calibrated regret of outcomes compatible with the observed data. This method relaxes the previous requirement that a pricing algorithm must use fully-supported price distributions to be auditable. This method is at least as permissive as any auditing method that has a high probability of failing algorithmic outcomes with non-vanishing calibrated regret. Additionally, we strengthen the justification for using vanishing calibrated regret, versus vanishing best-in-hindsight regret, as the non-collusion definition, by showing that even without any side information, the pricing algorithms that only satisfy weaker vanishing best-in-hindsight regret allow an opponent to manipulate them into posting supra-competitive prices. This manipulation cannot be excluded with a non-collusion definition of vanishing best-in-hindsight regret. We motivate and interpret the approach of auditing algorithms from their data as suggesting a per se rule. However, we demonstrate that it is possible for algorithms to pass the audit by pretending to have higher costs than they actually do. For such scenarios, the rule of reason can be applied to bound the range of costs to those that are reasonable for the domain."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          KU AIGEN ICL EDI@BC8 Track 3: Advancing Phenotype Named Entity Recognition and Normalization for Dysmorphology Physical Examination Reports", "authors": "Hajung Kim, Chanhwi Kim, Jiwoong Sohn, Tim Beck, Marek Rei, Sunkyu Kim, T Ian Simpson, Joram M Posma, Antoine Lain, Mujeen Sung, Jaewoo Kang", "subjects": "Subjects:\nArtificial Intelligence (cs.AI)", "abstract": "The objective of BioCreative8 Track 3 is to extract phenotypic key medical findings embedded within EHR texts and subsequently normalize these findings to their Human Phenotype Ontology (HPO) terms. However, the presence of diverse surface forms in phenotypic findings makes it challenging to accurately normalize them to the correct HPO terms. To address this challenge, we explored various models for named entity recognition and implemented data augmentation techniques such as synonym marginalization to enhance the normalization step. Our pipeline resulted in an exact extraction and normalization F1 score 2.6\\% higher than the mean score of all submissions received in response to the challenge. Furthermore, in terms of the normalization F1 score, our approach surpassed the average performance by 1.9\\%. These findings contribute to the advancement of automated medical data extraction and normalization techniques, showcasing potential pathways for future research and application in the biomedical domain."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Suggesting Code Edits in Interactive Machine Learning Notebooks Using Large Language Models", "authors": "Bihui Jin, Jiayue Wang, Pengyu Nie", "subjects": "Subjects:\nSoftware Engineering (cs.SE); Computation and Language (cs.CL); Machine Learning (cs.LG)", "abstract": "Machine learning developers frequently use interactive computational notebooks, such as Jupyter notebooks, to host code for data processing and model training. Jupyter notebooks provide a convenient tool for writing machine learning pipelines and interactively observing outputs, however, maintaining Jupyter notebooks, e.g., to add new features or fix bugs, can be challenging due to the length and complexity of the notebooks. Moreover, there is no existing benchmark related to developer edits on Jupyter notebooks. To address this, we present the first dataset of 48,398 Jupyter notebook edits derived from 20,095 revisions of 792 machine learning repositories on GitHub, and perform the first study of the using LLMs to predict code edits in Jupyter notebooks. Our dataset captures granular details of cell-level and line-level modifications, offering a foundation for understanding real-world maintenance patterns in machine learning workflows. We observed that the edits on Jupyter notebooks are highly localized, with changes averaging only 166 lines of code in repositories. While larger models outperform smaller counterparts in code editing, all models have low accuracy on our dataset even after finetuning, demonstrating the complexity of real-world machine learning maintenance tasks. Our findings emphasize the critical role of contextual information in improving model performance and point toward promising avenues for advancing large language models' capabilities in engineering machine learning code."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          FAST: Efficient Action Tokenization for Vision-Language-Action Models", "authors": "Karl Pertsch, Kyle Stachowicz, Brian Ichter, Danny Driess, Suraj Nair, Quan Vuong, Oier Mees, Chelsea Finn, Sergey Levine", "subjects": "Subjects:\nRobotics (cs.RO); Machine Learning (cs.LG)", "abstract": "Autoregressive sequence models, such as Transformer-based vision-language action (VLA) policies, can be tremendously effective for capturing complex and generalizable robotic behaviors. However, such models require us to choose a tokenization of our continuous action signals, which determines how the discrete symbols predicted by the model map to continuous robot actions. We find that current approaches for robot action tokenization, based on simple per-dimension, per-timestep binning schemes, typically perform poorly when learning dexterous skills from high-frequency robot data. To address this challenge, we propose a new compression-based tokenization scheme for robot actions, based on the discrete cosine transform. Our tokenization approach, Frequency-space Action Sequence Tokenization (FAST), enables us to train autoregressive VLAs for highly dexterous and high-frequency tasks where standard discretization methods fail completely. Based on FAST, we release FAST+, a universal robot action tokenizer, trained on 1M real robot action trajectories. It can be used as a black-box tokenizer for a wide range of robot action sequences, with diverse action spaces and control frequencies. Finally, we show that, when combined with the pi0 VLA, our method can scale to training on 10k hours of robot data and match the performance of diffusion VLAs, while reducing training time by up to 5x."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Enhancing Lexicon-Based Text Embeddings with Large Language Models", "authors": "Yibin Lei, Tao Shen, Yu Cao, Andrew Yates", "subjects": "Subjects:\nComputation and Language (cs.CL); Information Retrieval (cs.IR)", "abstract": "Recent large language models (LLMs) have demonstrated exceptional performance on general-purpose text embedding tasks. While dense embeddings have dominated related research, we introduce the first Lexicon-based EmbeddiNgS (LENS) leveraging LLMs that achieve competitive performance on these tasks. Regarding the inherent tokenization redundancy issue and unidirectional attention limitations in traditional causal LLMs, LENS consolidates the vocabulary space through token embedding clustering, and investigates bidirectional attention and various pooling strategies. Specifically, LENS simplifies lexicon matching by assigning each dimension to a specific token cluster, where semantically similar tokens are grouped together, and unlocking the full potential of LLMs through bidirectional attention. Extensive experiments demonstrate that LENS outperforms dense embeddings on the Massive Text Embedding Benchmark (MTEB), delivering compact feature representations that match the sizes of dense counterparts. Notably, combining LENSE with dense embeddings achieves state-of-the-art performance on the retrieval subset of MTEB (i.e. BEIR)."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          OmniThink: Expanding Knowledge Boundaries in Machine Writing through Thinking", "authors": "Zekun Xi, Wenbiao Yin, Jizhan Fang, Jialong Wu, Runnan Fang, Ningyu Zhang, Jiang Yong, Pengjun Xie, Fei Huang, Huajun Chen", "subjects": "Subjects:\nComputation and Language (cs.CL)", "abstract": "Machine writing with large language models often relies on retrieval-augmented generation. However, these approaches remain confined within the boundaries of the model's predefined scope, limiting the generation of content with rich information. Specifically, vanilla-retrieved information tends to lack depth, utility, and suffers from redundancy, which negatively impacts the quality of generated articles, leading to shallow, repetitive, and unoriginal outputs. To address these issues, we propose OmniThink, a machine writing framework that emulates the human-like process of iterative expansion and reflection. The core idea behind OmniThink is to simulate the cognitive behavior of learners as they progressively deepen their knowledge of the topics. Experimental results demonstrate that OmniThink improves the knowledge density of generated articles without compromising metrics such as coherence and depth. Human evaluations and expert feedback further highlight the potential of OmniThink to address real-world challenges in the generation of long-form articles."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A vertical slice frontogenesis test case for compressible nonhydrostatic dynamical cores of atmospheric models", "authors": "Hiroe Yamazaki, Colin Cotter", "subjects": "Subjects:\nNumerical Analysis (math.NA); Atmospheric and Oceanic Physics (physics.ao-ph)", "abstract": "A new test case is presented for evaluating the compressible dynamical cores of the atmospheric models. The test case is based on a compressible vertical slice model that can be obtained by simple modification of a standard three dimensional compressible dynamical core. On the one hand, an advantage of the test case is that is quasi-2D, so it can be run quickly on a standard workstation, enabling rapid experimentation with numerical schemes and discretisation choices. On the other hand, the test case exhibits frontogenesis, a challenging regime for numerical discretisations which usually only arises in 3D model configurations for the compressible case. Numerical results of the test case using an implicit time-stepping method with a compatible finite element discretisation are presented as a reference solution. An example comparison between advective and vector-invariant forms for the advective nonlinearity in the velocity equation demonstrates one possible use of the scheme. The comparison shows a Hollingsworth-like instability when the vector invariant form is used."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SRE-Conv: Symmetric Rotation Equivariant Convolution for Biomedical Image Classification", "authors": "Yuexi Du, Jiazhen Zhang, Tal Zeevi, Nicha C. Dvornek, John A. Onofrey", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Image and Video Processing (eess.IV)", "abstract": "Convolutional neural networks (CNNs) are essential tools for computer vision tasks, but they lack traditionally desired properties of extracted features that could further improve model performance, e.g., rotational equivariance. Such properties are ubiquitous in biomedical images, which often lack explicit orientation. While current work largely relies on data augmentation or explicit modules to capture orientation information, this comes at the expense of increased training costs or ineffective approximations of the desired equivariance. To overcome these challenges, we propose a novel and efficient implementation of the Symmetric Rotation-Equivariant (SRE) Convolution (SRE-Conv) kernel, designed to learn rotation-invariant features while simultaneously compressing the model size. The SRE-Conv kernel can easily be incorporated into any CNN backbone. We validate the ability of a deep SRE-CNN to capture equivariance to rotation using the public MedMNISTv2 dataset (16 total tasks). SRE-Conv-CNN demonstrated improved rotated image classification performance accuracy on all 16 test datasets in both 2D and 3D images, all while increasing efficiency with fewer parameters and reduced memory footprint. The code is available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Lost in Translation, Found in Context: Sign Language Translation with Contextual Cues", "authors": "Youngjoon Jang, Haran Raajesh, Liliane Momeni, G\u00fcl Varol, Andrew Zisserman", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV)", "abstract": "Our objective is to translate continuous sign language into spoken language text. Inspired by the way human interpreters rely on context for accurate translation, we incorporate additional contextual cues together with the signing video, into a new translation framework. Specifically, besides visual sign recognition features that encode the input video, we integrate complementary textual information from (i) captions describing the background show, (ii) translation of previous sentences, as well as (iii) pseudo-glosses transcribing the signing. These are automatically extracted and inputted along with the visual features to a pre-trained large language model (LLM), which we fine-tune to generate spoken language translations in text form. Through extensive ablation studies, we show the positive contribution of each input cue to the translation performance. We train and evaluate our approach on BOBSL -- the largest British Sign Language dataset currently available. We show that our contextual approach significantly enhances the quality of the translations compared to previously reported results on BOBSL, and also to state-of-the-art methods that we implement as baselines. Furthermore, we demonstrate the generality of our approach by applying it also to How2Sign, an American Sign Language dataset, and achieve competitive results."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Learnings from Scaling Visual Tokenizers for Reconstruction and Generation", "authors": "Philippe Hansen-Estruch, David Yan, Ching-Yao Chung, Orr Zohar, Jialiang Wang, Tingbo Hou, Tao Xu, Sriram Vishwanath, Peter Vajda, Xinlei Chen", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Visual tokenization via auto-encoding empowers state-of-the-art image and video generative models by compressing pixels into a latent space. Although scaling Transformer-based generators has been central to recent advances, the tokenizer component itself is rarely scaled, leaving open questions about how auto-encoder design choices influence both its objective of reconstruction and downstream generative performance. Our work aims to conduct an exploration of scaling in auto-encoders to fill in this blank. To facilitate this exploration, we replace the typical convolutional backbone with an enhanced Vision Transformer architecture for Tokenization (ViTok). We train ViTok on large-scale image and video datasets far exceeding ImageNet-1K, removing data constraints on tokenizer scaling. We first study how scaling the auto-encoder bottleneck affects both reconstruction and generation -- and find that while it is highly correlated with reconstruction, its relationship with generation is more complex. We next explored the effect of separately scaling the auto-encoders' encoder and decoder on reconstruction and generation performance. Crucially, we find that scaling the encoder yields minimal gains for either reconstruction or generation, while scaling the decoder boosts reconstruction but the benefits for generation are mixed. Building on our exploration, we design ViTok as a lightweight auto-encoder that achieves competitive performance with state-of-the-art auto-encoders on ImageNet-1K and COCO reconstruction tasks (256p and 512p) while outperforming existing auto-encoders on 16-frame 128p video reconstruction for UCF-101, all with 2-5x fewer FLOPs. When integrated with Diffusion Transformers, ViTok demonstrates competitive performance on image generation for ImageNet-1K and sets new state-of-the-art benchmarks for class-conditional video generation on UCF-101."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SynthLight: Portrait Relighting with Diffusion Model by Learning to Re-render Synthetic Faces", "authors": "Sumit Chaturvedi, Mengwei Ren, Yannick Hold-Geoffroy, Jingyuan Liu, Julie Dorsey, Zhixin Shu", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR)", "abstract": "We introduce SynthLight, a diffusion model for portrait relighting. Our approach frames image relighting as a re-rendering problem, where pixels are transformed in response to changes in environmental lighting conditions. Using a physically-based rendering engine, we synthesize a dataset to simulate this lighting-conditioned transformation with 3D head assets under varying lighting. We propose two training and inference strategies to bridge the gap between the synthetic and real image domains: (1) multi-task training that takes advantage of real human portraits without lighting labels; (2) an inference time diffusion sampling procedure based on classifier-free guidance that leverages the input portrait to better preserve details. Our method generalizes to diverse real photographs and produces realistic illumination effects, including specular highlights and cast shadows, while preserving the subject's identity. Our quantitative experiments on Light Stage data demonstrate results comparable to state-of-the-art relighting methods. Our qualitative results on in-the-wild images showcase rich and unprecedented illumination effects. Project Page: \\url{this https URL}"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Distilling Multi-modal Large Language Models for Autonomous Driving", "authors": "Deepti Hegde, Rajeev Yasarla, Hong Cai, Shizhong Han, Apratim Bhattacharyya, Shweta Mahajan, Litian Liu, Risheek Garrepalli, Vishal M. Patel, Fatih Porikli", "subjects": "Subjects:\nComputer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)", "abstract": "Autonomous driving demands safe motion planning, especially in critical \"long-tail\" scenarios. Recent end-to-end autonomous driving systems leverage large language models (LLMs) as planners to improve generalizability to rare events. However, using LLMs at test time introduces high computational costs. To address this, we propose DiMA, an end-to-end autonomous driving system that maintains the efficiency of an LLM-free (or vision-based) planner while leveraging the world knowledge of an LLM. DiMA distills the information from a multi-modal LLM to a vision-based end-to-end planner through a set of specially designed surrogate tasks. Under a joint training strategy, a scene encoder common to both networks produces structured representations that are semantically grounded as well as aligned to the final planning objective. Notably, the LLM is optional at inference, enabling robust planning without compromising on efficiency. Training with DiMA results in a 37% reduction in the L2 trajectory error and an 80% reduction in the collision rate of the vision-based planner, as well as a 44% trajectory error reduction in longtail scenarios. DiMA also achieves state-of-the-art performance on the nuScenes planning benchmark."}
